# Import required packages
import os
import pandas as pd
import matplotlib.pyplot as plt
import torch
from torch import nn
import torch.nn.functional as F
import torch_geometric
from torch_geometric.loader import DataLoader
from torch_geometric.nn import GCNConv
from torch_geometric.nn import global_mean_pool
# Get cpu, gpu or mps device for training.
device = (
"cuda"
if torch.cuda.is_available()
else "mps"
if torch.backends.mps.is_available()
else "cpu"
)
print(f"Using {device} device")
brca = torch_geometric.datasets.BrcaTcga(
root='./posts/pytorch-brca/'
)
len(brca)
brca.num_classes
brca.num_node_features
brca_graph0 = brca[0]
print(brca_graph0)
brca_graph0.is_undirected()
# Access the node features, edge indices, and target label
node_features = brca_graph0.x
edge_index = brca_graph0.edge_index
target = brca_graph0.y
print(node_features)  # Print the node features
print(edge_index)  # Print the edge indices
print(target)  # Print the target label
# Apply 70/30 train/test split
splitIndex = round(len(brca)*.7)
training_data = brca[:splitIndex]
test_data = brca[splitIndex:]
batch_size = 64
# Create data loaders.
train_dataloader = DataLoader(
training_data,
batch_size=batch_size,
shuffle=True
)
for step, data in enumerate(train_dataloader):
data = data.to(device)
test_dataloader = DataLoader(
test_data,
batch_size=batch_size,
shuffle=False
)
for step, data in enumerate(test_dataloader):
data = data.to(device)
class GCN(nn.Module):
def __init__(self, hidden_channels, num_node_features):
super(GCN, self).__init__()
self.conv1 = GCNConv(num_node_features, hidden_channels)
self.conv2 = GCNConv(hidden_channels, hidden_channels)
self.conv3 = GCNConv(hidden_channels, hidden_channels)
self.conv4 = GCNConv(hidden_channels, hidden_channels)
self.lin = nn.Linear(hidden_channels, 1)
def forward(self, x, edge_index, batch):
# 1. Obtain node embeddings
x = self.conv1(x, edge_index)
x = x.relu()
x = self.conv2(x, edge_index)
x = x.relu()
x = self.conv3(x, edge_index)
x = self.conv4(x, edge_index)
# 2. Readout layer
x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]
# 3. Apply a final regression layer
x = F.dropout(x, p=0.2, training=self.training)
x = self.lin(x)
return x.squeeze()  # Remove the extra dimension
model = GCN(hidden_channels=64, num_node_features=1).to(device)
print(f"Model structure: {model}")
for name, param in model.named_parameters():
print(f"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \n")
learning_rate = 1e-3
batch_size = 64
epochs = 5
# Initialize the loss function and the optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
def train_loop(dataloader, model, loss_fn, optimizer):
model.train()
for step, data in enumerate(train_dataloader):
data = data.to(device)
# Compute prediction and loss
pred = model(
data.x,
data.edge_index,
data.batch
)
loss = loss_fn(
pred,
data.y.view(-1)
)
# Backpropagation
loss.backward()
optimizer.step()
optimizer.zero_grad()
def test_loop(dataloader, model, loss_fn):
model.eval()
test_loss = 0
with torch.no_grad():
for step, data in enumerate(test_dataloader):
data = data.to(device)
pred = model(
data.x,
data.edge_index,
data.batch
)
loss += loss_fn(
pred,
data.y.view(-1)
).item()
test_loss /= num_batches
for t in range(epochs):
print(f"Epoch {t+1}\n-------------------------------")
train_loop(train_dataloader, model, loss_fn, optimizer)
test_loop(test_dataloader, model, loss_fn)
print("Done!")
ppi = torch_geometric.datasets.PPI(
root='./posts/pytorch-brca/'
)
View(ppi)
amex <- 38+68+155.70+47.45+241.66+113.04+375.18+17.65+79.46+7.72+16.99+86.42+12.9+6.24
amex
amex_paid <- 663.85+104.83+116.31
amex_paid
amex - amex_paid
joint <- 1.5+40+8.81+42.42+60.59+23.14+42+10.47+47.32+338.1+17.61+15.27+47.44+14.35+13.13+56.45+12+8.23+35+11.20+28.4+126.17
joint
joint_paid <- 804.14+64.68
joint_paid
joint - joint_paid
amex - amex_paid + joint - joint_paid
amex - amex_paid + joint - joint_paid - 1.88
28.13+2.99
vehicleTheft=c(1031, 951, 931, 911, 917, 1004, 951)
gambler=c(15, 30, 36, 50, 57, 59, 55, 48, 36, 20, 17)
q1.a<-rep(sum(vehicleTheft)/7, 7)
# Question 1.b
# Calculate the chi2 test statistic for testing the hypothesis described.
# Save your answer in the variable q1.b
q1.b<-sum((vehicleTheft-q1.a)^2 / q1.a)
monday<-(1031-957)^2/957
saturday<-(1004-957)^2/957
q1.c<-pchisq(q1.b, df=7-1, lower.tail = FALSE)
(a-b)
a <- c(1, 2, 3, 4)
b <- c(5, 6, 7, 8)
(a-b)
q2.b<-sum(gambler)*q2.a
q2.b<-sum(gambler)*q2.a
q2.a<-c(1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36, 1/36)
q2.b<-sum(gambler)*q2.a
a = 322
b = (500-322)
c = 341
d = (500-341)
(a+b)*(a+c)/1000
tensileData=read.csv("tensileData.csv")
tensileData = read.csv("./tensileData.csv")
# # # # # # # DO NOT EDIT BELOW # # # # # # #
tensileData = read.csv("./tensileData.csv")
setwd(./)
tensileData = read.csv("./tensileData.csv")
