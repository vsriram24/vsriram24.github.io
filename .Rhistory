# Import required packages
import os
import pandas as pd
import matplotlib.pyplot as plt
import torch
from torch import nn
import torch.nn.functional as F
import torch_geometric
from torch_geometric.loader import DataLoader
from torch_geometric.nn import GCNConv
from torch_geometric.nn import global_mean_pool
# Get cpu, gpu or mps device for training.
device = (
"cuda"
if torch.cuda.is_available()
else "mps"
if torch.backends.mps.is_available()
else "cpu"
)
print(f"Using {device} device")
brca = torch_geometric.datasets.BrcaTcga(
root='./posts/pytorch-brca/'
)
len(brca)
brca.num_classes
brca.num_node_features
brca_graph0 = brca[0]
print(brca_graph0)
brca_graph0.is_undirected()
# Access the node features, edge indices, and target label
node_features = brca_graph0.x
edge_index = brca_graph0.edge_index
target = brca_graph0.y
print(node_features)  # Print the node features
print(edge_index)  # Print the edge indices
print(target)  # Print the target label
# Apply 70/30 train/test split
splitIndex = round(len(brca)*.7)
training_data = brca[:splitIndex]
test_data = brca[splitIndex:]
batch_size = 64
# Create data loaders.
train_dataloader = DataLoader(
training_data,
batch_size=batch_size,
shuffle=True
)
for step, data in enumerate(train_dataloader):
data = data.to(device)
test_dataloader = DataLoader(
test_data,
batch_size=batch_size,
shuffle=False
)
for step, data in enumerate(test_dataloader):
data = data.to(device)
class GCN(nn.Module):
def __init__(self, hidden_channels, num_node_features):
super(GCN, self).__init__()
self.conv1 = GCNConv(num_node_features, hidden_channels)
self.conv2 = GCNConv(hidden_channels, hidden_channels)
self.conv3 = GCNConv(hidden_channels, hidden_channels)
self.conv4 = GCNConv(hidden_channels, hidden_channels)
self.lin = nn.Linear(hidden_channels, 1)
def forward(self, x, edge_index, batch):
# 1. Obtain node embeddings
x = self.conv1(x, edge_index)
x = x.relu()
x = self.conv2(x, edge_index)
x = x.relu()
x = self.conv3(x, edge_index)
x = self.conv4(x, edge_index)
# 2. Readout layer
x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]
# 3. Apply a final regression layer
x = F.dropout(x, p=0.2, training=self.training)
x = self.lin(x)
return x.squeeze()  # Remove the extra dimension
model = GCN(hidden_channels=64, num_node_features=1).to(device)
print(f"Model structure: {model}")
for name, param in model.named_parameters():
print(f"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \n")
learning_rate = 1e-3
batch_size = 64
epochs = 5
# Initialize the loss function and the optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
def train_loop(dataloader, model, loss_fn, optimizer):
model.train()
for step, data in enumerate(train_dataloader):
data = data.to(device)
# Compute prediction and loss
pred = model(
data.x,
data.edge_index,
data.batch
)
loss = loss_fn(
pred,
data.y.view(-1)
)
# Backpropagation
loss.backward()
optimizer.step()
optimizer.zero_grad()
def test_loop(dataloader, model, loss_fn):
model.eval()
test_loss = 0
with torch.no_grad():
for step, data in enumerate(test_dataloader):
data = data.to(device)
pred = model(
data.x,
data.edge_index,
data.batch
)
loss += loss_fn(
pred,
data.y.view(-1)
).item()
test_loss /= num_batches
for t in range(epochs):
print(f"Epoch {t+1}\n-------------------------------")
train_loop(train_dataloader, model, loss_fn, optimizer)
test_loop(test_dataloader, model, loss_fn)
print("Done!")
ppi = torch_geometric.datasets.PPI(
root='./posts/pytorch-brca/'
)
View(ppi)
