[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vivek Sriram, PhD, MA",
    "section": "",
    "text": "Welcome to my website! I am a biomedical data scientist and health machine learning researcher based in Seattle, WA.\nMy general research skills and interests include:\n\ntranslational bioinformatics and personalized medicine\nbig data analysis\ndeep learning and generative AI\ndata visualization\nnetwork science\nhuman-centered design\n\nI am always open to speaking, teaching, collaboration, consulting, and outreach opportunities. Feel free to reach out to me with questions or requests at vivek.sriram@gmail.com."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I consider myself a computational scientist with a passion for people-focused projects. I currently work as a clinical data scientist for the Office of the Chief Data Officer (OCDO) at the Fred Hutchinson Cancer Center in Seattle, WA. My role centers on the development and productization of statistical models and machine learning systems for electronic phenotyping and cohort identification across the institution. I also serve as a guest lecturer in the Department of Biostatistics, Epidemiology, and Informatics at the University of Pennsylvania and a collaborator with the Health Futures Group at Microsoft Research.\nPrior to my position at Fred Hutch, I completed my Ph.D. and postdoctoral training in Biomedical Informatics and Computational Genomics at the University of Pennsylvania Perelman School of Medicine. There, I worked with Dr. Dokyoon Kim’s Integrative ’Omics and Biomedical Informatics Lab, developing machine learning and graph-based methods to identify genetic contributors to disease comorbidities from large-scale multimodal biomedical data (You can listen to a recording of my public thesis defense here!)\nIn addition to my doctoral degree, I hold a M.A. in Statistics and Data Science from the Wharton School of Business, as well as a B.Sc. with honors in Statistics, a B.Sc. in Computer Science, and a minor in Computational Biology from Duke University."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "[VS]Codes",
    "section": "",
    "text": "Welcome to [VS]Codes, a biomedical data science and clinical informatics blog mixed with professional advice and miscellaneous detours, written by Vivek Sriram. To subscribe to my blog and get updates on my new posts directly in your inbox, click here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCascadia R Conference 2024\n\n\n\n\n\n\nConferences\n\n\n\nA few talk summaries and my personal takeaways\n\n\n\n\n\nJul 22, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\n\n\n\n\n\n\nMy podcast recommendations\n\n\n\n\n\n\nPersonal\n\n\n\nListen up!\n\n\n\n\n\nJul 15, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\n\n\n\n\n\n\nA Python introduction to neural networks and backpropagation\n\n\n\n\n\n\nTutorials\n\n\n\nAndrej Karpathy’s ‘Neural Networks: Zero to Hero’ video #1\n\n\n\n\n\nJul 8, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\n\n\n\n\n\n\nMy doctoral research: takeaways and advice\n\n\n\n\n\n\nPersonal\n\n\nAdvice\n\n\n\nWe’re all in this together\n\n\n\n\n\nJun 24, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\n\n\n\n\n\n\nMy doctoral research: the content\n\n\n\n\n\n\nPersonal\n\n\n\nConte(n)t is everything\n\n\n\n\n\nJun 17, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\n\n\n\n\n\n\nMy doctoral research: the background\n\n\n\n\n\n\nPersonal\n\n\n\nContext is everything\n\n\n\n\n\nJun 10, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\n\n\n\n\n\n\nBiomedical Data Science sub-disciplines (v0)\n\n\n\n\n\n\nOverviews\n\n\n\nWhat’s in a word?\n\n\n\n\n\nJun 3, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\n\n\n\n\n\n\nCorrecting batch effects in single cell RNA-seq data with Monocle 3\n\n\n\n\n\n\nTutorials\n\n\n\nTakeaways from the SASC User Group Workshop #2\n\n\n\n\n\nMay 27, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\n\n\n\n\n\n\nMy professional journey\n\n\n\n\n\n\nPersonal\n\n\n\nLife is a highway\n\n\n\n\n\nMay 15, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\n\n\n\n\n\n\nHello world!\n\n\n\n\n\n\nPersonal\n\n\n\nThe start of a new chapter\n\n\n\n\n\nMay 14, 2024\n\n\nVivek Sriram\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Sriram V§, Nam Y§, Shivakumar M, Verma A, Jung S-H, Lee SM*, Kim D*. A Network-Based Analysis of Disease Complication Associations for Obstetric Disorders in the UK Biobank. Journal of Personalized Medicine. 2021; 11(12):1382. https://doi.org/10.3390/jpm11121382\nNam Y§, Jung S-H§, Verma A, Sriram V, Wong H-H, Yun J-S, Kim D*. netCRS: Network-based comorbidity risk score for prediction of myocardial infarction using biobank-scaled PheWAS data. Pacific Symposium on Biocomputing 2022. https://doi.org/10.1142/9789811250477_0030\nSriram V§, Shivakumar M§, Jung S-H, Nam Y, Bang L, Verma A, Lee S, Choe EK, Kim D, NETMAGE: A human disease phenotype map generator for the network-based visualization of phenome-wide association study results, GigaScience, Volume 11, 2022, giac002, https://doi.org/10.1093/gigascience/giac002\nLee S§, Nam Y§, Choi ES, Jung YM, Sriram V, Leiby J, Koo JN, Oh IH, Kim BJ, Kim SM, Kim SY, Kim GM, Joo SK, Shin S, Norwitz E, Park CW, Jun JK, Kim W, Kim D*, Park JS*. Development of early prediction model for pregnancy-associated hypertension with graph-based semi-supervised learning. Scientific Reports, 12(1), 15793, 2022. https://doi.org/10.1038/s41598-022-15391-4\nNam Y§, Jung SH§, Yun JS, Verma A, Sriram V, Shin H, Won H*, Kim D*. Discovering comorbid diseases using an inter-disease interactivity network based on biobank-scale PheWAS data. Bioinformatics 39(1), 2023. https://doi.org/10.1093/bioinformatics/btac822\nWoerner J§, Sriram V§, Nam Y, Verma A, Kim D*. Uncovering genetic associations in the human diseasome using an endophenotype-augmented disease network. Bioinformatics 40(3), 2024. https://doi.org/10.1093/bioinformatics/btae126.\nSriram V, Conard AM, Rosenberg I, Kim D, Hall AK*. Accelerating precision medicine: a proposed framework for large-scale multiomic data integrity, interoperability, analysis, and collaboration in biomedical discovery. medRXiv. https://doi.org/10.1101/2024.03.15.24304358. Preprint.\nNam Y§, Sriram V§, Shivakumar M, Verma A, Yun JS, Kim D*. An enhanced disease network with robust cross-phenotype relationships via variant frequency-inverse phenotype frequency. Preprint.\nSriram V, Woerner J, Ahn YY*, Kim D*. The interplay of sex and genotype in disease associations: a comprehensive network analysis in the UK Biobank. Preprint."
  },
  {
    "objectID": "posts/240514_hello-world/index.html",
    "href": "posts/240514_hello-world/index.html",
    "title": "Hello world!",
    "section": "",
    "text": "Hello world, and welcome to my official blog! I’ve had numerous thoughts swirling around in my head over the past several years, but have had trouble formally committing to bringing them out into the world… however, encouragement from colleagues and recent reading (i.e. Dorie Clark’s The Long Game) have convinced me to finally bring my virtual pen to paper. In particular, I found myself tremendously inspired by the Fred Hutch DaSL Culture and Work Style document and the mantra of “ship as soon as you can.” The following graphic does a great job at reminding us how to avoid the pit of perfectionism!\n\nMy hopes for this blog are to (a) build a community, (b) share my knowledge, and (c) learn alongside my readers. I aim to write weekly (if not more frequent) posts on a variety of subjects, including:\n\nmy personal story\nadvice to others in my field\ntechnical tutorials\nsubject matter overviews, and\nmiscellaneous detours\n\nI have no expectations that my content will be perfect, but then again, learning from mistakes is one of the best parts of life :)\nGiven my background and expertise, my general focus will be on the world of biomedical data science and health technology, but the sky is the limit for the topics we may cover!\nThanks for tuning in - I’m delighted to have you along for the ride…"
  },
  {
    "objectID": "posts/240515_professional-journey/index.html",
    "href": "posts/240515_professional-journey/index.html",
    "title": "My professional journey",
    "section": "",
    "text": "For my first “real” post, I figured it would be a helpful exercise to go through my professional journey and track how I ended up where I currently am. This description is meant to be more of an overview, and I intend to provide more details on individual portions of it in the future.\n\nHaving grown up in the Silicon Valley, I always had a front-row seat to the power and potential of technology to improve people’s lives. All of the biggest tech companies had their headquarters within driving distance from my home, and every day, I could see how they had impacted not only myself but also everyone around me: computers, cellphones, social media, education, automobiles, entertainment… everything was shaped by information technology. Both of my parents were in the software industry too, and seeing the productive, fulfilling jobs that they were able to have made me certain that I wanted to involve technology in my future career. Learning how to code from my mother in high school made me feel like I was being imparted with some special kind of magic - entering the world of software engineering truly felt right at my fingertips.\nAt the same time, growing up in the Silicon Valley felt like growing up in a bubble. I yearned to explore the link between information technology and its downstream applications beyond my baseline understanding of how to write code. So, I sought out more. In high school, I took a breadth of science classes, and I found myself inspired by the concept of “interdisciplinarity”. Instead of being drawn to “information technology,” I was drawn closer and closer to the world of “information science” and its applications to multiple disciplines, including biology and medicine. My drive for interdisciplinary experiences and my desire to explore a world of technological applications outside of the Bay Area led me to Duke University for my undergraduate education - in fact, one of the mantras of the university was “creative thinking across intellectual boundaries”. At Duke, I completed double majors in Computer Science and Statistics. Duke’s affiliated medical campus also gave me chances to explore interdisciplinary applications in the world of biomedical informatics, and I pursued multiple research opportunities, including an Honor’s thesis for my Statistics degree under the supervision of Dr. Li Ma. I also completed a minor in Computational Biology, taking classes such as Computational Genomics with Dr. Alexander Hartemink and Computational Structural Biology with Dr. Bruce Donald. Lastly, I was lucky to have great summer internship mentors (including Li-Yuan Chern at Pharmacyclics and Drs. Zichen Wang and Avi Ma’ayan at the Icahn School of Medicine), who kept me motivated and inspired to stick to my path and pursue an advanced interdisciplinary career.\nBy the end of my undergrad, I knew that I wasn’t going to enter the traditional computer science recruitment cycle for software engineering roles - I instead applied to doctoral programs in biomedical informatics and computational biology that would allow me to build my knowledge base further and prepare me to become a leader in impactful projects that made a clear benefit in people’s lives. I was lucky to earn an admission with the Genomics and Computational Biology program at the University of Pennsylvania Perelman School of Medicine. Again, great mentors from my classes and research rotations (including Drs. Ryan Urbanowicz and Marylyn Ritchie to name a few) helped advance my training and made me a better researcher and scientist day by day. I am most indebted to my PhD advisor, Dr. Dokyoon Kim, for his support and mentorship throughout my PhD and subsequent post-doctoral position. With his leadership style and work ethic, he was a true role model for me throughout my graduate degree. I also fell in love with the combination of technical research and scientific storytelling that came out of my dissertation (to be discussed in a later post). During my PhD, I was able to complete a Master’s degree in Statistics and Data Science from the Wharton School of Business under the supervision of Dr. Anderson Zhang, as well as a summer internship as a User Experience Researcher in Health AI/ML under the supervision of Dr. Mandi Hall with the Health Futures team at Microsoft Research. All of these opportunities helped me to refine a set of motivators for my long-term career:\n\nimpact\nconnection\npassion\nleadership\n\nThese values aided me tremendously in my search for my first job upon the completion of my PhD. Today, I work as a clinical data scientist in the Translational Analytics and Informatics group at the Fred Hutchinson Cancer Center’s Data Science Lab (DaSL) in Seattle, WA (also to be discussed more in a future post). I am tremendously grateful to be a part of a supportive, driven community of fellow data scientists and researchers as we develop the clinical data infrastructure at Fred Hutch, and I look forward to sharing more about my work and career as the years progress!"
  },
  {
    "objectID": "posts/sasc-workshop2/index.html",
    "href": "posts/sasc-workshop2/index.html",
    "title": "Correcting batch effects in single cell RNA-seq data with Monocle 3",
    "section": "",
    "text": "In this week’s blog, I’ll be summarizing takeaways and a code example from the Seattle Area Single Cell (SASC) User Group’s second workshop of the year, which was held on May 16th, 2024. Slides from the workshop can be found here.\nThe SASC User Group, directed by Dr. Mary O’Neill at the Brotman Baty Institute, is designed to create connections and foster community among single-cell researchers at Fred Hutch, UW Medicine, Seattle Children’s, as well as other Seattle-area researchers working with single-cell data. If you are interested in joining the group, you can subscribe to their listserv here. The group holds quarterly meetings rotating across the three campuses, each with a different focus. May’s workshop was dedicated to applying batch correction methods using Monocle 3 to analyze single-cell RNA-seq (scRNA-seq) data.\n\nAll credit for the data and code in this workshop goes to Mary and the folks at the BBI who helped organize this community. I have simply summarized their content and added a few clarifiers in various sections! I claim no significant knowledge myself of working with single cell data - in the future, I hope to release a post that highlights some more of the biological context highlighted through this workshop. You can follow along with the original tutorial and code example at the SASC GitHub page here.\nAnd so, with context out of the way, let’s get started!\n\n\n1. Background\nMonocle 3 is “an analysis toolkit for single-cell RNA-seq data”, developed by the Trapnell Lab at the University of Washington Department of Genome Sciences.\nWhen analyzing any form of data, especially single cell data, it is important to keep the right sources of variation (see Aquino, Bisiaux, Li et al., Nature 2024). Batch effects refer to technical, non-biological factors that cause variation in data, and must be appropriately addressed to avoid confounding in results.\nThe best way to get around batch effects is to avoid introducing them in the first place! Nothing can salvage a poor study design. In a similar vein, it is important to determine whether or not there are actually batch effects in the first place that are influencing your data. Sometimes, batch corrections can introduce more artifacts than they alleviate. So, when applying batch correction methods, apply them thoughtfully. Know what they are doing, what to use them for, and where they can lead you astray.\nA variety of batch correction methods exist for scRNA-seq data (see Antonsson, Melsted, bioRXiv 2024). Generally, single cell analysis falls into two camps:\n\nBatch correction is only for visualization. The batch category is used as a covariate in downstream analysis\nBatch correction is incorporated into the data processing pipeline. Batch corrected data are used in downstream analysis.\n\nFor our code example, the data we are using represent a subset of heart data generated by the BBI after processing through Scale Biosciences’ and Parse Biosciences’ respective single-cell sequencing assays. The same samples are used in both assays - each sample had two different donors. Data were mixed together, and then genetic demultiplexing was performed.\nWe start off by calling our required packages for analysis. In this case, we are using R version 4.4.0. Refer to the following links (or the SASC GitHub page) for help with installing required packages:\n\nBioconductor Installation\nMonocle 3 Installation\nkBET Installation\nHarmony Installation\n\n\nsetwd(\"~/Documents/Developer/vsriram24.github.io/posts/sasc-workshop2\")\n\n#load required packages\nlibrary(monocle3)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(randomcoloR)\nlibrary(kBET)\nlibrary(cowplot)\nlibrary(harmony)\nlibrary(uwot)\nlibrary(batchelor)\n\n\n\n2. Reading in the data\nWith our environment ready to go, we start by reading in our input scRNA-seq data. This dataset is in the form of an S4 object, the standard format for representing sequencing data in Monocle 3. Other packages such as Seurat will have their own file formats to represent data.\n\n#Read in the cell data set containing a random sub-sampling of 35K barcodes from\nsasc &lt;- readRDS(\"BBI_heart_hs_mix_36601humangenes_35000barcodes.RDS\")\n\nWe can use the detect_genes function to count how many cells in our data are expressed above a minimum threshold.\n\nsasc &lt;- detect_genes(sasc)\n\nexpressed &lt;- data.frame(rowData(sasc)) %&gt;% \n  arrange(desc(num_cells_expressed))\n\nWe then use the n.umi attribute from the output of detect_genes to see how many unique molecular identifiers (UMIs) are in our data.\n\nsummary(sasc$n.umi)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    100     306     837    2084    2311  179927 \n\n\nLooking at the donor attribute of our data, and we see that there are numerous doublet (appearing for both donors) as well as unassigned (appearing for neither donor) UMIs in our data that may belong to either of our donors.\n\ntable(sasc$donor)\n\n\n         0          1    doublet unassigned \n     16410      14938        274       3378 \n\n\nWe are also able to see the breakdown of UMIs processed by our Parse and Scale scRNA-seq assays respectively.\n\ntable(sasc$batch)\n\n\nParse Scale \n16263 18737 \n\n\n\n\n3. Quality control\nNow that we have a breakdown of our data, we can perform quality control.\nWe start by calculating the mitochondrial DNA content in our scRNA-seq data. The presence of mitochondrial DNA (mtDNA) in our data represents low quality calls.\n\n# Search for genes with \"MT\" in their name.\nfData(sasc)$MT &lt;- grepl(\n  \"MT-\", \n  rowData(sasc)$gene_short_name\n)\n\ntable(fData(sasc)$MT)\n\n\nFALSE  TRUE \n36588    13 \n\n\nBased upon the mitochondrial DNA content we calculated, we can evaluate the percentage of mitochondrial reads in our data.\n\npData(sasc)$MT_reads &lt;- Matrix::colSums(exprs(sasc)[fData(sasc)$MT,])\npData(sasc)$MT_perc &lt;- pData(sasc)$MT_reads/Matrix::colSums(exprs(sasc))*100\n\nsummary(sasc$MT_perc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.1303  0.9560  2.8839  3.2258 61.3861       1 \n\n\nWith our calculated mitochondrial percentages, we can start to visualize our data.\nLet’s look at a plot of genes by UMIs, colored by mitochondrial percentage.\n\nggplot(\n  data.frame(pData(sasc)), \n  aes(x = n.umi, y = num_genes_expressed)) +\n  facet_wrap(~batch, nrow = 1) +\n  geom_point(size = 0.5, alpha = 0.3, aes(color = MT_perc)) +\n  theme_light() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 14),\n        axis.title = element_text(size = 16),\n        axis.text.y = element_text(size = 14),\n        aspect.ratio = 1) +\n  scale_color_viridis() +\n  xlab(\"UMIs\") +\n  ylab(\"Number of Genes Captured\") +\n  scale_y_log10() +\n  scale_x_log10() +\n  geom_abline(slope = 1, color = \"grey\") +\n  geom_hline(yintercept = 200, linetype = \"dotted\", color = \"red\") +\n  geom_vline(xintercept = 300, linetype = \"dotted\", color = \"red\")\n\n\n\n\n\n\n\n\nWe can see that in spite of the fact that our two samples were identical, different mitochondrial content are exhibited across our assays. In particular, we see a lot of noise for the UMIs that correspond to under 200 genes.\nNow let’s look at mitochondrial percentage by donor type.\n\nggplot(\n  data.frame(pData(sasc)), \n  aes(x = donor, y = MT_perc)) +\n  facet_wrap(~batch, nrow = 1, drop = TRUE, scales = \"free_x\") +\n  geom_violin(aes(fill = batch)) +\n  geom_boxplot(notch = T, fill = \"white\", width = 0.25, alpha = 0.3, outlier.shape = NA) +\n  theme_light() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 14),\n        axis.title = element_text(size = 16),\n        axis.text.y = element_text(size = 14)) +\n  xlab(\"\") +\n  ylab(\"MT %\") +\n  theme(legend.position = \"none\")\n\nNotch went outside hinges\nℹ Do you want `notch = FALSE`?\n\n\n\n\n\n\n\n\n\nWe again see differences across our assays here in terms of MT percentage - in particular, it seems like we would want to have mitochondrial percentage no greater than 10% in our data.\nNow let’s look at UMIs by donor type.\n\nggplot(\n  data.frame(pData(sasc)), \n  aes(x = donor, y = n.umi)) +\n  facet_wrap(~batch, nrow = 1, drop = TRUE, scales = \"free_x\") +\n  geom_violin(aes(fill = batch)) +\n  geom_boxplot(notch = T, fill = \"white\", width = 0.25, alpha = 0.3, outlier.shape = NA) +\n  theme_light() +\n  geom_hline(yintercept = 300, linetype = \"dashed\", color = \"blue\") + #change to thresholds\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 14),\n        axis.title = element_text(size=16),\n        axis.text.y = element_text(size = 14)) +\n  scale_y_log10() +\n  xlab(\"\") +\n  ylab(\"UMIs\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nHere, it seems like data are hard to differentiate under a certain number of UMIs (in this case, 300).\nSo, let’s establish a QC filter for our data: 300 UMIs, 200 genes, and over 10% mitochondrial content.\n\n#Let's remove everything under 300 UMIs, 200 genes, and over 10% mitochondrial percentage\nsasc$qcflag &lt;- ifelse(\n  sasc$n.umi &gt;= 300 & \n  sasc$num_genes_expressed &gt;= 200 & \n  sasc$MT_perc &lt; 10, \n  \"PASS\", \n  \"FAIL\"\n)\n\ntable(sasc$qcflag)\n\n\n FAIL  PASS \n10180 24820 \n\nsasc &lt;- sasc[,sasc$qcflag == \"PASS\"] #filter out failing barcodes\nsasc\n\nclass: cell_data_set \ndim: 36601 24820 \nmetadata(1): cds_version\nassays(1): counts\nrownames(36601): ENSG00000243485 ENSG00000237613 ... ENSG00000278817\n  ENSG00000277196\nrowData names(6): id gene_short_name ... num_cells_expressed MT\ncolnames(24820): AGGATAATCTCGGCCTTACAGGTCAGCTT 22_60_95__s4 ...\n  24_87_10__s1 20_17_34__s4\ncolData names(12): barcode n.umi ... MT_perc qcflag\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\n\n\nLet’s also remove UMIs that were mapped to the wrong genome, nonassignable to a donor, or deemed a doublet.\n\nsasc &lt;- sasc[,sasc$organism == \"human\" & sasc$donor %in% c(0, 1)]\nsasc\n\nclass: cell_data_set \ndim: 36601 24216 \nmetadata(1): cds_version\nassays(1): counts\nrownames(36601): ENSG00000243485 ENSG00000237613 ... ENSG00000278817\n  ENSG00000277196\nrowData names(6): id gene_short_name ... num_cells_expressed MT\ncolnames(24216): AGGATAATCTCGGCCTTACAGGTCAGCTT 22_60_95__s4 ...\n  24_87_10__s1 20_17_34__s4\ncolData names(12): barcode n.umi ... MT_perc qcflag\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\n\n\nFinally, we have our semi-cleaned data!\n\ntable(sasc$batch)\n\n\nParse Scale \n11474 12742 \n\ntable(sasc$batch, sasc$donor)\n\n       \n           0    1 doublet unassigned\n  Parse 8637 2837       0          0\n  Scale 4506 8236       0          0\n\n\n\n\n4. Pre-processing and data visualization\nAfter completing quality control of our data, we can start to pre-process it.\n\n# remove non-expressed/non-captured genes \nhist(fData(sasc)$num_cells_expressed)\n\n\n\n\n\n\n\n\nWe can also conduct feature selection for genes if we want. This step is not necessary in every case, but it can help with reducing computational loads. Here, we filter out genes that are not expressed in at least 25 cells.\n\ntable(fData(sasc)$num_cells_expressed &gt; 25)\n\n\nFALSE  TRUE \n15315 21286 \n\n# filter out genes not expressed in at least 25 cells\nsasc &lt;- sasc[fData(sasc)$num_cells_expressed &gt; 25, ]\nsasc \n\nclass: cell_data_set \ndim: 21286 24216 \nmetadata(1): cds_version\nassays(1): counts\nrownames(21286): ENSG00000238009 ENSG00000241860 ... ENSG00000278817\n  ENSG00000277196\nrowData names(6): id gene_short_name ... num_cells_expressed MT\ncolnames(24216): AGGATAATCTCGGCCTTACAGGTCAGCTT 22_60_95__s4 ...\n  24_87_10__s1 20_17_34__s4\ncolData names(12): barcode n.umi ... MT_perc qcflag\nreducedDimNames(0):\nmainExpName: NULL\naltExpNames(0):\n\n\nNow we apply the estimate_size_factors function from Monocle 3 to evaluate the relative bias in each cell.\n\nsasc &lt;- estimate_size_factors(sasc)\n\nAfter estimating size factors, we can run preprocess_cds, a standardized workflow in the Monocle 3 package that normalizes the data by log and size factor to address depth differences, and then calculates a lower dimensional space that will be used as the input for further dimensionality reduction.\n\nset.seed(1000)\nsasc &lt;- preprocess_cds(sasc) #this may take a few minutes\n\nWe can then call reduce_dimensions from Monocle 3 on our data to get down to the most relevant components.\n\nset.seed(1000)\nsasc &lt;- reduce_dimension(sasc) #this may take a few minutes\n\nNo preprocess_method specified, using preprocess_method = 'PCA'\n\n\nNow let’s plot the cells in our data (first colored by batch and then by donor)\n\nplot_cells(sasc, color_cells_by = \"batch\")\n\nNo trajectory to plot. Has learn_graph() been called yet?\n\n\n\n\n\n\n\n\nplot_cells(sasc, color_cells_by = \"donor\")\n\nNo trajectory to plot. Has learn_graph() been called yet?\n\n\n\n\n\n\n\n\n\nWe now have our dimensionality-reduced data! Let’s use k-means clustering to categorize our cells into clusters.\nOne can (and should) spend a lot of time tweaking their clustering parameters. In this situation, we’ll go with a k of 40 for Leiden clustering. It is advisable to try several k-values and/or resolutions during this exploratory data analysis.\n\nsasc &lt;- cluster_cells(\n  sasc, \n  k=40, \n  cluster_method=\"leiden\", \n  random_seed=1000\n) #this may take a few minutes\n\n# add cluster information for each cell\ncolData(sasc)$k40_leiden_clusters = clusters(sasc) \n\nplot_cells(sasc)\n\n\n\n\n\n\n\n\nLet’s get the top marker genes based on our Leiden clustering:\n\ntop_marker_genes &lt;- top_markers(\n  sasc, \n  group_cells_by=\"k40_leiden_clusters\"\n)\n\nkeep &lt;- top_marker_genes %&gt;%\n  filter(fraction_expressing &gt;= 0.30) %&gt;%\n  group_by(cell_group) %&gt;%\n  top_n(3, marker_score) %&gt;%\n  pull(gene_short_name) %&gt;%\n  unique()\n\n\nplot_genes_by_group(\n  sasc,\n  c(keep),\n  group_cells_by = \"k40_leiden_clusters\", #\"partition\", \"cluster\"\n  ordering_type = \"maximal_on_diag\",\n  max.size = 3\n)\n\n\n\n\n\n\n\n\nLet’s do some more data visualization here. We’ll move out of Monocle 3 and into ggplot2 to improve our flexibility with plotting.\n\n#add UMAP coordinates to the colData for easy plotting\nsasc$UMAP1 &lt;- reducedDim(sasc, \"UMAP\")[,1]\nsasc$UMAP2 &lt;- reducedDim(sasc, \"UMAP\")[,2]\n\n\n#generate a distinguishable color scheme\nset.seed(1000)\ncolpal &lt;- randomcoloR::distinctColorPalette(k=12)\n\nggplot(\n  data.frame(pData(sasc)), \n  aes(x=UMAP1, y=UMAP2, color=cell_type)) +\n  facet_wrap(~batch+donor) +\n  geom_point(size=0.5, alpha=0.5) +\n  theme_bw() +\n  scale_color_manual(values=colpal) +\n  theme(legend.position=\"bottom\", aspect.ratio = 1, panel.grid=element_blank()) +\n  guides(color = guide_legend(override.aes = list(size=8, alpha=1)))\n\n\n\n\n\n\n\n\nFrom our visualizations, clusters 2, 3, 4, and 9 all appear to be related cell types - ventricular cardiomyocytes.\nWe can also see across our four plots that we have clear evidence of both technical (batch) and biological (donor) variation!\n\n\n5. Quantifying a batch effect\nNow that we have evidence of a batch effect, let’s quantify it! We’ll make use of the kBET (k-nearest neighbor batch effect test) package from the Theis lab.\n\n#kBET - k-nearest neighbour batch effect test\ndata &lt;- reducedDim(sasc)\nbatch &lt;- sasc$batch\n\nsubset_size &lt;- 0.1 #subsample to 10% of the data for speed\nsubset_id &lt;- sample.int(\n  n = length(batch), \n  size = floor(subset_size * length(batch)), \n  replace=FALSE\n)\n\nset.seed(1000)\nbatch.estimate &lt;- kBET(\n  data[subset_id,], \n  batch[subset_id]\n) #this may take a few minutes\n\n\n\n\n\n\n\n\n\nbatch.estimate$summary\n\n      kBET.expected kBET.observed kBET.signif\nmean    0.002482853     0.9888066           0\n2.5%    0.000000000     0.9753086           0\n50%     0.002743484     0.9917695           0\n97.5%   0.006207133     1.0000000           0\n\n\nBased on our rejection rate plot, it really does seem that we have a batch effect in our data. We can simulate a random batch assignment in our data and look at the same plot to convince ourselves of this observation.\n\nset.seed(1000)\nrandombatch &lt;- sample(sasc$batch, dim(sasc)[2])\nbatch.estimate.fake &lt;- kBET(\n  data[subset_id,], \n  randombatch[subset_id]\n) #this may take a few minutes\n\n\n\n\n\n\n\n\nAlright, so we clearly do have a batch effect!\n\n\n6. Batch correction\nSince we’ve proven that we have a batch effect in our data, let’s perform batch correction using Monocle 3. We make use of the align_cds function, a wrapper built around the reducedMNN function from the batchelor package developed by the Marioni Lab at the University of Cambridge.\n\n### Batch correction built-in to Monocle3\nset.seed(1000)\nbc_cds &lt;- align_cds(\n  sasc, \n  alignment_group = \"batch\", \n  k = 50\n) #this may take a minute\n\nAligning cells from different batches using Batchelor.\nPlease remember to cite:\n     Haghverdi L, Lun ATL, Morgan MD, Marioni JC (2018). 'Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors.' Nat. Biotechnol., 36(5), 421-427. doi: 10.1038/nbt.4091\n\nbc_cds\n\nclass: cell_data_set \ndim: 21286 24216 \nmetadata(2): cds_version citations\nassays(1): counts\nrownames(21286): ENSG00000238009 ENSG00000241860 ... ENSG00000278817\n  ENSG00000277196\nrowData names(6): id gene_short_name ... num_cells_expressed MT\ncolnames(24216): AGGATAATCTCGGCCTTACAGGTCAGCTT 22_60_95__s4 ...\n  24_87_10__s1 20_17_34__s4\ncolData names(16): barcode n.umi ... UMAP1 UMAP2\nreducedDimNames(3): PCA UMAP Aligned\nmainExpName: NULL\naltExpNames(0):\n\n\nBased on our ‘aligned’ PCA, we can then call reduce_dimensions to generate a corresponding UMAP.\n\n# We can run reduce_dimensions to generate a UMAP from the 'aligned' PCA\nset.seed(1000)\nbc_cds &lt;- reduce_dimension(\n  bc_cds, \n  reduction_method = \"UMAP\", \n  preprocess_method = \"Aligned\"\n)\n\nsasc$aligned_UMAP1 &lt;- reducedDim(bc_cds, \"UMAP\")[,1] #save these in our original cds\nsasc$aligned_UMAP2 &lt;- reducedDim(bc_cds, \"UMAP\")[,2] #save these in our original cds\n\nplot_cells(bc_cds, color_cells_by = \"batch\")\n\nNo trajectory to plot. Has learn_graph() been called yet?\n\n\n\n\n\n\n\n\n\nFinally, we use kBET again to quantitatively verify that we have removed our batch effect from our data.\n\n#Use kBET to quantitatively ask if it removes the batch effect\ndata &lt;- reducedDim(bc_cds, \"UMAP\") #note that we are running this on the UMAP\nbatch &lt;- bc_cds$batch\nsubset_size &lt;- 0.1 #subsample to 10% of the data\nsubset_id &lt;- sample.int(\n  n = length(batch), \n  size = floor(subset_size * length(batch)), \n  replace = FALSE\n)\n\nset.seed(1000)\nbatch.estimate &lt;- kBET(\n  data[subset_id,], \n  batch[subset_id]\n) #this may take a few minutes\n\n\n\n\n\n\n\nbatch.estimate$summary\n\n      kBET.expected kBET.observed kBET.signif\nmean     0.02403292     0.8678189           0\n2.5%     0.01574074     0.8291152           0\n50%      0.02331962     0.8683128           0\n97.5%    0.03364198     0.9012346           0\n\n\nWhile the UMAP looks much better, the kBET metric is telling us that there is still a batch effect. If we run kBET on the ‘aligned’ PCs, the rejection rate is still close to 1. Is it possible we introduced artifacts through our batch correction? Let’s try the Harmony package from the Raychaudhuri Lab at Harvard and see if anything is different.\n\n### Batch correction with Harmony\nset.seed(1000)\nharm_cds &lt;- RunHarmony(sasc, 'batch') #this may take a few minutes\n\nTransposing data matrix\n\n\nInitializing state using k-means centroids initialization\n\n\nHarmony 1/10\n\n\nHarmony 2/10\n\n\nHarmony 3/10\n\n\nHarmony 4/10\n\n\nHarmony converged after 4 iterations\n\nharm_cds #note the \"HARMONY\" in reducedDim\n\nclass: cell_data_set \ndim: 21286 24216 \nmetadata(2): cds_version citations\nassays(1): counts\nrownames(21286): ENSG00000238009 ENSG00000241860 ... ENSG00000278817\n  ENSG00000277196\nrowData names(6): id gene_short_name ... num_cells_expressed MT\ncolnames(24216): AGGATAATCTCGGCCTTACAGGTCAGCTT 22_60_95__s4 ...\n  24_87_10__s1 20_17_34__s4\ncolData names(18): barcode n.umi ... aligned_UMAP1 aligned_UMAP2\nreducedDimNames(3): PCA UMAP HARMONY\nmainExpName: NULL\naltExpNames(0):\n\nsasc\n\nclass: cell_data_set \ndim: 21286 24216 \nmetadata(2): cds_version citations\nassays(1): counts\nrownames(21286): ENSG00000238009 ENSG00000241860 ... ENSG00000278817\n  ENSG00000277196\nrowData names(6): id gene_short_name ... num_cells_expressed MT\ncolnames(24216): AGGATAATCTCGGCCTTACAGGTCAGCTT 22_60_95__s4 ...\n  24_87_10__s1 20_17_34__s4\ncolData names(18): barcode n.umi ... aligned_UMAP1 aligned_UMAP2\nreducedDimNames(2): PCA UMAP\nmainExpName: NULL\naltExpNames(0):\n\n\n\n# Under the hood, Monocle 3 is using the uwot package to generate UMAPs\nharmony_umap &lt;- umap(reducedDim(harm_cds, \"HARMONY\"), seed=1000) #this may take a minute\nsasc$harmony_UMAP1 &lt;- harmony_umap[,1] #save these to our original cds\nsasc$harmony_UMAP2 &lt;- harmony_umap[,2] #save these to our original cds\n\n\n#Plot\nggplot(\n  data.frame(pData(sasc)), \n  aes(x = harmony_UMAP1, y = harmony_UMAP2, color = batch)) +\n  geom_point(size=0.5, alpha=0.5) +\n  theme_bw() + \n  scale_color_viridis(discrete=T, begin=0.1, end=0.9, option=\"A\") +\n  theme(legend.position=\"bottom\", aspect.ratio = 1, panel.grid=element_blank()) +\n  guides(color = guide_legend(override.aes = list(size = 8, alpha = 1)))\n\n\n\n\n\n\n\n\n\n#Use kBET to quantitatively ask\ndata &lt;- harmony_umap #note, we could alternatively run kBET at the level of the corrected PCs \nbatch &lt;- harm_cds$batch\nsubset_size &lt;- 0.1 #subsample to 10% of the data\nsubset_id &lt;- sample.int(\n  n = length(batch),\n  size = floor(subset_size * length(batch)), \n  replace = FALSE)\n\nset.seed(1000)\nbatch.estimate &lt;- kBET(data[subset_id,], batch[subset_id]) #this may take a few minutes\n\n\n\n\n\n\n\nbatch.estimate$summary\n\n      kBET.expected kBET.observed kBET.signif\nmean    0.003004115     0.8504115           0\n2.5%    0.000000000     0.8106996           0\n50%     0.002743484     0.8518519           0\n97.5%   0.008230453     0.8973251           0\n\n\nOnce again, our UMAP looks better, but our kBET metric suggests that it is still far from perfect.\nSo what benefit does batch correction offer? This is debatable, but certainly one thing it can do is help in identifying cell types. In our case, our toy dataset already had annotated cell types, but if we didn’t know these ahead of time, batch correction could help us identify them.\n\n#cluster cells that have been aligned and plot these on our original UMAP\nbc_cds &lt;- cluster_cells(\n  bc_cds, \n  k = 40, \n  cluster_method = \"leiden\", \n  random_seed = 1000\n) #this may take a few minutes\n\n\nsasc$aligned_clusters &lt;- clusters(bc_cds) #save to original cds object\nsasc$aligned_partitions &lt;- partitions(bc_cds) #save to original cds object\n\n\nggplot(\n  data.frame(pData(sasc)), \n  aes(x = UMAP1, y = UMAP2, color = k40_leiden_clusters)) +\n  geom_point(size = 0.5, alpha = 0.5) +\n  theme_bw() + \n  scale_color_manual(values = colpal) +\n  theme(legend.position = \"bottom\", aspect.ratio = 1, panel.grid = element_blank()) +\n  guides(color = guide_legend(override.aes = list(size = 8, alpha = 1)))\n\n\n\n\n\n\n\n\n\ndata.frame(colData(sasc)) %&gt;%\n  group_by(cell_type) %&gt;%\n  count(aligned_partitions) %&gt;%\n  spread(aligned_partitions, n)\n\n# A tibble: 12 × 6\n# Groups:   cell_type [12]\n   cell_type                   `1`   `2`   `3`   `4`   `5`\n   &lt;fct&gt;                     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1 Adipocyte                     1    NA    NA    63    NA\n 2 Atrial Cardiomyocyte          5    NA    NA    NA    NA\n 3 Cytoplasmic Cardiomyocyte  1368    16     3     2     3\n 4 Endothelium                2309     9   238    NA    31\n 5 Fibroblast                 2666     6     4    NA     1\n 6 Lymphocyte                  192    NA    NA    NA    NA\n 7 Macrophage                 1752     4    11    NA    NA\n 8 Neuronal                    445     4     2    NA    NA\n 9 Pericyte                    280   880     2     1    NA\n10 Unknown                    2981    71    34    15    17\n11 Vascular Smooth Muscle      116    87     1    NA    NA\n12 Ventricular Cardiomyocyte 10556    15     1    23     1\n\n\nEven with our imperfect batch correction methods, our analysis has started to show us that some of our original clusters are related (ventricular cardiomyocytes).\n\n\n7. Differential gene expression\nWe are going to focus specifically on the ventricular cardiomyocytes for the rest of this code example. We start by subsetting our data down to ventricular cardiomyocytes that belong to clusters 2, 3, 4, and 9.\n\n#combine batch and donor as a new column \nsasc$id &lt;- paste(sasc$batch, sasc$donor, sep=\"_\")\n\n#subset ventricular cardiomyocyte data only \ncds_vent &lt;- sasc[,sasc$cell_type == \"Ventricular Cardiomyocyte\" &\n                   sasc$k40_leiden_clusters %in% c(\"2\", \"3\", \"4\", \"9\")]\n\nDifferential expression analysis can take a long time, so we will run the following code on a subset of pre-defined genes.\n\ngene_list &lt;- c(\"LINC00486\", \"TTN\", \"LINC-PINT\", \"TAS2R14\", \"MT-CO1\",\n               \"MT-ND4\", \"FN1\", \"LAMA2\", \"XIST\", \"PDK4\", \"ZBTB16\",\n               \"PPP1R3E\", \"TMTC1\", \"NT5DC3\", \"RBX1\", \"MRPL45\", \"ESR2\",\n               \"TUBGCP4\", \"MYH7\", \"MYL2\", \"MB\", \"ACTC1\", \"TPM1\", \"MYH6\")\n\ncds_subset &lt;- cds_vent[rowData(cds_vent)$gene_short_name %in% gene_list,]\n\nWe now plot expression levels of these genes, split by donor.\n\nplot_genes_violin(cds_subset, group_cells_by = \"donor\", ncol = 4) +\n  theme(axis.text.x=element_text(angle = 45, hjust = 1))\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n\n\nWarning: Removed 108135 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\nWarning: Removed 108135 rows containing non-finite outside the scale range\n(`stat_summary()`).\n\n\n\n\n\n\n\n\n\nIt is clear that some of our genes are differentially expressed across our two donors. How do we tell what contribution comes from donors and what comes from assay batch? Let’s build models for our data and compare.\nIn the donor model, we assume there are no batch effects and the only contributing variable is donor.\n\ndonor_model &lt;- fit_models(\n  cds_subset,\n  model_formula_str = \"~donor\",\n  expression_family=\"negbinomial\"\n)\n\n\ncoefficient_table(donor_model) %&gt;% \n  filter(term == \"donor1\") %&gt;%\n  filter(q_value &lt; 0.05) %&gt;%\n  select(id, gene_short_name, term, q_value, estimate) %&gt;%\n  arrange(gene_short_name)\n\n# A tibble: 15 × 5\n   id              gene_short_name term     q_value estimate\n   &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 ENSG00000159251 ACTC1           donor1 5.46e-125   0.671 \n 2 ENSG00000115414 FN1             donor1 0           2.40  \n 3 ENSG00000196569 LAMA2           donor1 2.56e- 88  -0.245 \n 4 ENSG00000231721 LINC-PINT       donor1 1.67e-258  -1.91  \n 5 ENSG00000230876 LINC00486       donor1 4.42e-217   1.14  \n 6 ENSG00000198125 MB              donor1 1.38e- 55   0.463 \n 7 ENSG00000198804 MT-CO1          donor1 2.12e-214   1.23  \n 8 ENSG00000198886 MT-ND4          donor1 1.25e-170   1.13  \n 9 ENSG00000092054 MYH7            donor1 1.46e-107  -0.460 \n10 ENSG00000111245 MYL2            donor1 1.76e- 22   0.299 \n11 ENSG00000004799 PDK4            donor1 5.25e- 29  -0.165 \n12 ENSG00000212127 TAS2R14         donor1 6.18e-155  -3.80  \n13 ENSG00000155657 TTN             donor1 2.41e- 24  -0.0999\n14 ENSG00000229807 XIST            donor1 1.59e-167  -5.55  \n15 ENSG00000109906 ZBTB16          donor1 3.44e-178  -0.579 \n\n\nIn our second model, we include batch effects as a predictor variable.\n\n#controlling for batch effects\ndonor_batch_model &lt;- fit_models(\n  cds_subset,\n  model_formula_str = \"~donor + batch\",\n  expression_family=\"negbinomial\"\n)\n\n\ncoefficient_table(donor_batch_model) %&gt;% \n  filter(term == \"donor1\") %&gt;%\n  filter(q_value &lt; 0.05) %&gt;%\n  select(id, gene_short_name, term, q_value, estimate) %&gt;%\n  arrange(gene_short_name)\n\n# A tibble: 15 × 5\n   id              gene_short_name term     q_value estimate\n   &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 ENSG00000159251 ACTC1           donor1 6.11e-  6   0.165 \n 2 ENSG00000115414 FN1             donor1 2.00e-200   2.37  \n 3 ENSG00000196569 LAMA2           donor1 3.44e- 72  -0.275 \n 4 ENSG00000231721 LINC-PINT       donor1 3.45e-  2   0.228 \n 5 ENSG00000198125 MB              donor1 4.23e-  2  -0.0950\n 6 ENSG00000198804 MT-CO1          donor1 4.17e- 43   0.605 \n 7 ENSG00000198886 MT-ND4          donor1 1.48e- 21   0.422 \n 8 ENSG00000197616 MYH6            donor1 6.76e- 23   0.303 \n 9 ENSG00000092054 MYH7            donor1 7.85e- 16  -0.215 \n10 ENSG00000111245 MYL2            donor1 1.12e- 13   0.299 \n11 ENSG00000004799 PDK4            donor1 5.56e-243  -0.534 \n12 ENSG00000212127 TAS2R14         donor1 9.17e-  3  -0.527 \n13 ENSG00000155657 TTN             donor1 2.00e- 36   0.142 \n14 ENSG00000229807 XIST            donor1 1.15e-167  -5.56  \n15 ENSG00000109906 ZBTB16          donor1 3.01e-  3  -0.0961\n\n\nComparing these two models, we can see that some of our genes are significantly influenced by the introduction of batch as a predictor.\n\n# Comparing models of gene expression\ncompare_models(donor_batch_model, donor_model) %&gt;% \n  select(gene_short_name, q_value) %&gt;% \n  data.frame()\n\n   gene_short_name       q_value\n1        LINC00486  0.000000e+00\n2              TTN 4.329415e-286\n3              FN1  1.000000e+00\n4            LAMA2  1.020045e-02\n5             PDK4  0.000000e+00\n6        LINC-PINT  0.000000e+00\n7           ZBTB16 6.655693e-187\n8          TAS2R14  0.000000e+00\n9            TMTC1  2.872632e-05\n10          NT5DC3  5.740679e-02\n11            MYL2  1.000000e+00\n12         PPP1R3E  4.636225e-01\n13            MYH6  1.999277e-62\n14            MYH7  5.726891e-61\n15            ESR2  2.311010e-02\n16           ACTC1 4.529192e-170\n17         TUBGCP4  5.352325e-01\n18            TPM1  9.684985e-01\n19          MRPL45  1.000000e+00\n20              MB 4.086623e-205\n21            RBX1  1.000000e+00\n22            XIST  1.000000e+00\n23          MT-CO1 7.757731e-279\n24          MT-ND4  0.000000e+00\n\n\nLet’s take a closer look at two example genes: LINC00486 and TTN, both of which have highly significant q-values (close to 0).\n\n# Get normalized counts\ncntmtx &lt;- normalized_counts(cds_subset)\ncds_subset$LINC00486 &lt;- cntmtx[\"ENSG00000230876\",]\ncds_subset$TTN &lt;- cntmtx[\"ENSG00000155657\",]\n\n\n#the case of LINC00486\na &lt;- ggplot(\n  data.frame(pData(cds_subset)), \n  aes(x = donor, y = LINC00486)) + \n  geom_violin(aes(fill = donor)) +\n  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.3, outlier.shape = NA) +\n  theme_bw() \n\nb &lt;- ggplot(\n  data.frame(pData(cds_subset)), \n  aes(x = batch, y = LINC00486)) + \n  geom_violin(aes(fill = \"salmon\")) +\n  geom_boxplot(width=0.2, fill = \"white\", alpha = 0.3, outlier.shape = NA) +\n  theme_bw() \n\nc &lt;- ggplot(\n  data.frame(pData(cds_subset)), \n  aes(x = id, y = LINC00486, fill = donor)) + \n  geom_violin() +\n  geom_boxplot(width=0.2, fill = \"white\", alpha = 0.3, outlier.shape = NA) +\n  theme_bw() \n\nplot_grid(a + theme(legend.position = \"none\"),\n          b + theme(legend.position = \"none\") + ylab(\"\"),\n          c + theme(legend.position = \"none\") + ylab(\"\"), \n          labels=c(\"A\", \"B\", \"C\"),\n          nrow = 1)\n\n\n\n\n\n\n\n\nFrom our model, we can see that the batch variable was the primary contributor to differences in LINC00486 expression across our data.\n\ncoefficient_table(donor_model) %&gt;% \n  filter(gene_short_name == \"LINC00486\" & term ==\"donor1\") %&gt;%\n  select(id, gene_short_name, term, q_value, estimate) \n\n# A tibble: 1 × 5\n  id              gene_short_name term     q_value estimate\n  &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 ENSG00000230876 LINC00486       donor1 4.42e-217     1.14\n\ncoefficient_table(donor_batch_model) %&gt;% \n  filter(gene_short_name == \"LINC00486\" & term %in% c(\"donor1\", \"batchScale\")) %&gt;%\n  select(id, gene_short_name, term, q_value, estimate) \n\n# A tibble: 2 × 5\n  id              gene_short_name term       q_value estimate\n  &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 ENSG00000230876 LINC00486       donor1           1   0.0133\n2 ENSG00000230876 LINC00486       batchScale       0   3.64  \n\n\n\n#the case of TNN\nx &lt;- ggplot(\n  data.frame(pData(cds_subset)), \n  aes(x = donor, y = TTN)) + \n  geom_violin(aes(fill = donor)) +\n  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.3, outlier.shape = NA) +\n  theme_bw() \n\ny &lt;- ggplot(\n  data.frame(pData(cds_subset)), \n  aes(x = batch, y = TTN)) + \n  geom_violin(aes(fill = \"salmon\")) +\n  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.3, outlier.shape = NA) +\n  theme_bw() \n\nz &lt;- ggplot(\n  data.frame(pData(cds_subset)), \n  aes(x = id, y = TTN, fill = donor)) + \n  geom_violin() +\n  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.3, outlier.shape = NA) +\n  theme_bw() \n\nplot_grid(\n  x + theme(legend.position=\"none\"),\n  y + theme(legend.position=\"none\") + ylab(\"\"),\n  z + theme(legend.position=\"none\") + ylab(\"\"), \n  labels=c(\"A\", \"B\", \"C\"),\n  nrow = 1)\n\n\n\n\n\n\n\n\nOn the other hand, in the case of TTN, we see that both donor and batch affected its expression.\n\ncoefficient_table(donor_model) %&gt;% \n  filter(gene_short_name == \"TTN\" & term ==\"donor1\") %&gt;%\n  select(id, gene_short_name, term, q_value, estimate) \n\n# A tibble: 1 × 5\n  id              gene_short_name term    q_value estimate\n  &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 ENSG00000155657 TTN             donor1 2.41e-24  -0.0999\n\ncoefficient_table(donor_batch_model) %&gt;% \n  filter(gene_short_name == \"TTN\" & term %in% c(\"donor1\", \"batchScale\")) %&gt;%\n  select(id, gene_short_name, term, q_value, estimate) \n\n# A tibble: 2 × 5\n  id              gene_short_name term        q_value estimate\n  &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 ENSG00000155657 TTN             donor1     2.00e-36    0.142\n2 ENSG00000155657 TTN             batchScale 0          -0.405\n\n\n\n\n8. Key takeaways and suggestions\n\nDo not blindly apply batch correction! You risk introducing more artifacts than you remove.\nIn general, it is better to use batch correction methods for data exploration and visualization rather than analysis.\nIf you have a batch effect, model it in your downstream analysis (i.e include it as a covariate) instead of modifying your data directly.\n\n\n\n9. Conclusions\nThis concludes the content that was covered in the SASC User Group workshop on batch correction. I’d like to give a huge thank you again to Mary and the team at the BBI for organizing this tutorial and sharing it freely with the public! I look forward to covering more from these meetings in the future, as well as sharing my own thoughts and exploration of single cell data down the road."
  },
  {
    "objectID": "posts/terminologies/index.html",
    "href": "posts/terminologies/index.html",
    "title": "Biomedical Data Science sub-disciplines (v0)",
    "section": "",
    "text": "Welcome back to another week of [VS]Codes! In today’s post, I will be summarizing my personal definitions and interpretations of the various subdisciplines in biomedical data science. Given my prior background and experience in this subject area, I figured that writing this post would be an easy task! However, referencing the literature further made me realize that the boundaries across the subfields of health technology are fairly nebulous. Different departments, organizations, and individuals all have their own opinions of what their work involves. Dr. Bill Hersh from Oregon Health and Science University has a great paper (all the way back from 2009!) on the need to converge on consistent terminology in the field of biomedical informatics: you can give it a read here.\nGiven the lack of clarity in the subfields of biomedical data science, my goal today will be to provide my personal interpretation of the breakdown of relevant fields, informed by some of the definitions I’ve collated from external references. This description is absolutely meant to be a first draft of sorts (hence the v0 in the title)… I aim to refine these terms further based on additional input down the road."
  },
  {
    "objectID": "posts/terminologies/index.html#information-and-data",
    "href": "posts/terminologies/index.html#information-and-data",
    "title": "Biomedical Data Science sub-disciplines (v0)",
    "section": "Information and Data",
    "text": "Information and Data\nInformation Technology (IT)\nInformation technology (IT) refers to the use of computer systems to manage, process, protect, and exchange information. The overarching goal among its specializations is to use technology systems to solve problems and handle information. [5]\nInformation Science\nInformation science is the theoretical study of how information is created, organized, managed, stored, retrieved, and used. It is an interdisciplinary field that combines aspects of computer science and information management. [6]\nInformatics\nInformatics refers to the use and implementation of technology systems to analyze and manage information. Its primary focus is its application to specific external domains “for the good of people, organizations, and society”. [7, 8]\nData Science\nData science refers the study of data to extract meaningful insights and acquire knowledge. It is an interdisciplinary field that combines principles from a broad range of fields, including mathematics, statistics, artificial intelligence, and computer engineering, to collect, process, and analyze large amounts of data. There is a stronger focus on predictive modeling and algorithmic design. [9, 10, 11]\nData Analytics\nData analysis involves the analysis and examination of large amounts of data to better understand trends in the system being studied. There is a stronger focus on developing tables, visualizations, and overarching products to comprehend the data. [12]\nBased on the above definitions, I visualize the interplay of information and data as follows:\n\nInformation technology serves as the overarching guidebook for computational work. Within IT, information science dictates the way that we collect, store, organize, and manage our data. And finally, under both information technology and information science, data science, data analytics, and informatics intersect with one another, allowing for the development of predictive models and the analysis of data for applications to external domains."
  },
  {
    "objectID": "posts/terminologies/index.html#biomedical-informatics-and-computational-biology",
    "href": "posts/terminologies/index.html#biomedical-informatics-and-computational-biology",
    "title": "Biomedical Data Science sub-disciplines (v0)",
    "section": "Biomedical Informatics and Computational Biology",
    "text": "Biomedical Informatics and Computational Biology\nBiomedicine\nBiomedicine and the biomedical sciences refer to a set of sciences that apply understandings of biology and the natural sciences to develop knowledge, interventions, or technology that are of use in healthcare or public health. [13]\n\nBiomedical Informatics\nBiomedical Informatics\nBiomedical informatics is an interdisciplinary field seeking to study and advance the use of biomedical data to improve individual health, public health, and healthcare. It investigates, simulates, experiments with and translates a wide swath of biological systems to connect basic and clinical research with practical application for the overall betterment of healthcare. [17, 18, 19]\nBioinformatics\nBioinformatics, the application of biomedical informatics in cellular and molecular biology (often with a focus on genomics), is a scientific subdiscipline that involves using computer technology to collect, store, analyze, and disseminate biological data and information, such as DNA and amino acid sequences or annotations about those sequences, to increase our understanding of health and disease. [19, 20]\nTranslational Informatics\nTranslational informatics, the application of biomedical informatics to human health, is focused on the study and application of existing biomedical data to bridge new ways to improve diagnosis, staging, prognosis, and treatment of human disease. [19, 21]\nClinical Informatics\nClinical informatics, the subdiscipline of biomedical informatics related to patient data (typically from electronic medical records), focuses on the application of informatics to specific clinical subdisciplines, such as healthcare, nursing, dentistry, and pathology. [19, 22]\nThe subfields of biomedical informatics can be represented in the following hierarchy:\n\nBioinformatics is focused on processing the core data of biological systems, translational informatics is focused on the translation from biology to medicine, and clinical informatics is focused on the analysis of medical and healthcare data.\n\n\nComputational Biology\nComputational Biology\nComputational biology refers to the use of mathematics, statistics, and algorithms to understand biological systems based on data from experimental measurements. Examples of biological questions that may be tackled include what:\n\nbiological tasks are carried out by particular nucleic acid or peptide sequences\nwhich gene (or genes) when expressed produce a particular phenotype or behavior\nwhat sequence of changes in gene or protein expression or localization lead to a particular disease\nhow do changes in cell organization influence cell behavior. [23]\n\nComputational Genomics\nGenomics is a subfield of biomedicine focused on studying the entire set of DNA of an organism. Genomics research involves identifying and characterizing all the genes and functional elements in an organism’s genome as well as how they interact. [14, 15] Computational genomics refers to the use of computational and statistical analysis to decipher biology from genome sequences and related data, including both DNA and RNA sequence as well as other “post-genomic” data. [24]\nThe following figure shows some of the subfields of biology that can be addressed through computation. Computational genomics could be utilized in all three cases.\n\n\n\nDifferentiating biomedical informatics and computational biology\nBiomedical informatics and computational biology are very similar terms to one another - both involve the interdisciplinary application of information technology to biomedicine. The key differentiators I see between the two terms are the order of prioritization in disciplines and the nature of the data under consideration.\nIn biomedical informatics, the focus is on the development computational infrastructure and analysis to handle large-scale biomedical data.\nOn the other hand, computational biology starts with the focus on a biological experiment. From a biological question, corresponding data are generated, and computational analyses are applied.\nIndeed, I see the second word in each phrase as the “order of operations”: biomedical informatics is centered on the informatics, and computational biology is centered on the biology."
  },
  {
    "objectID": "posts/terminologies/index.html#health-technology-and-biotechnology",
    "href": "posts/terminologies/index.html#health-technology-and-biotechnology",
    "title": "Biomedical Data Science sub-disciplines (v0)",
    "section": "Health Technology and Biotechnology",
    "text": "Health Technology and Biotechnology\nHealth Technology\nHealth technology, or “health tech,” refers to the use of technologies developed for the purpose of improving any and all aspects of the healthcare system. It is focused primarily on the development of healthcare products and services. [25]\nHealth Information Technology\nHealth information technology (health IT) involves the processing, storage, and exchange of health information in an electronic environment. Applications include enhancing the quality of healthcare, preventing medical errors, reducing healthcare costs, and expanding access to healthcare. [26]\nBiotechnology\nBiotechnology (biotech) involves the use of living organisms and/or biological systems to develop or create different products [27].\nBioengineering\nBioengineering involves the application of engineering principles in combination with living organisms and/or biological systems to develop or create different products. These solutions may take the form of devices or computer programs (e.g., simulation of biomedical processes). However, the focus is on the biomedical problem to be solved, not data, information or knowledge. [28]\nDigital Health\nDigital health refers to the use of information and communications technologies in medicine and other health professions to manage illnesses and health risks and to promote wellness. [29]\nI see health technology and biotechnology as synonymous fields to one another, with health tech focused more on advancing human healthcare and biotech focused more on the use of biological systems. The incorporation of IT into health technology yields digital health and health IT, while the incorporation of engineering into biotechnology yields bioengineering."
  },
  {
    "objectID": "posts/hello-world/index.html",
    "href": "posts/hello-world/index.html",
    "title": "Hello world!",
    "section": "",
    "text": "Hello world, and welcome to my official blog! I’ve had numerous thoughts swirling around in my head over the past several years, but have had trouble formally committing to bringing them out into the world… however, encouragement from colleagues and recent reading (i.e. Dorie Clark’s The Long Game) have convinced me to finally bring my virtual pen to paper. In particular, I found myself tremendously inspired by the Fred Hutch DaSL Culture and Work Style document and the mantra of “ship as soon as you can.” The following graphic does a great job at reminding us how to avoid the pit of perfectionism!\n\nMy hopes for this blog are to (a) build a community, (b) share my knowledge, and (c) learn alongside my readers. I aim to write weekly (if not more frequent) posts on a variety of subjects, including:\n\nmy personal story\nadvice to others in my field\ntechnical tutorials\nsubject matter overviews, and\nmiscellaneous detours\n\nI have no expectations that my content will be perfect, but then again, learning from mistakes is one of the best parts of life :)\nGiven my background and expertise, my general focus will be on the world of biomedical data science and health technology, but the sky is the limit for the topics we may cover!\nThanks for tuning in - I’m delighted to have you along for the ride…"
  },
  {
    "objectID": "posts/professional-journey/index.html",
    "href": "posts/professional-journey/index.html",
    "title": "My professional journey",
    "section": "",
    "text": "For my first “real” post, I figured it would be a helpful exercise to go through my professional journey and track how I ended up where I currently am. This description is meant to be more of an overview, and I intend to provide more details on individual portions of it in the future.\n\nHaving grown up in the Silicon Valley, I always had a front-row seat to the power and potential of technology to improve people’s lives. All of the biggest tech companies had their headquarters within driving distance from my home, and every day, I could see how they had impacted not only myself but also everyone around me: computers, cellphones, social media, education, automobiles, entertainment… everything was shaped by information technology. Both of my parents were in the software industry too, and seeing the productive, fulfilling jobs that they were able to have made me certain that I wanted to involve technology in my future career. Learning how to code from my mother in high school made me feel like I was being imparted with some special kind of magic - entering the world of software engineering truly felt right at my fingertips.\nAt the same time, growing up in the Silicon Valley felt like growing up in a bubble. I yearned to explore the link between information technology and its downstream applications beyond my baseline understanding of how to write code. So, I sought out more. In high school, I took a breadth of science classes, and I found myself inspired by the concept of “interdisciplinarity”. Instead of being drawn to “information technology,” I was drawn closer and closer to the world of “information science” and its applications to multiple disciplines, including biology and medicine. My drive for interdisciplinary experiences and my desire to explore a world of technological applications outside of the Bay Area led me to Duke University for my undergraduate education - in fact, one of the mantras of the university was “creative thinking across intellectual boundaries”. At Duke, I completed double majors in Computer Science and Statistics. Duke’s affiliated medical campus also gave me chances to explore interdisciplinary applications in the world of biomedical informatics, and I pursued multiple research opportunities, including an Honor’s thesis for my Statistics degree under the supervision of Dr. Li Ma. I also completed a minor in Computational Biology, taking classes such as Computational Genomics with Dr. Alexander Hartemink and Computational Structural Biology with Dr. Bruce Donald. Lastly, I was lucky to have great summer internship mentors (including Li-Yuan Chern at Pharmacyclics and Drs. Zichen Wang and Avi Ma’ayan at the Icahn School of Medicine), who kept me motivated and inspired to stick to my path and pursue an advanced interdisciplinary career.\nBy the end of my undergrad, I knew that I wasn’t going to enter the traditional computer science recruitment cycle for software engineering roles - I instead applied to doctoral programs in biomedical informatics and computational biology that would allow me to build my knowledge base further and prepare me to become a leader in impactful projects that made a clear benefit in people’s lives. I was lucky to earn an admission with the Genomics and Computational Biology program at the University of Pennsylvania Perelman School of Medicine. Again, great mentors from my classes and research rotations (including Drs. Ryan Urbanowicz and Marylyn Ritchie to name a few) helped advance my training and made me a better researcher and scientist day by day. I am most indebted to my PhD advisor, Dr. Dokyoon Kim, for his support and mentorship throughout my PhD and subsequent post-doctoral position. With his leadership style and work ethic, he was a true role model for me throughout my graduate degree. I also fell in love with the combination of technical research and scientific storytelling that came out of my dissertation (to be discussed in a later post). During my PhD, I was able to complete a Master’s degree in Statistics and Data Science from the Wharton School of Business under the supervision of Dr. Anderson Zhang, as well as a summer internship as a User Experience Researcher in Health AI/ML under the supervision of Dr. Mandi Hall with the Health Futures team at Microsoft Research. All of these opportunities helped me to refine a set of motivators for my long-term career:\n\nimpact\nconnection\npassion\nleadership\n\nThese values aided me tremendously in my search for my first job upon the completion of my PhD. Today, I work as a clinical data scientist in the Translational Analytics and Informatics group at the Fred Hutchinson Cancer Center’s Data Science Lab (DaSL) in Seattle, WA (also to be discussed more in a future post). I am tremendously grateful to be a part of a supportive, driven community of fellow data scientists and researchers as we develop the clinical data infrastructure at Fred Hutch, and I look forward to sharing more about my work and career as the years progress!"
  },
  {
    "objectID": "posts/phd-context/index.html",
    "href": "posts/phd-context/index.html",
    "title": "My doctoral research: the background",
    "section": "",
    "text": "In the next few posts, I will be providing an overview of my PhD in Biomedical Informatics and Computational Genomics that I completed under the mentorship of Dr. Dokyoon Kim at the University of Pennsylvania Perelman School of Medicine. You can listen to a full presentation of my thesis defense here, and you can read the full text of my dissertation here. Note that all figures featured in this blog post were created using BioRender.com. Today’s post will focus on the background context that motivated my research. Without further ado, let’s get started!\n\n\nHuman biology is a complicated field. Millions of cells, cellular components, molecules, and chemicals interact with one another moment by moment to keep us alive each and every day. And while biologists and clinicians have defined a variety of classifications and ontologies to organize and understand these systems, the intricacies of the field continue to require extensive research and investment. Achieving a better understanding of human biology necessitates a unified language.\nAt the core of human biology and its defined ontologies lies the field of genetics. Genetics refers to the study of heritable traits (also known as phenotypes). If we define genetics as the language of biology, then the vocabulary of genetics would be the gene - a unit of heritable information that influences how we develop and operate. Extending the analogy further, the letters of genetics would be the nucleotide, a set of four molecules whose arrangements define different genes. Indeed, differences in individual nucleotides, also known as single-nucleotide variants/polymorphisms or “SNVs/SNPs”, are responsible for genetic variation across individuals and can lead to differing phenotypic outcomes. Genetic variation is a significant component of the diversity of life.\nGiven the complex interactions that occur across biomolecules in our bodies, it becomes apparent that networks of interacting genes drive our ability to live. Human diseases can be thought of as disruptions to these networks. The field of medicine aims to prevent, alleviate, and cure disease through the maintenance of health and the development of novel therapeutics.\nUnfortunately, for the most part, medicine today still operates from a “good enough” perspective - many patients are treated with the same medications without regard for or understanding of differences in their individual backgrounds or health profiles. Indeed, much more can be done to enhance the accuracy and efficacy of treatment.\nThe field of precision medicine uses large-scale multimodal/multiomic data to individualize patient care and gain a comprehensive understanding of human health. The goal of precision medicine is to achieve more accurate and precise disease prediction, prevention, treatment, and therapeutics. The field of genomics, involving the study of genetics from a “big data” lens, offers a significant opportunity to advance precision medicine research.\nGenomics refers to the study of an individual’s entire set of genes (a.k.a. their genome). We can work with genomic data from large-scale biomedical data, including both electronic health records (EHRs) and patient biobanks. EHRs, also known as electronic medical records (EMRs), refer to large clinical databases of patient medical history and clinical data. Biobanks, on the other hand, refer to biomedical databases with large quantities of patient biological samples, often including access to their genetic information. Combining these two data sources into a merged EHR-linked biobank provides an extra level of power in the study of genomics and medicine. EHR-linked biobanks offer the ability to identify and evaluate statistically significant genetic contributors to human disease. For instance, a genome-wide or phenome-wide association study (GWAS/PheWAS) applied to an EHR-linked biobank can identify associations between a variety of diseases and SNPs.\nMany research efforts in the field of precision medicine have used the results of PheWASs to identify genetic contributors to diseases. With such discoveries, patient genetic profiles can be built into diagnosis/treatment pipelines, allowing for the personalization of patient care.\nNotably, so far, most precision medicine research efforts that have made their way into the clinic have focused on one disease at a time. However, complex diseases rarely impact patients one-at-a-time. Shared SNPs and genes can contribute to the onset of multiple diseases in a single patient over time. These disease “multimorbidities” can lead to increase healthcare costs, health burdens, and risk of death. Thus, it becomes clear that we must evaluate the genetics of not only individual diseases but also cross-phenotype associations if we wish to gain a deeper understanding of overall patient health.\nGiven the significance of cross-phenotype associations, the field of “network medicine” offers a helpful framework to investigate the associations between diseases. Thus, the objective of my dissertation was to apply a “network medicine” approach to investigate genetic contributors to disease multimorbidities:\n\n\n\nFig 1. An overview of the process of using PheWAS results from an EHR-linked biobank for network medicine\n\n\nI broke this objective down into three chapters:\n\nCreation: construct and analyze a network of diseases derived from an EHR-linked biobank for the evaluation of genetic similarity between phenotypes\nComparison. generate and compare different disease networks generated from different populations and from genetic components.\nTranslation. extend the conclusions drawn from disease network analysis and comparison to downstream precision medicine applications.\n\n\n\n\nFig 2. The three sub-chapters of my PhD dissertation\n\n\nIn the coming week(s), I will go in-depth into the published manuscripts and preprints that correspond to these chapters, as well as my overall takeaways from my PhD research! Till next time~"
  },
  {
    "objectID": "posts/phd-papers/index.html",
    "href": "posts/phd-papers/index.html",
    "title": "My doctoral research: the content",
    "section": "",
    "text": "In last week’s post, I provided an overview of the context for my PhD research in Biomedical Informatics and Computational Genomics that I completed under the mentorship of Dr. Dokyoon Kim at the University of Pennsylvania Perelman School of Medicine. Today’s post will focus on some of the actual content that came out of my research. You can listen to a full presentation of my thesis defense here, and you can read the full text of my dissertation here. Note that all figures featured in this blog post were created using BioRender.com.\n\n\nAs discussed last week, the objective of my dissertation was to apply a network medicine approach to investigate genetic contributors to disease multimorbidities.\n\n\n\nFig 1. An overview of the process of using PheWAS results from an EHR-linked biobank for network medicine\n\n\nI broke this objective down into three chapters:\n\nCreation: construct and analyze a network of diseases derived from an EHR-linked biobank for the evaluation of genetic similarity between phenotypes\nComparison. generate and compare different disease networks generated from different populations and from genetic components.\nTranslation. extend the conclusions drawn from disease network analysis and comparison to downstream precision medicine applications.\n\n\n\n\nFig 2. The three sub-chapters of my PhD dissertation\n\n\nIn today’s post, I will provide an example manuscript from each of these chapters to provide more insight into some of the work that I did.\nChapter 1. Creation\nExample manuscript - NETMAGE: A human disease phenotype map generator for the network-based visualization of phenome-wide association study results\n\nDisease-disease networks (DDNs), graphs where nodes represent diseases and edges represent associations between diseases, can provide an intuitive way of understanding the relationships between diseases.\nUsing summary statistics from a phenome-wide association study (PheWAS), we can generate a corresponding DDN where edges represent shared genetic variants (e.g. SNPs) between diseases.\nSuch a network can help us analyze genetic associations across the “diseasome,” the landscape of all human diseases, and identify potential genetic influences for disease multimorbidities.\nTo improve the ease of network-based analysis of shared genetic components across diseases, we developed the humaN disEase phenoType MAp GEnerator (NETMAGE), a web-based tool that produces interactive DDN visualizations from PheWAS summary statistics. You can try out the tool we developed at the following link: https://hdpm.biomedinfolab.com/netmage/\n\nUsers can search their generated maps by various attributes and select nodes to view related diseases, associated variants, and various network statistics.\n\nAs a test case, we used NETMAGE to construct an example network from UK BioBank (UKBB) PheWAS summary statistic data. You can explore this network at the following link: https://hdpm.biomedinfolab.com/ddn/ukbb\n\nOur map correctly displayed previously identified disease comorbidities from the UKBB and identified concentrations of hub diseases in the endocrine/metabolic and circulatory disease categories.\n\nBy examining the associations between diseases in our map, we can identify potential genetic explanations for the relationships between diseases and better understand the underlying architecture of the human diseasome.\nYou can read the published manuscript for this project here.\n\nChapter 2. Comparison\nExample manuscript - The interplay of sex and genotype in disease associations: a comprehensive network analysis in the UK Biobank\n\nGiven that many individual diseases exhibit sex-specific differences in their genetic influences (also known as “genotype-by-sex” or “GxS” effects), we aimed to determine whether disease multimorbidities are also influenced by GxS interactions.\nThrough the comparison of sex-stratified DDNs, we investigated differences across the sexes in patterns of shared genetic architecture between diseases.\nUsing sex-stratified phenome-wide association study summary data from the UK Biobank, we built male- and female-specific DDNs for 103 different diseases.\nWe compared our networks using the network comparison methods highlighted in figure 3:\n\n\n\n\nFig 3. Overview of network comparison methods for comparing sex-stratified DDNs\n\n\n\nComparing the two graphs reveals that the diseasomes of males and females are similar to one another in terms of network topology.\n\n\n\n\nTable 1. Network statistics for our two sex-stratified DDNs\n\n\n\nSome diseases, however, seem to exhibit sex-specific influence in cross-phenotype associations. For instance, autoimmune and inflammatory disorders including multiple sclerosis and osteoarthritis are centrally involved only in the female-specific DDN, while cardiometabolic diseases and skin cancer are more prominent only in the male-specific DDN.\n\n\n\n\nTable 2. Most central diseases in our sex-stratified DDNs, based on centrality measures including degree, weighted degree, and betweenness centrality.\n\n\n\nNotably, discrepancies in embedding distances and clustering patterns across the networks imply a more expansive genetic influence on multimorbidity risk for females than males.\n\n\n\n\nFig 4. Heatmaps of edge sets across disease categories for our two sex-stratified DDNs. Brighter colors indicate more edges shared between disease categories.\n\n\n\nIn summary, our analysis affirms the presence of GxS interactions in cross-phenotype associations, emphasizing the continued need for investigation of the role of sex in disease onset and its importance in biomedical discovery and precision medicine research.\nThis manuscript is currently under review for publication.\n\nChapter 3. Translation\nExample chapter - An enhanced disease network with robust cross-phenotype relationships via variant frequency-inverse phenotype frequency.\n\nDDNs constructed from PheWAS data offer a unique ability to observe and evaluate associations between diseases from large-scale biomedical data.\nThese publications all follow a similar approach when constructing a DDN:\n\n(a) a single statistical significance level (p-value) is selected to determine associations between diseases and SNPs.\n(b) the links between diseases and SNPs are compressed into links between diseases to generate the DDN\n(c) a similarity metric such as cosine similarity is used to determine how similar two diseases are based on the number of shared associated SNPs\n\nThis process for constructing DDN seems straightforward, but it has the following limitations (see Figure 5):\n\n(a) the entire structure of the DDN can vary depending on the selection of significance level threshold in the PheWAS-driven complex relationship.\n(b) the effect of individual SNPs on the interactions across more than 2 diseases is masked\n(c) the chosen similarity metric can mask the exact amount of similarity between diseases\n\n\n\n\n\nFig 5. Overview of current approaches for constructing a DDN and their limitations.\n\n\n\nTo address the discussed limitations of previous approaches to developing DDNs, we proposed a new method inspired by natural language processing to generate networks from PheWAS data\nTaking inspiration from the NLP method “term frequency - inverse document frequency” (TF-IDF), we propose a new method we call “variant frequency - inverse phenotype frequency” (VF-IPF), which will weight the contributions of SNPs to disease associations. The outcome of this method presents itself as follows:\n\nIf a SNP is significant for only a few diseases, it is upweighted.\nIf a SNP is significant for many diseases, it is downweighted (similar to searching for the word “the” in a manuscript)\nIf a SNP is not significant for diseases, it is downweighted.\n\n\n\n\n\nFig 6. An overview of the VF-IPF algorithm\n\n\n\nTo test how the proposed method affects the way we represent cross-phenotype associations, we constructed an enhanced disease-disease network (eDDN) using UK biobank PheWAS summary statistics and tested the eDDN with three downstream tasks (see Figure 7), including:\n\nco-occurrence disease prediction when index disease of interest is given,\nnovel disease connection prediction, and\ntherapeutic drug prediction based on disease similarity.\n\n\n\n\n\n\nFig 7. Downstream tasks for the eDDN\n\n\n\nComparing our eDDN’s effectivness at predicting known disease comorbidities compared to other DDNs, we see that our eDDN has the highest AUC (i.e. it has the best performance).\n\n\n\n\nFig 8. The eDDN can predict disease comorbidities better than standard DDNs\n\n\n\nFurthermore, we see the utility of the eDDN in evaluating potential options for drug repurposing in the treatment of rheumatoid arthritis.\n\n\n\n\nFig 9. The eDDN can help with drug repurposing applications, suggesting alternative pre-existing treatments for rheumatoid arthritis.\n\n\n\nIn summary, we find that our proposed eDDN more effectively captures genetic associations between diseases from PheWAS data compared to previous approaches.\nThis manuscript is currently under review for publication.\n\n\nToday’s post was meant to give a sample of some of my work during my PhD. To read more about my currently published manuscripts, you can refer to my Google Scholar profile here.\nIn next week’s post, I will conclude this series on my PhD work with my personal takeaways from my program as well as tips for current, incoming, and aspiring PhD students, including selecting a program, selecting a thesis advisor, picking projects, and more! Until then~"
  },
  {
    "objectID": "posts/phd-takeaways/index.html",
    "href": "posts/phd-takeaways/index.html",
    "title": "My doctoral research: takeaways and advice",
    "section": "",
    "text": "In the last few posts, I have provided an overview of my PhD in Biomedical Informatics and Computational Genomics that I completed under the mentorship of Dr. Dokyoon Kim at the University of Pennsylvania Perelman School of Medicine. You can listen to a full presentation of my thesis defense here, and you can read the full text of my dissertation here. In today’s post, I will conclude this series on my doctoral research with my personal takeaways and tips for picking, pursuing, and finishing a PhD program."
  },
  {
    "objectID": "posts/phd-takeaways/index.html#why-did-i-choose-to-pursue-a-phd-after-my-undergrad",
    "href": "posts/phd-takeaways/index.html#why-did-i-choose-to-pursue-a-phd-after-my-undergrad",
    "title": "My doctoral research: takeaways and advice",
    "section": "Why did I choose to pursue a PhD after my undergrad?",
    "text": "Why did I choose to pursue a PhD after my undergrad?\nAs I explained in my previous post describing my professional journey, I’ve always wanted to be a leader in impactful projects that made a clear benefit in people’s lives. When I was an undergrad, I began to research job opportunities that I found aligned with my interests. Looking at the qualifications required for these roles, and based on further advice from colleagues and mentors in my summer internships, I realized that in order for me to be able to become a leader in an interdisicplinary field in the future, I would have to pursue education beyond my undergraduate degree. Without a Master’s or PhD, I knew that I would eventually hit a wall in my career progression.\nI knew earning a graduate degree in the future after working for some time was a completely valid option. But, I also felt that knowing my own personality, it would be harder to bring myself back to school after a few years - I would feel the pay differential more keenly, and I would have to retrain myself to become a student. So, I decided to apply for graduate programs during my senior year of college.\nI considered both Master’s and PhD programs, but in weighing the opportunity costs for the computational fields I was considering, I ended up focusing my attention on doctorate degrees. I knew that a PhD would help me transition more clearly into cutting-edge research-based career opportunities. I also ideally wanted to avoid having to pay for a Master’s degree. A PhD program, on the other hand, would support me with a stipend for the duration of the program. Finally, I knew that with a computationally-focused PhD, it would be very reasonable to aim to graduate in about five years, which would be shorter than the average timeline for a PhD in the United States.\nI applied only for PhD programs where I knew I would feel content about spending 5+ years of my time. I also applied to one Master’s program in case I didn’t get in to any PhD programs. If nothing worked out for me, my back-up plan would have been to try to find a 1-year Master’s program attached to my undergrad or look for a short-term research position so that I could gain more experience and reapply fully for Master’s programs in the following year. Luckily, PhD admissions worked out, and I found a program that fit with everything I was looking for!"
  },
  {
    "objectID": "posts/phd-takeaways/index.html#why-did-i-apply-for-bioinformatics-programs",
    "href": "posts/phd-takeaways/index.html#why-did-i-apply-for-bioinformatics-programs",
    "title": "My doctoral research: takeaways and advice",
    "section": "Why did I apply for bioinformatics programs?",
    "text": "Why did I apply for bioinformatics programs?\nI chose to apply for bioinformatics / computational biology programs based on both my interest in the field as well as my likelihood of getting into such a department. I had always been motivated by the concepts of interdisclipinary research involving informational technology. So, I knew that I wanted to pursue a graduate degree related to data science, computer science, or statistics. At the same time, focusing on the area of biomedical research felt like an untapped market to me - there was so much data to work with and so much opportunity to advance the field. My time at Duke also gave me extensive exposure to research in the biomedical informatics domain. As a result, I felt that I would be a competitive applicant for cutting-edge programs in biomedical informatics and computational biology compared to other disciplines. I also felt that even if I wanted to pivot to a career that didn’t involve biomedical applications in the future, having a computational PhD would be sufficient to qualify me for such roles."
  },
  {
    "objectID": "posts/phd-takeaways/index.html#why-did-i-pick-penn-genomics-and-computational-biology",
    "href": "posts/phd-takeaways/index.html#why-did-i-pick-penn-genomics-and-computational-biology",
    "title": "My doctoral research: takeaways and advice",
    "section": "Why did I pick Penn Genomics and Computational Biology?",
    "text": "Why did I pick Penn Genomics and Computational Biology?\nComing from a more computational background, I wanted a program that could help me catch up in topics in which I was lacking while also advancing further in my training for subjects where I already had the expertise. Penn GCB offered a very customized approach for selecting coursework, allowing me to take more foundational classes in genetics and molecular biology while pursuing more advanced curriculum in statistics and computer science.\nPenn also had multiple professors under whom I could see myself working, as well as access to interesting medical data due to its association with the University of Pennsylvania Health System.\nI also considered the happiness of students currently in the program and the livability of Philadelphia. It was apparent to me after my interview weekend that students were able to have fulfilling lives outside of their research, and that Philadelphia would be an exciting (and affordable) city for me to spend my twenties!\nLastly, I appreciated that Penn offered the opportunity to pursue a free Master’s degree in Statistics and Data Science from the Wharton School of Business concurrently with my PhD. Given my undergraduate degree in Statistics, I felt that this would be something I could more easily pursue, and that it would also give me a leg up in terms of foundational knowledge and branding in the future if I chose to pivot away from biomedical research.\n\n\n\nA view of my thinking face for all of my major life decisions during my PhD."
  },
  {
    "objectID": "posts/phd-takeaways/index.html#how-did-i-choose-my-principal-investigator-pi",
    "href": "posts/phd-takeaways/index.html#how-did-i-choose-my-principal-investigator-pi",
    "title": "My doctoral research: takeaways and advice",
    "section": "How did I choose my Principal Investigator (PI)?",
    "text": "How did I choose my Principal Investigator (PI)?\nThe highest priority for me in picking my PhD lab was finding a group whose research spoke to me. After this, there were a few pieces that led me to settle on Dr. Dokyoon Kim.\nComing directly out of my undergrad, I knew that I would need a lot of support from my PI. So, I wanted to work with a more junior professor who would have the time to help me when I needed it. I also liked the idea of being one of the first students in a new lab and marking my own path. Based on my rotation, I could tell that my PI was highly attentive, and I had plenty of face-time with him each week, as well as support from post-docs and engineers in the lab whenever I needed it.\nFurther, I appreciated that my PI had a program set up with internationally-based clinicians to stay in Philadelphia and work in the lab each year. This gave countless opportunities to learn from and collaborate with people in the medical field as well as gain deeper insight into the impact that our projects could have downstream.\nLastly, it just so happened that my rotation with my PI coincided with March 2020, the start of the full impact of the COVID-19 pandemic on the U.S. In the face of entirely remote work for an unknown amount of time, it was immediately apparent to me that my PI would be great about supporting me virtually for however long we were required to work from home."
  },
  {
    "objectID": "posts/phd-takeaways/index.html#how-did-i-choose-my-dissertation-topic",
    "href": "posts/phd-takeaways/index.html#how-did-i-choose-my-dissertation-topic",
    "title": "My doctoral research: takeaways and advice",
    "section": "How did I choose my dissertation topic?",
    "text": "How did I choose my dissertation topic?\nTo read more about the context and content of my dissertation, you can read my previous posts here and here.\nPersonally, I’ve always found that I excel the most when I am passionate about the projects I’m pursuing. It is important for me to not only see the motivators of my work, but also its downstream impact. As a result, I wanted to pursue a dissertation that felt intuitive and important.\nComing from a computational background, I did not have a disease area of interest that I had to focus on. Indeed, the biological question at hand was less important to me in my initial choice of project than its impact.\nLastly, I wanted the opportunity to familiarize myself with new types of data, to develop new computational methods and tools that could be used by the biomedical research community, and to see the translational impact of my work on people’s lives.\nMy rotation project (you can read the published manuscript for this project here) gave me an incredible view into the potential of my research trajectory at the start of my PhD. I loved how intuitive the baseline concepts of network medicine were, and I could see how it had the potential to bring together scientific storytelling aspects of data visualization with advanced technical research in graph-based machine learning. Ultimately, this dissertation topic felt like something that I could truly take full ownership of."
  },
  {
    "objectID": "posts/phd-takeaways/index.html#my-personal-phd-pros",
    "href": "posts/phd-takeaways/index.html#my-personal-phd-pros",
    "title": "My doctoral research: takeaways and advice",
    "section": "My personal PhD pros",
    "text": "My personal PhD pros\n\nI gained strong interdisciplinary expertise in my subject matter:\n\nBiomedical informatics, computational genomics, translational science\nData science, software development, statistics, machine learning\n\nI learned how to conduct independent research and lead the direction of projects\nI gained valuable experience in mentoring and teaching others\nI was able to network with many amazing colleagues both in academia and industry in my discipline\nI was able to keep making income throughout the duration of my degree\nAfter my degree, I am taken more seriously by people in my field whom I meet for the first time\nI feel tremendously prepared to take on leadership roles in exciting interdisciplinary research areas in the future"
  },
  {
    "objectID": "posts/phd-takeaways/index.html#my-personal-phd-cons",
    "href": "posts/phd-takeaways/index.html#my-personal-phd-cons",
    "title": "My doctoral research: takeaways and advice",
    "section": "My personal PhD cons",
    "text": "My personal PhD cons\n\nHaving a PhD will make the jobs that you seek more niche\n\nWhen you pursue a PhD for career advancement, you’re typically seeking a career that is beyond the norm\nBachelor’s-level (and to an extent, Master’s-level) jobs are less individually unique from one another, but they are more broadly available (e.g. software engineer)\nFinding the right type of opportunity for a PhD-level individual requires patience\n\nPursuing a PhD is a stressful experience!\n\nIt can be hard to set boundaries between your work and your personal life. There are no clear deadlines for your projects either… your work will expand to fill your time unless you set your own pace\nA lot of luck is involved in how quickly you can make progress. There are so many factors out of your control that can affect the success of your experiments and your publications\n\nThere is a financial cost to pursuing a PhD\n\nIf you can be accepted to a PhD program, then you can be accepted to a much higher-paying job in industry. It is a very personal decision regarding whether or not this drop in salary is worth it"
  },
  {
    "objectID": "posts/phd-takeaways/index.html#choosing-to-do-a-phd",
    "href": "posts/phd-takeaways/index.html#choosing-to-do-a-phd",
    "title": "My doctoral research: takeaways and advice",
    "section": "Choosing to do a PhD",
    "text": "Choosing to do a PhD\nThe biggest piece of advice I have here is… make sure you’re doing a PhD for the right reason.\n\nIt’s important to think about why you want a graduate degree in the first place… Becoming a professor? Seeking those longer-term “extraordinary” opportunities in industry? Pure academic curiosity?\n\nI know people in all three of these camps, and I think they’re all very justified reasons. There are plenty more reasons to do a PhD outside of these - everyone has their own individual biases that draw them to the experience.\n\nThere are also plenty of reasons NOT to do a PhD.\n\nThe worst reason to pursue a PhD is for the “prestige.”\n\nIf you don’t find yourself intrinsically excited about the work you’re doing at the end of the day, then stop wasting your time! It’s not worth spending so much time on something just because you want other people to think more of you.\nA caveat - this lack of intrinsic excitement is different from joining a PhD program and then experiencing lulls in your research where you’re frustrated with your progress. This latter occurrence is totally normal and quite common! At the end of the day, when the experiments work out, you’ll remember why you started your program in the first place.\n\nThe second worst reason to pursue a PhD is that you don’t know what else to do with your time.\n\nGetting a PhD is not a passive experience. You cannot just “let it happen to you.” You have to be active about seeking out opportunities, making connections with others, and progressing on your work in order to succeed.\n\nIf you find yourself in either of these camps, then I can guarantee that you will be miserable and that you will burn out.\n\nIf you want to gain more knowledge, there are plenty of more lucrative / less time-intensive ways to do so than pursuing a PhD:\n\nPursue a different type of graduate degree\nFind a job relevant to your career\nJoin a technical bootcamp\nTake individual classes / online courses\nPursue independent projects (maybe even start a blog! ;))\n\nThere will always be a tradeoff when you decide to pursue a PhD. Some doors will open and other doors will close. Think about what’s best for YOU in your life and for your career.\n\n\n\n\nMy transition from first-year student to graduate. A pandemic and a doctorate degree will make you older AND wiser!"
  },
  {
    "objectID": "posts/phd-takeaways/index.html#selecting-a-program",
    "href": "posts/phd-takeaways/index.html#selecting-a-program",
    "title": "My doctoral research: takeaways and advice",
    "section": "Selecting a program",
    "text": "Selecting a program\nI’ve discussed earlier why I personally chose to attend Penn GCB, but here are some good questions to ask yourself when selecting a PhD program to attend:\n\nDo you like the work that you’ll be doing?\n\nThis is the whole point of a PhD - to do cutting-edge work. You need to like the field you’re in and the opportunities that will be available to you\n\nIs there more than one professor with whom you could see yourself working?\n\nEven if you have a professor who has committed to taking you on, this point is important to consider. Professors are people too, and they move around universities all the time. Make sure you’re not joining a program just because of a single person - otherwise, if they leave or if you position doesn’t work out, you may find yourself scrambling to find a new professor in the middle of your PhD who may not even align with your research interests.\n\nWill you have the right level of support for your background?\n\nSome people will come with a lot of experience and need less guidance when they start their PhDs. Others will come with minimal experience and need more hand-holding.\n\nI was in this second camp - I needed lots of hand-holding for biomedical concepts, and I wanted more independence in my explorations of computer science and statistics\n\nMake sure that the program can help you up-skill as needed (i.e. through coursework, registering for conferences / workshops, connecting you with the right mentors, etc.)\n\nHow is work-life harmony handled in this program?\n\nI cannot stress this enough - you are more than your work. You will need to work hard in a PhD, but you cannot let it absorb your entire life. You will burn out if you do. A PhD is a marathon and not a sprint.\nYou won’t necessarily need an active student community, but your peers are the only people who will truly understand the day-to-day of what being a PhD student means. You’ll find that being a part of such a community can be tremendously rewarding, and that your colleagues will be a huge help in your times of need.\nYou can gauge the status of how well work boundaries are set by your program through the students you meet during interview/admit visits. Obviously a lot of your work-life balance will come down to the lab you join. But in general, are the students happy with their choice to join this program? Do they have time for things outside of their work?\n\nDo you like where will you be living?\n\nDo you like the location of the program? Can you see yourself spending 5+ years there?\nIs the place you’re living affordable given the stipend that the program offers? How are housing/rental costs in the area?\nIs it easy to get to work? If not, how often will you expect to be coming in to campus?\n\nHow does the program support career progression and what are the types of opportunities that may be available to you after graduation?\n\nWhat kinds of support systems does the program have for career development?\n\nIs there support for internships? Fellowships / grants? Travel opportunities to conferences? Mentorship / teaching opportunities? The ability to earn additional certificates / degrees?\n\nWhat do alumni from the program usually do after graduation? Where (physically) do they end up? How much did the program and/or their research focus help with finding a job?\nIn these situations, when you have an admission to a program and you’re trying to decide on it, it’s great to speak to not only current students but also alumni to get a sense for the pros and cons of the program. You may not know the right questions to ask during these informational interviews, but if the program has a good community, then they’ll be happy to help you out regardless."
  },
  {
    "objectID": "posts/phd-takeaways/index.html#selecting-a-thesis-advisor",
    "href": "posts/phd-takeaways/index.html#selecting-a-thesis-advisor",
    "title": "My doctoral research: takeaways and advice",
    "section": "Selecting a thesis advisor",
    "text": "Selecting a thesis advisor\n\nYour PhD advisor doesn’t have to be your best friend, but you should ideally have a friendly relationship with them :) Are they a nice person to work with? Do they have your best interests at heart? Or are they more concerned with using your time and work to advance the standing of their lab?\nDo you like the work that you’d be doing with this PI? It’s important that you don’t pick a lab just because you like the mentor’s personality.\nPick a PI who will lift you up rather than hold you down\n\nYou want to be challenged, but you don’t want to make life harder for yourself. Your PI is directly responsible for:\n\nthe type of research you explore\nwhen you graduate\nhow much work-life balance you have\n\nAt the end of the day, a great PI should always be your advocate!\n\nRegarding co-mentorships…\n\nCo-mentorships across two groups can be great if you have the right projects in mind and need both labs’ expertise.\nHowever, these can also go very poorly if your work aligns more with one group than the other. There’s a high likelihood that you will fall between the cracks and be stuck in your PhD for much longer than you need to be.\n\nSometimes it’ll still work out, especially if both PI’s already collaborate. But in these cases, I personally think it seems unnecessary to have both professors be your mentor. You can always have one of these professors serve on your thesis committee instead.\n\nHere’s my personal opinion… If you are coming in with less experience, I would advise picking a single PI. If you are coming in with more experience and know exactly what type of dissertation you want to work on, then you can consider multiple PIs."
  },
  {
    "objectID": "posts/phd-takeaways/index.html#picking-research-projects",
    "href": "posts/phd-takeaways/index.html#picking-research-projects",
    "title": "My doctoral research: takeaways and advice",
    "section": "Picking research projects",
    "text": "Picking research projects\n\nHere’s a big “duh” piece of advice – pick a research topic you’re excited about! Why would you spend 5+ years of your life on something that doesn’t get you excited?\nAnother point - prioritize skill-building when you can, but don’t prioritize it over progress on your dissertation.\n\nYou can up-skill in specific areas as much as you want after your PhD. If you are distracted by “side-quests,” you will take longer to graduate when you could have instead finished your degree earlier and kept progressing in your career.\n\nThink about the trade-off between your academic passions and the logistics of your work. Try to find the optimal balance across academic curiosity, skill-building, and time required for the research project.\n\nData generation will always take longer than expected. The easiest way to cut down on the time needed for your PhD is to work on projects where the data are already generated :)"
  },
  {
    "objectID": "posts/phd-takeaways/index.html#wrapping-up-your-phd",
    "href": "posts/phd-takeaways/index.html#wrapping-up-your-phd",
    "title": "My doctoral research: takeaways and advice",
    "section": "Wrapping up your PhD",
    "text": "Wrapping up your PhD\n\nIn my personal opinion, ending a PhD is an exercise in self-confidence and believing in oneself. Ultimately, completing your PhD means knowing how to advocate for yourself.\n\nThis can be easier or harder depending on your PI and your thesis committee. Some PIs / committees will be on the same page as you. They may even say themselves that it’s time for you to defend.\nOthers will not tell you they think you are ready to leave. It is up to you to justify in your committee meetings why you feel qualified to defend and graduate.\n\nHere’s my biggest indicator for when it’s time to graduate - when you no longer feel that you NEED guidance from your superiors.\n\nYou don’t need to feel that you have nothing more to learn. In fact, pursuing a PhD will teach you that you always have more to learn!\nYou don’t even have to have fulfilled all the goals of your dissertation… the aims that you come up with at the start of your disseration are somewhat arbitrary benchmarks.\nInstead… Are you able to devise a full research project concept and methodology? Can you procure the right data and follow through on the analysis? Are you able to communicate your results in a cogent, impactful manner?\n\nI hit a point toward the end of my PhD where I felt I could still keep learning and exploring, but I was coming up with all of the directions of the exploration myself. In other words, I was an independent researcher! This was my cue to wrap up and defend.\n\n\nWith that, we’ve reached the conclusion of my series on my doctoral research! If you’ve read this far, I hope you found the information I shared to be useful. The process of picking, starting, and completing a PhD is a tremendous challenge, and if you’re struggling at any point with any of the concepts I’ve covered today, feel free to reach out to me on LinkedIn or shoot me an email at vivek.sriram@gmail.com! I am always happy to chat and offer my two cents.\nAnd a last reminder… as I’ve said earlier in this post - you are not your work! Regardless of the stressors and major decisions that surround you, never forget to remember what matters most at the end of the day: your personal happiness and well-being. Make sure to take time to enjoy the little things in life, like this squirrel :)\n\n\nImage References:\n\nParamount Plus\nMemebase.com\nBusiness Insider"
  },
  {
    "objectID": "posts/karpathy-1/index.html",
    "href": "posts/karpathy-1/index.html",
    "title": "A Python introduction to neural networks and backpropagation",
    "section": "",
    "text": "This is a walkthrough of Andrej Karpathy’s video “The spelled-out intro to neural networks and backpropagation: building micrograd”. This video is the first in his YouTube series, “Neural Networks: Zero to Hero.”\n\n\n\nA screen-grab of Andrej’s video\n\n\nNeural networks are mathematical models used to represent nodes and the signals they send to one another through their links. Neural networks replicate the structure of the brain, where interconnected neurons send messages to each other through electric signals across the synpases that bridge them together. While individual nodes can perform only simple operations, many nodes connected together in a network can perform complex computational tasks.\nThe general structure of a neural network for machine learning includes three types of nodes, grouped into different “layers” within the neural network. The first set of nodes are the input nodes, corresponding to input (or training data). The second set of nodes refer to intermediate (hidden) nodes. The final type of node is the output node, corresponding to the result of processing the input data through the hidden nodes. This output layer typically comes in the form of a loss function, characterizing the difference between the output of the model and the expected output. The goal of optimizing a neural network is to minimize this output loss to best match the behavior of the input data.\n\n\n\nThe basic format of a neural network\n\n\nBackpropagation is an algorithm for supervised learning of neural networks using gradient descent. This method will calculate the gradient of each intermediate node in the network with respect to the loss function, allowing us to iteratively tune their weights to minimize the overall loss.\nIn his video tutorial, Andrej shows how to construct a neural network from scratch and perform backpropagation on it to optimize the weights of the network. The code presented in this example is a direct copy of the code walked through in the video, streamlined a bit for interpretation. Writing this blog post helped me solidify my understanding of the material (and also helped me practice writing Python code in Quarto :) ). I would highly recommend following along with this tutorial and further videos for a hands-on, ground-up exploration of neural networks and language models! I aim to work through his other tutorials in the future as well.\nWith background out of the way, let’s get started~\n```{r}\nlibrary(reticulate)\nuse_python('/opt/anaconda3/bin/python')\n```\n\n# Import required packages\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\n\nDefining functions and manually calculating derivatives\nWe can start by thinking about a simple mathematical expression to give us some intuition behind the workings of individual neurons.\nLet’s define a scalar value function f(x) that takes scalar input and returns scalar output. We can apply this function to a single value or a range of values.\n\n# e.g. scalar value function that takes scalar input and returns scalar output\ndef f(x):\n    return 3*x**2 - 4*x + 5\n\n# e.g. single value\nf(3.0)\n\n# e.g. range of values\nxs = np.arange(-5, 5, 0.25)\nys = f(xs)\nys\n\narray([100.    ,  91.6875,  83.75  ,  76.1875,  69.    ,  62.1875,\n        55.75  ,  49.6875,  44.    ,  38.6875,  33.75  ,  29.1875,\n        25.    ,  21.1875,  17.75  ,  14.6875,  12.    ,   9.6875,\n         7.75  ,   6.1875,   5.    ,   4.1875,   3.75  ,   3.6875,\n         4.    ,   4.6875,   5.75  ,   7.1875,   9.    ,  11.1875,\n        13.75  ,  16.6875,  20.    ,  23.6875,  27.75  ,  32.1875,\n        37.    ,  42.1875,  47.75  ,  53.6875])\n\n\nWe can plot the output of our function to see the association between our input and output as well.\n\nplt.plot(xs, ys)\n\n\n\n\n\n\n\n\nDetermining the derivative of f would let us identify inflection points in our data. Let’s calculate the derivative of f at 3 (i.e. f’(3)) numerically using the fundamental law of calculus:\n\\[\n\\lim_{h\\to\\infty} \\frac{f(x+h)-f(x)}{h}\n\\]\n\nh = 0.0000000001\nx = 3.0\n\n(f(x+h) - f(x))/h\n\n14.000001158365194\n\n\nNote that if our h is too small for Python, we will end up with a floating point error. With some trial and error for different values of h, we can see f’(3) = 14\nNow let’s make a function that is a little more complicated: \\[\nd(a, b, c) = a*b + c\n\\]\n\na = 2.0\nb = -3.0\nc = 10.0\nd1 = a*b + c\n\nAgain, we can calculate the derivative of d. This time, since we have three inputs, we have to pick a variable with respect to which we calculate the derivative. Let’s numerically calculate the derivative of d with respect to a.\n\nh = 0.0000001\n\n#derivative wrt a\na += h\n\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2-d1)/h)\n\nd1 4.0\nd2 3.9999997\nslope -2.9999999995311555\n\n\nWe can do the same with respect to b as well.\n\n#derivative wrt b\nb += h\na = 2.0\n\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2-d1)/h)\n\nd1 4.0\nd2 4.0000002\nslope 1.9999999967268423\n\n\nWe now have some intuition for how functions and derivatives work.\n\n\nThe ‘Value’ Class\nLet’s define a class “Value” to store the individual values that come together to make a function / mathematical expression. Each ‘Value’ can be thought of as a node in a neural network.\n\nclass Value:\n    def __init__(self, data, _children=(), _op='', label=''):\n        self.data = data\n        self.grad = 0.0\n        self._backward = lambda: None #default: nothing\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n\n    # Nicer looking way to see what the value actually is instead of an object\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n\n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data + other.data, (self, other), '+')\n        def _backward():\n            self.grad += out.grad\n            other.grad += out.grad\n        out._backward = _backward\n        return out\n\n    def __radd__(self, other): # other * self\n        return self + other\n        \n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data * other.data, (self, other), '*')\n        def _backward():\n            self.grad += other.data * out.grad\n            other.grad += self.data * out.grad\n        out._backward = _backward\n        return out\n\n    def __rmul__(self, other): # other * self\n        return self * other\n\n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x)-1)/(math.exp(2*x)+1)\n        out = Value(t, (self, ), 'tanh')\n        def _backward():\n            self.grad +=  (1 - t**2) * out.grad\n        out._backward = _backward\n        return out\n\n    def exp(self):\n        x = self.data\n        out = Value(math.exp(x), (self, ), 'exp')\n\n        def _backward():\n            self.grad += out.data * out.grad\n        out._backward = _backward\n\n        return out\n\n    def __pow__(self, other):\n        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n        out = Value(self.data**other, (self,), f'**{other}')\n\n        def _backward():\n            self.grad += other * (self.data**(other-1)) * out.grad\n        out._backward = _backward\n\n        return out\n    \n    def __truediv__(self, other): #self / other\n        return self * other**-1\n\n    def __neg__(self): # -self\n        return self * -1\n\n    def __sub__(self, other): # self - other\n        return self + (-other)\n\n    def backward(self):\n        topo = []\n        visited = set()\n        def build_topo(v):\n            if v not in visited:\n                visited.add(v)\n                for child in v._prev:\n                    build_topo(child)\n                topo.append(v)\n        \n        build_topo(self)\n        \n        # call _backward() in the right topological order\n        self.grad = 1.0\n        for node in reversed(topo):\n            node._backward()\n\nWe can see how to perform mathematical operations using our Value class:\n\na = Value(2.0)\nb = Value(4.0)\na-b\n\nValue(data=-2.0)\n\n\nNow let’s define an example function L that makes use of our Value class:\n\\[\nL(a, b, c, f) = (a*b + c)*f\n\\]\n\na = Value(2.0, label='a')\nb = Value(-3.0, label='b')\nc = Value(10.0, label='c')\ne = a*b; e.label = 'e'\nd = e + c; d.label = 'd'\nf = Value(-2.0, label = 'f')\nL = d * f; L.label = 'L'\nL\n\nValue(data=-8.0)\n\n\nBased on the code in our Value class, we are able to see for each node which nodes came before it and what the operation was to generate the current node.\n\nd._prev\nd._op\n\n'+'\n\n\nWe can also define a function ‘draw_dot’ to be able to visualize the components of our function. Here, we build out a graph using the GraphViz API. We then iterate over all nodes and create corresponding nodes and edges (including values and operations as different node types in our network).\n\nfrom graphviz import Digraph\n\ndef trace(root):\n    # builds a set of all nodes and edges in a graph\n    nodes, edges = set(), set()\n    def build(v):\n        if v not in nodes:\n            nodes.add(v)\n            for child in v._prev:\n                edges.add((child, v))\n                build(child)\n    build(root)\n    return nodes, edges\n\ndef draw_dot(root):\n    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) #LR = left to right\n\n    nodes, edges = trace(root)\n    for n in nodes:\n        uid = str(id(n))\n        # for any value in the graph, create a rectangular ('record') node for it\n        dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape = 'record')\n        if n._op:\n            # if this value is a result of some operation, create an op node for it\n            dot.node(name = uid + n._op, label = n._op)\n            # and connect this node to it\n            dot.edge(uid + n._op, uid)\n\n    for n1, n2 in edges:\n        # connect n1 to the op node of n2\n        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n\n    return dot\n\n\ndraw_dot(L)\n\n\n\n\n\n\n\n\n\n\nManual backpropagation example\nWith our basic function L now represented as a network of values and operations, let’s perform manual backpropagation.\nWe’ll start from L and work backwards, taking the derivative with respect to L at each intermediate value. This exercise is equivalent to determining the derivative of an output L with respect to the internal weights of a neural network.\n\n# Let's calculate gradient of L wrt a manually using the fundamental theorem of calculus\n# (f(x+h) - f(x))/h\ndef lol():\n    h = 0.001\n    \n    a = Value(2.0, label='a')\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label = 'f')\n    L = d * f; L.label = 'L'\n    L1 = L.data\n\n    a = Value(2.0 + h, label='a')\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label = 'f')\n    L = d * f; L.label = 'L'\n    L2 = L.data\n\n    print((L2-L1)/h)\n\n\n#dL/da\nlol()\n\n6.000000000000227\n\n\nWe can go through this entire network structure and set the gradients for each node with respect to L.\n\n#We know dL/dL = 1\nL.grad = 1\n\n\n#L = d*f\n#So dL/df = d\n#and dL/dd = f\n\nf.grad = 4.0 # this is just the value of d\nd.grad = -2.0 # this is just the value of f\n\n\n# what is dL/dc?\n# We can use dL/dd and dd/dc and apply the chain rule\n# dL / dc = (dL/dd) * (dd/dc) = -2*1 = -2\n# dL/de is the same, -2\nc.grad = -2.0 # this is just the value of d\ne.grad = -2.0 # this is just the value of f\n\n\n# dL/da = dL/de * de/da = -2*b = -2*-3 = 6\n# dL/db = dL/de * de/db = -2*a = -2*2 = -4\na.grad = 6.0 # this is just the value of d\nb.grad = -4.0 # this is just the value of f\n\n\ndraw_dot(L)\n\n\n\n\n\n\n\n\nHere is our key takeaway from this example:\nBackpropagation is just the recursive application of the chain rule backwards through the computational graph of your neural network.\n\n\nIntroducing an activation function.\nIn our previous example, we had an output L that could take on any value. Now let’s make use of the hyperbolic tangent (\\(tanh\\)) activation function to limit our output to a range of -1 to 1.\n\\(Tanh\\) looks as follows:\n\n#Squashing/activation function - tan(h)\nplt.plot(np.arange(-5,5,0.2), np.tanh(np.arange(-5,5,0.2)));\nplt.grid();\n\n\n\n\n\n\n\n\nLet’s define a new function \\(o = tanh(x1*w1 + x2*w2 + b)\\)\n\n# inputs x1, x2\nx1 = Value(2.0, label = 'x1')\nx2 = Value(0.0, label = 'x2')\n\n# weights w1, w2\nw1 = Value(-3.0, label = 'w1')\nw2 = Value(1.0, label = 'w2')\n\n# bias of the neuron (crazy bias makes clean output in this example)\nb = Value (6.881373587019542, label = 'b')\n\n#x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\n\nx1w1x2w2 = x1w1 + x2w2;\nx1w1x2w2.label = 'x1*w1 + x2*w2'\n\n# n is our cell body activation without the activation function\nn = x1w1x2w2 + b;\nn.label = 'n'\n\n# Apply activation function (defined in Value class earlier)\no = n.tanh(); o.label = 'o'\n\nHere is the network that represents the function we just defined:\n\ndraw_dot(o)\n\n\n\n\n\n\n\n\nWe care most about the derivative of o with respect to the weights w1 and w2. In a normal neural network, we would have many more input and intermediate nodes (not just the two as in this example). We will calculate the gradients for this network by hand.\n\no.grad = 1.0\n\n# o = tanh(n)\n# do/dn = 1-tanh^2(n) = 1 - o^2\nn.grad = 1-o.data**2\n\n# do/db = do/dn * dn/db = (1-o^2)*1 = 1-o^2\n# d(x1w1x2w2)/db = do/dn * dn/d(x1w1x2w2) = (1-o^2)*1 = 1-o^2\nx1w1x2w2.grad = 1-o.data**2\nb.grad = 1-o.data**2\n\n# same logic of back-propagation wrt '+'\nx1w1.grad = 1-o.data**2\nx2w2.grad = 1-o.data**2\n\n#do/dx2 = w2 * do/d(x2w2)\nx2.grad = w2.data * x2w2.grad\n#do/dw2 = x2 * do/d/(x2w2)\nw2.grad = x2.data * x2w2.grad\n\n# same logic as for x2/w2\nx1.grad = w1.data * x1w1.grad\nw1.grad = x1.data * x1w1.grad\n\n\ndraw_dot(o)\n\n\n\n\n\n\n\n\nSo, because w1’s gradient is positive, if we want this neuron’s output to increase, then we should increase w1. w2 doesn’t affect the output of this function because its gradient is 0.\n\n\nAutomating backpropagation\nLet’s stop doing this back-propagation manually! Take a look at the logic for _backward and backwardin the Value class to see how we handle this (we apply a topological sort to our data in the backward function). We also ensure that we never call _backward on a node before we’ve called it on its children. Lastly, we make sure that we accumulate gradients in the backward function.\n\no.grad = 1.0\n\no._backward()\nn._backward()\nb._backward()\nx1w1x2w2._backward()\nx2w2._backward()\nx1w1._backward()\n\n\ndraw_dot(o)\n\n\n\n\n\n\n\n\n\no.backward()\ndraw_dot(o)\n\n\n\n\n\n\n\n\n\na = Value(3.0, label = 'a')\nb = a+a; b.label = 'b'\nb.backward()\ndraw_dot(b)\n\n\n\n\n\n\n\n\nEverything works! Yay!\n\n\nBreaking up tanh into its individual components\nInstead of using a \\(tanh\\) function in our Value class, we can break it up into exponent and division functions to see an example of a more complicated network.\n\n# inputs x1, x2\nx1 = Value(2.0, label = 'x1')\nx2 = Value(0.0, label = 'x2')\n\n# weights w1, w2\nw1 = Value(-3.0, label = 'w1')\nw2 = Value(1.0, label = 'w2')\n\n# bias of the neuron\nb = Value (6.881373587019542, label = 'b')\n\n#x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\n\nx1w1x2w2 = x1w1 + x2w2;\nx1w1x2w2.label = 'x1*w1 + x2*w2'\n\n# n is our cell body activation without the activation function\nn = x1w1x2w2 + b;\nn.label = 'n'\n\n# Apply activation function (defined in Value class earlier)\ne = (2*n).exp()\no = (e-1)/(e+1)\no.label = 'o'\no.backward()\n\n\ndraw_dot(o)\n\n\n\n\n\n\n\n\nAs we can see, even after breaking our tanh function into its individual components, our forward and backward passes are still correct! Note that the level at which you perform your individual operations is entirely up to you (e.g. tanh vs. its individual components). All that matters is that you have input and output and that you can do forward/backward passing of your operations.\n\n\nBackpropagation with PyTorch\nNow that we’ve developed backpropagation manually, let’s see how it can be performed in PyTorch. With PyTorch, everything is based around tensors rather than scalars.\n\nimport torch\n\n# Cast to double to get 64bit precision\nx1 = torch.Tensor([2.0]).double()\n# by default, pytorch will say leaf nodes don't have gradients to improve efficiency\nx1.requires_grad = True\n\nx2 = torch.Tensor([0.0]).double()\nx2.requires_grad = True\n\nw1 = torch.Tensor([-3.0]).double()\nw1.requires_grad = True\n\nw2 = torch.Tensor([1.0]).double()\nw2.requires_grad = True\n\nb = torch.Tensor([6.8813735870195432]).double()\nb.requires_grad = True\n\nn = x1*w1 + x2*w2 + b\no = torch.tanh(n)\n\n# PyTorch tensors have data and grad elements\nprint(o.data.item())\n# PyTorch has a backward function too\no.backward()\n\nprint('---')\nprint('x2', x2.grad.item())\nprint('w2', w2.grad.item())\nprint('x1', x1.grad.item())\nprint('w1', w1.grad.item())\n\n0.7071066904050358\n---\nx2 0.5000001283844369\nw2 0.0\nx1 -1.5000003851533106\nw1 1.0000002567688737\n\n\nPyTorch makes all of our calculations much more efficient. We can do all of these operations in parallel with very large tensors and not just scalar values.\n\n\nA simple neural network\nWe’ve had enough fun with “neural network adjacent” mathematical expressions and their corresponding computational topologies.\nLet’s implement a simple neural network. We will base this off of a multilayer perceptron (MLP). We can define a Neuron class, Layer class, and MLP class for our network.\nA typical neural network neuron looks like the following:\n\n\n\nA typical neuron in a neural network\n\n\n\nclass Neuron:\n    def __init__(self, nin):\n        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n        self.b = Value(random.uniform(-1,1))\n        \n    # Python goes to __call__ when you use the class as a function\n    def __call__(self, x):\n        # w.x + b\n        # start with self.b, add the dot product of w and x\n        act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b)\n        out = act.tanh()\n        return out\n\n    def parameters(self):\n        return self.w + [self.b]\n\n\nclass Layer:\n    # nout is the size of the output of the layer\n    def __init__(self, nin, nout):\n        self.neurons = [Neuron(nin) for _ in range(nout)]\n\n    def __call__(self, x):\n        outs = [n(x) for n in self.neurons]\n        return outs[0] if len(outs) == 1 else outs\n\n    def parameters(self):\n        params = []\n        for neuron in self.neurons:\n            ps = neuron.parameters()\n            params.extend(ps)\n        return params\n        \n        # Same as:\n        # return [p for neuron in self.neurons for p in neuron.parameters()]\n\n\nclass MLP:\n    # nouts is the list of layer sizes we want\n    def __init__(self, nin, nouts):\n        sz = [nin] + nouts\n        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n\n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n\n    def parameters(self):\n        return [p for layer in self.layers for p in layer.parameters()]\n\nBased upon our defined classes, let’s initialize our MLP.\n\nx = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n\nValue(data=0.4944649312890593)\n\n\n\ndraw_dot(n(x))\n\n\n\n\n\n\n\n\nWow, our function is much crazier than our initial examples! Obviously we’re never going to manually backpropagate such an example… let’s have PyTorch do it for us.\nWe start by defining some sample input data and our desired targets. We then use our baseline MLP to calculate model outputs from the input data.\n\n# Example data\nxs = [\n    [2.0, 3.0, -1.0],\n    [3.0, -1.0, 0.5],\n    [0.5, 1.0, 1.0],\n    [1.0, 1.0, -1.0]\n]\n\nys = [1.0, -1.0, -1.0, 1.0] #desired targets\n\n# Apply our MLP to predict y from x\nypred = [n(x) for x in xs]\nypred\n\n[Value(data=0.4944649312890593),\n Value(data=0.40977958134154474),\n Value(data=-0.4050151100259451),\n Value(data=0.3923524132012742)]\n\n\nWe can compare our model outputs to the expected outputs using a loss function such as mean squared error (MSE).\n\n# loss will measure how good our neural net is\n# let's do mean squared error\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n\nValue(data=2.96628678270387)\n\n\nNow let’s backpropagate (automatically this time)!\n\nloss.backward()\n\nIf the gradient of a weight is positive, then decreasing the weight will decrease the overall loss. Similarly, if the gradient is negative, then increasing the weight will decrease the loss.\n\n# If this gradient is positive, then decreasing this weight will decrease our loss\n# If this is negative, then increasing this weight will decrease our loss\nn.layers[0].neurons[0].w[0].grad\n\n-1.2640701291368466\n\n\n\nn.layers[0].neurons[0].w[0].data\n\n-0.9567063145203327\n\n\nFor every parameter in our neural network, let’s change the weights slightly to reduce the overall loss. We increase the weight for negative gradients and decrease the weight for positive gradients.\n\n# for every parameter in our neural net, let's change the weights slightly to reduce the loss\n# increase for negative grad, decrease for positive grad\nfor p in n.parameters():\n    p.data += -0.01*p.grad\n\nOur overall loss should have gone down a bit now. Let’s recalculate it.\n\nypred = [n(x) for x in xs]\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n\nValue(data=2.6726876872891854)\n\n\n\n# Propagate\nloss.backward()\n\n\nypred\n\n[Value(data=0.4993403271200778),\n Value(data=0.3198034181833698),\n Value(data=-0.45493607758790167),\n Value(data=0.38108818311718595)]\n\n\nNice, we’re able to train our data better now. Let’s formalize this process of updating gradients in a loop. This is the same thing as “stochastic gradient descent”.\n\n# Reset the neural net\nx = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n\nValue(data=0.34934876482956906)\n\n\n\n# Initialize input data and desired targets\nxs = [\n    [2.0, 3.0, -1.0],\n    [3.0, -1.0, 0.5],\n    [0.5, 1.0, 1.0],\n    [1.0, 1.0, -1.0]\n]\n\nys = [1.0, -1.0, -1.0, 1.0]\n\n\n# 20 iterations\nfor k in range(20):\n    # forward pass\n    ypred = [n(x) for x in xs]\n    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n\n    # backward pass\n    for p in n.parameters():\n        p.grad = 0.0\n    loss.backward()\n\n    # update\n    # \"stochastic gradient descent\"\n    for p in n.parameters():\n        p.data += -0.05 * p.grad\n\n    print(k, loss.data)\n\n0 8.493929671336291\n1 6.992068662805386\n2 5.769077247651545\n3 4.4735019295768295\n4 3.989548688723282\n5 3.7147609186944743\n6 3.405667943207894\n7 2.8620742530053116\n8 1.7745806845463523\n9 0.7698861574003086\n10 0.4457449169022083\n11 0.30780024751796564\n12 0.23273878356815986\n13 0.18590290331973824\n14 0.15408948967655905\n15 0.13116783996889828\n16 0.11392081179247492\n17 0.10050481438071963\n18 0.08979065153648244\n19 0.08104964070586138\n\n\n\nypred\n\n[Value(data=0.9034116586940597),\n Value(data=-0.9567970932148172),\n Value(data=-0.8069423147548922),\n Value(data=0.8194935678632469)]\n\n\nTa-da! We now understand the intuition behind developing simple neural networks and performing backpropagation to improve their predictive performance!\n\n\nTakeaways and summary\nNeural nets are simple mathematical expressions that take input data and weights. Working with neural networks involves a forward pass of input data followed by the application of a loss function.\nThe goal of a neural network for machine learning is to minimize the output loss to get the model to better predict desired targets. Backpropagation can be applied from the loss function to determine the gradients of the intermediate weights of the network. We can then tune the weights of these nodes against the gradient (i.e. gradient descent) to improve the predictive performance of the model.\nSimulating a blob of neural tissue in this manner can handle all sorts of interesting problems. Generative Pre-trained Transformers (GPTs) uses massive amounts of text from the internet and then predict the next words in a sentence based on context. These are really just fancy neural networks with hundreds of billions of parameters. Different models may use different loss functions and different methods for gradient descent, but the underlying concepts are all consistent.\nThis concludes my walkthrough of Andrej’s first neural networks video tutorial. Until next time, [VS]Coders!"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching and Mentorship",
    "section": "",
    "text": "Teaching\n\nTeaching Assistant – “Introduction to R”, 2024 to Present\n\nFred Hutchinson Cancer Center Data Science Lab, Seattle, WA\n\nGuest Lecturer – “Databases and Data Integration”, 2024 to Present\n\nUniversity of Pennsylvania Department of Biostatistics, Epidemiology, and Informatics, Philadelphia, PA\n\nVolunteer teacher and instructor, 2019 to 2023\n\nScience Education Academy outreach program, Philadelphia, PA\n\nGraduate Teaching Assistant – “Databases and Data Integration”, 2022 to 2023\n\nUniversity of Pennsylvania Department of Biostatistics, Epidemiology, and Informatics, Philadelphia, PA\n\nGraduate Tutor – “Machine Learning”, 2022\n\nUniversity of Pennsylvania Department of Computer and Information Science, Philadelphia, PA\n\nGraduate Mentor and Lecturer - “Summer Computational Biology Preview”, Summer 2021\n\nUniversity of Pennsylvania Genomics and Computational Biology Graduate Group, Philadelphia, PA\n\nGraduate Teaching Assistant - Python Bootcamp, Summer 2020\n\nUniversity of Pennsylvania Genomics and Computational Biology Graduate Group, Philadelphia, PA\n\nUndergraduate Teaching Assistant – “Intro to Computational Genomics”, 2017 to 2018\n\nDuke University Department of Computer Science, Durham, NC\n\n\nMentorship\n\nRotation Advisor for Alexis Garófalo, UPenn GCB PhD Student (2022)\nRotation Advisor for Jakob Woerner, UPenn GCB PhD Student (2021)\nRotation Advisor for Anni Moore, UPenn GCB PhD Student (2021)"
  },
  {
    "objectID": "conferences.html",
    "href": "conferences.html",
    "title": "Presentations and Talks",
    "section": "",
    "text": "Talks\n\n2023 - Public Thesis Defense, University of Pennsylvania Genomics and Computational Biology Graduate Group\n\n“Dissecting the genetic architecture of disease multimorbidities through the graph-based analysis of EHR-linked biobanks”\n\n2023 - Invited Speaker, University of Pennsylvania Institution for Biomedical Informatics Annual Retreat\n\n“From network medicine to precision medicine: AI methods for the investigation of genetic contributors to disease multimorbidities”\n\n\nPresentations\n\n2023 - Poster Presenter, American Society for Human Genetics Annual Conference\n\n“The interplay of sex and genotype in disease associations: a comprehensive network analysis in the UK Biobank”\n\n2022 - Poster Presenter (Reviewer’s Choice), American Society for Human Genetics Annual Conference\n\n“A genetic correlation disease-disease network (gcDDN) for the improved identification of novel phenotype relationships”\n\n2021 - Poster Presenter, Mid-Atlantic Bioinformatics Conference\n\n“Polygenic Score Pipeline (PiPn): a Toolkit for Automated Polygenic Score Analysis using the PGS Catalog”\n\n2021 - Poster Presenter, American Society for Human Genetics Annual Conference\n\n“The identification of comorbidity risk via disease-disease network: an application to pre-eclamptic women in the UK Biobank”\n\n2020 - Poster Presenter, American Society for Human Genetics Annual Conference\n\n“NETMAGE: a human disease phenotype map generator for the visualization of phenome-wide association study results”"
  },
  {
    "objectID": "posts/podcasts/index.html",
    "href": "posts/podcasts/index.html",
    "title": "My podcast recommendations",
    "section": "",
    "text": "Welcome back to another edition of [VS]Codes! In this week’s post, I’ll be summarizing a list of my top podcasts, including content that covers the biomedical informatics and digital health space, statistics and data science, and a couple of miscellaneous topics as well. Without further ado, let’s get started!\n\n\nBiomedicine / Health AI\n\nThe AI Health Podcast, hosted by Pranav Rajpurkar and Adriel Saporta\n“The AI Health Podcast” was my first foray into the realm of podcasts covering technical topics - with the demands of my doctoral research and my limited time, I was finding it challenging to keep up with the plethora of advances that were concurrently occurring in medicine with the expanded use of AI. Pranav and Adriel do a great job of synthesizing complex topics across the field of health AI, explaining both the biomedical context as well as the impact of the methodologies being developed. I appreciate how each episode is separated into a section covering the context of the topic followed by an interview with an expert. The experts interviewed also come from a variety of backgrounds in both academia and industry, offering diverse perspectives on artificial intelligence and biomedicine.\nGround Truths, hosted by Eric Topol\nEric Topol is a giant in the field cardiovascular medicine, At the same time, he is a keen proponent of expanding the applications of AI to medicine. In this podcast, he interviews leading experts on a variety of topics in biomedicine and health science. I appreciate how the pace of his discussions synthesizes complex areas into very digestible conversations, and I don’t think any other host has the same ability as Eric to bring such esteemed guests to the table so easily!\nThe Pulse, hosted by Wharton Digital Health\nI learned about “The Pulse” from other Wharton students while I was at the University of Pennsylvania. This podcast is a great way to gain a broad perspective of the field of health technology from a commercial perspective - the companies and interviews vary tremendously from episode to episode, and I found these episodes particularly helpful while I was in academia and looking to learn more about opportunities in the health technology space in industry. Given that the series comes from the Wharton School, there is a focus in some episodes on the business / MBA side of health tech, but much of the content is still relevant to broad audiences looking to learn more about the landscape of the field.\n\nData Science / Statistics\n\nThe Data Chief, hosted by Cindi Howson\nHow does one become a “Chief Data Officer”? What does it take to manage the data infrastructure of an organization? How does one continue to support a culture of innovation and progress from such a high-level position? “The Data Chief” answers these questions and more through interviews with leaders across a variety of industries. I appreciate how this podcast exposes listeners to the importance of well-maintained data ecosystems across practically any application area one can think of.\nCasual Inference, hosted by Lucy D’Agostino McGowan and Ellie Murray\nA play on the field of “causal inference,” this podcast covers a variety of topics in epidemiology, statistics, data science, causal inference, and public health. I am a big fan of the hosts’ mantra of “keeping it casual” by requiring guests to explain their subject matter expertise as simply as they can!\nBuild a Career in Data Science, hosted by Jacqueline Nolis and Emily Robinson\nThis podcast serves as an accompaniment to Jacqueline and Emily’s amazing book “Build a Career in Data Science,” but there is absolutely no need to have read the book to follow along! Jacqueline and Emily spend each episode on a chapter from their book, covering practical advice for how to succeed in the data science industry. Topics include how to interview for a data science job, how to communicate with stakeholders, how to pick the right position for you, and more!\nNot So Standard Deviations, hosted by Roger Peng and Hilary Parker\nAs I transitioned from the biomedical focus of my dissertation research to broader data science applications, I wanted to find a podcast that could expose me to the gamut of statistics, machine learning, data science. “Not So Standard Deviations” fits this bill to a tee, including discussions of topics in both data science and tech while making time for fun tangents and detours depending on the news of the day.\n\nMiscellaneous\n\nThe Happiness Lab, hosted by Laurie Santos\nLaurie Santos is a professor of psychology at Yale and has spent her career studying the evolutionary origins of human cognition and the science of happiness. In this podcast, she considers a variety of questions in the happiness space using a science-based approach, interviewing a plethora of guests across the field of human cognition. I’ve found the way I think about how I approach each of my days has notably shifted since finding this podcast!\n“Factually!”, hosted by Adam Conover\nI first learned about Adam Conover from watching his television show “Adam Ruins Everything,” where he reveals hidden truths about a variety of topics that are commonly misunderstood by the public using a comedic lens. “Factually!” continues this tradition of irreverently diving deeper through interviews with experts that cover every topic imaginable, whether it be the ethics of artificial intelligence or “your houseplants can think!”\n\n\nThis concludes my blog post for today. Until next week!"
  },
  {
    "objectID": "posts/cascadia-conf-24/index.html",
    "href": "posts/cascadia-conf-24/index.html",
    "title": "Cascadia R Conference 2024",
    "section": "",
    "text": "Welcome back to another week of [VS]Codes! A few weeks ago, I had the opportunity to attend Cascadia R Conference 2024, a local R conference for the data science community of the Pacific Northwest. It was a great experience getting to see so many different applications of data science across a variety of industries, and I very much enjoyed the experience of connecting with other data scientists from the surrounding PNW area. This blog post will summarize content from some of the talks that I attended that day as well as my personal overall takeaways from the conference.\n\n\n\nKeynote: “Why is everybody talking about Generative AI?,” by Deepsha Menghani from Microsoft\nGenerative Artificial Intelligence (GenAI) is a type of artificial intelligence that can create new content based on the patterns it has learned from existing day. GenAI can be trained through human intervention - a human can reinforce what behavior is correct and what isn’t. GenAI can be very powerful when you make it work for you.\nWe can break GenAI use cases into three different scenarios:\n\nDirect\nCustomized\nCommercial\n\nIn a direct scenario, a prompt leads directly to a response.\nIn a customized scenario, a prompt will lead to data, which will then lead to a response.\nLastly, in a commercial scenario, a prompt will lead to decision making, leading to data, then to actions, then to an outcome, then to feedback, and back to decision making. This will be an iterative process.\nWith this framework of GenAI scenarios, we can see how GenAI might operate across different fields.\n\nGenAI scenarios for different fields\n\n\n\n\n\n\n\n\nField\nDirect\nCustomized\nCommercial\n\n\n\n\nFinance\nFinancial literacy\nBudget and tax optimization\nFraud detection\n\n\nHealthcare\nDeveloping a general health routine\nPersonalized fitness / health data summaries\nMedical image processing\n\n\nEducation\nGeneral conceptual explanations\nPersonalized study plans\nReasoning and content generation (e.g. Khanmigo bot - a safe space to converse while learning)\n\n\nYou!\nCode assistance / copilot (e.g. turning comments into code or synthetic data generation)\nREADME / documentation generation. Return a consistent README / documentation structure\nShiny application support bot. Feed documentation into a bot that sits at the bottom of your web app. This bot can help users when they want to use your dashboard.\n\n\n\nGenAI has many pros and cons to consider:\n\n“The Good, The Bad, and The Ugly” of GenAI\n\n\n\n\n\n\n\nThe Good\nThe Bad\nThe Ugly\n\n\n\n\nKnowledge accessibility\nGarbage in = garbage out\nBias\n\n\nPersonalization\nData Privacy\nResource Intensive\n\n\nCreativity\nDependencies\nCost\n\n\nEfficiency\nHallucinations\nEthics\n\n\n\nMisinformation\nEvolving Regulations\n\n\n\nGenAI can be incredibly useful in commercial settings if you train it on an application that you’ve developed so that it can help users navigate the application. However, this means it’s more important than ever before to have good, comprehensive documentation, because this will be the training data for your GenAI model!\nA caveat to using GenAI - when you have a hammer, everything looks like a nail! Don’t fall into the trap of thinking that GenAI is the only tool you can use… remember to think about the impact that you want!\nQuestions:\n\nHow do you pick the right LLM for your purposes?\n\nGo with accessibility, cost, data privacy\n\nHow do you evaluate the output of an LLM?\n\nEvaluation is such an evolving field. Different models can check for different things (e.g. no swear words). Human evaluation also\n\nWhat is the impact on jobs of data scientists?\n\nPeople who use AI to advance their work will do better. There will be an up-leveling from nitty-gritty work to strategic oversight. Some jobs will become more impactful through the introduction of AI. Other jobs may not find AI to be useful. Employers should train their employees in terms of how they can best apply AI in their jobs.\n\n\n\n\n“R Workflows in Azure Machine Learning for Athletic Data Analysis,” by Emily Kraschel from the University of Oregon\nWhen working with data related to sports, you need to work fast. Data collection is live, and will need to be evaluated over a variety of timescales, from daily to weekly to even longer. Sports analytics work requires efficient storage, as well as a combination of basic analysis and reporting as well as more complicated decision making.\nThis fast space of sports analytics stands in high contrast to the slow work of data science, which generally involves extensive data cleaning, the development of in-depth reports and aggregation, and advanced data analysis.\nThe conflicting needs of data science and sports analytics are thus as follows: - data are changing constantly. There are many new versions of the data and many additions to existing data - data science in general comes with numerous bottlenecks and stopping points - sports data is inherently observational, resulting in an inability to perform controlled experimentation\nThe old framework implemented by the team at the University of Oregon focused on automated reports generated from a data analysis dashboard. This process was good for a fast pace of work, but hindered slower, more complicated analysis. It was challenging to take a step back and decide on new metrics that could be incorporated into the dashboard. There was no central source for raw data, resulting in a variety of athlete IDs coming from different instrument interfaces. Furthermore, with the lack of centrality in the infrastructure of the system, data would exist in different versions, different places, and different file formats. The team was left with a clunky system if they tried to pull data out of the dashboard to perform further, more in-depth analysis.\nThus, the goals of the new framework were as follows: - improve competition outcomes through the generation of more complete, valid, actionable data - lower the barriers to more complex data science and analytics - aggregate the data in a centralized location and unify athlete IDs across instrumentation sources - enhance compute power and the ability to collaborate - reduce bottlenecks in data analysis (e.g. duplication, updates, incomplete data, etc.)\nWith these goals in mind, the team decided to migrate their data infrastructure to the cloud with Azure ML. Services that they have begun to take advantage of include: - analysis in Jupyter notebooks - configurable compute - services for pipeline development and implementation - improved data storage and loading - enhanced data security\nThe team still has an automated dashboard for day-to-day analysis. However, the new platform improves their ability to perform slow work, letting them step back from the constant stream of data. Now they can pull data easily across all instrument APIs into a centralized storage point. They are able to merge data more easily, maintain the most recent version of a given dataset, and perform compute more quickly.\nWith this new cloud-based infrastructure, the team is able to perform a variety of more complicated analysis in R, including developing prediction models for hamstring injuries through the application of discrete time survival models, or evaluating differences in jump height by rate of force development across genders.\n\n\n“Fair Machine Learning,” by Simon Couch from Posit PBC\nWhat does it mean for a model to be good vs. a model to be fair? A good model will produce a high value of sensitivity, specificity, or accuracy, all depending on the metric that you choose. Fairness, on the other hand, is not just about statistical behavior. Fairness is about our beliefs. We can think of fairness as the translation of values into mathematical measures.\nIn general, definitions of fairness are not mathematically or morally compatible (see Mitchel et al. 2021). Metrics such as R2 and AUC are useful for evaluating a model, but at the end of the day, a model is just a single part of a larger system. It is important to think about how model predictions will be used at the end of the day.\nThe hard part of this process is articulating what fairness means to you (or your stakeholders) in the context of a problem. Then, you need to choose a mathematical measure of fairness that speaks to that meaning - this should situate the resulting measure in the context of the entire system.\nChoose tools that help you think about the hard parts of fair ML. The {tidymodels} set of packages, including {rsample}, {recipes}, {parsnip}, {tune}, and {yardstick}, are a great set of software options to support fair machine learning. You can refer to the textbook Tidy Modeling with R or tidymodels.org for more information on how to use these tools.\nQuestions:\n\nWhat is a structured way to get stakeholders involved?\n\nModel cards are a great option. These are just a couple of paragraphs that provide context for how the data were initially generated and various techniques used to model the data. Model cards can be generated using the {vetiver} package.\n\n\n\n\n“How to make a Thousand Plots Look Good: Data Viz Tips for Parameterized Reporting,” by David Keyes from R for the Rest of Us\nParameterized reporting refers to process of creating a single document in markdown/Quarto and using it to make multiple reports at once. For instance, one can work with a single report for the visualization of housing and demographics data, and then expand this report to view data for a variety of towns, counties, and countries.\nHow can we think about intuitive data visualization in the context of parameterized reporting? Here are some rules to consider:\n\nThere is no magic package\nConsider the outer limits of your data\n\n\ne.g. scale of income\n\n\nMinimize text and position it carefully\nDon’t label everything\n\n\n{ggrepel}: repel overlapping labels in ggplot\n{shadowtext}: add background color to text\n\n\nHide small values\nDon’t put text where it could be obscured\n\n\nAdd text elements as multiple layers. Make sure to include a separate element for text position\n\n\nHighlight items strategically\n\n\nMake use of color, size, shadow, outline, and opacity\nConsider the R package {ggfx}\n\nHere’s the ultimate takeaway: there are a countless number of R packages that can help you achieve your goals in modularizing your applications, but at the end of the day, you are the one who has to do the thinking!\n\n\n“Cartographic Tricks and Techniques in R,” by Justin Sherrill from ECONorthwest\nCartography refers to the generation of maps for geographic locations. However, in a more figurative sense, cartography is an exercise in story-telling. Through the information that you convey in your cartographic visualizations, you are choosing the story that you tell. Writing a good story is about making decisions - you need to make the right sacrifices in the information that you choose to exclude.\nWhat are the key principles of “good” cartography? 1. Visual hierarchy (the arrangement of elements that guide the viewer’s eye through the content in the right order) 2. Legibility 3. Figure-ground (the ability to differentiate between an object and its background) 4. Balance\nJacques Bertin and William Bunge were two renowned geographers from the 20th century who consistently followed the principles of good cartography. You can refer to a lot of their work to get inspiration for developing cartographic visualizations. Timo Grossenbacher is a modern-day geographer and data scientist who has used R to develop some beautiful cartographic illustrations. Here is a great example of a bivariate thematic map he generated of Switzerland’s regional income inequality.\nAs Timo demonstrates, you can do pretty much all of the data visualization you want to do with {ggplot2}. {ggplot2} is one of the strongest data visualization tools in existence.\nHere is a set of great packages to apply for geospatial data visualization in R and {ggplot2}:\n1. {ggspatial}: includes the north arrow / scale bar\n2. {mapboxapi}: can show roads, bodies of water, and more.\n3. {patchwork}: can do map insets to show larger context of your zoomed in map - can also use {ggmagnify}\n4. {ggrepel}: label placement to avoid overlapping labels\n5. {st_inscribed_circle}: label an unusually shaped polygon\n6. {ggforce}: label a subset of points in a nice style\n7. {ggfx}: fun effects for {ggplot2}\n8. {ggdensity}: show density patterns\n9. {rmapshaper}: simplify geometries of shapes\n10. {smoothr}: round the corners for shapes\n11. {ggarrow}: make pretty arrows\n12. {ggstar}: pch symbols\n13. {ggsvg}: use SVGs as points in your plot\nThese packages are all very easy to implement and can turn your basic cartographic maps into true works of art! If you’re interested in playing around with cartographic visualizations, you can get access to open-source geospatial data for the state of Washington from the Washington Geospatial Open Data Portal.\n\n\nPersonal Takeaways\nI had a lot of fun attending Cascadia R Conference 2024, and I look forward to being back in 2025! Here are some personal takeaways I got from the conference.\n\nThe R community is extremely creative and fun! This conference felt very different from some of the technical biomedical informatics conferences I’ve attended in the past, many of which were focused purely on scientific advancements. At this conference, there were so many talks that demonstrated all sorts of random things you could do with the language of R, and these wacky detours were both encouraged and celebrated!\nThere is a growing focus on R for production-level ventures, including parameterization and modularization. Many data scientists are interested in scaling R for industrial applications and integrating it with other languages.\nWhile we are currently in a hype cycle for the field of generative AI and large language models, there is still plenty of other interesting work to be accomplished in the field of data science. It’s important to not get carried away by the fear of missing out (FOMO)! Focus on the goals of your work and find the right tools for the job (i.e. problem-first instead of tooling-first solutions)\n\n\nThis concludes my summary of my experience at Cascadia R Conference 2024! I’d like to give a huge thank you to the organizers of this conference for all of their hard work and for bringing the PNW data science community together in such a wonderful event. The next conference I will be attending will be posit::conf(2024), and I look forward to summarizing my experiences there in another blog post. Until next week, [VS]Coders!"
  }
]