{
  "hash": "8ea11bcce66918b8ed007a220a6ee50d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Intro to Neural Networks and Backpropagation\ndescription: Andrej Karpathy's video 1\nauthor: Vivek Sriram\ndate: 7/1/2024\ndate-modified: 7/1/2024\nimage: zolaRunning.PNG\ncategories:\n  - Tutorials\ndraft: true\n---\n\nThis is a walkthrough of Andrej Karpathy's video \"The spelled out intro to neural networks and backpropagation\". See https://www.youtube.com/watch?v=VMj-3S1tku0.\n\nNeural networks are defined as ... Back propagation is defined as ...\n\nThis code example is a direct copy of the code walked through in the video, streamlined a bit for interpretation. I would highly recommend following along with this tutorial. I hope to work through his other tutorials in the future as well.\n\n```{{r}}\nlibrary(reticulate)\nuse_python('/opt/anaconda3/bin/python')\n```\n\n::: {#4fa82bf1 .cell execution_count=1}\n``` {.python .cell-code}\n# Import required packages\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n```\n:::\n\n\n# Background\n\n::: {#d931227b .cell execution_count=2}\n``` {.python .cell-code}\n# e.g. scalar value function that takes scalar input and returns scalar output\ndef f(x):\n    return 3*x**2 - 4*x + 5\n\n# e.g. single value\nf(3.0)\n\n# e.g. range of values\nxs = np.arange(-5, 5, 0.25)\nys = f(xs)\nys\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\narray([100.    ,  91.6875,  83.75  ,  76.1875,  69.    ,  62.1875,\n        55.75  ,  49.6875,  44.    ,  38.6875,  33.75  ,  29.1875,\n        25.    ,  21.1875,  17.75  ,  14.6875,  12.    ,   9.6875,\n         7.75  ,   6.1875,   5.    ,   4.1875,   3.75  ,   3.6875,\n         4.    ,   4.6875,   5.75  ,   7.1875,   9.    ,  11.1875,\n        13.75  ,  16.6875,  20.    ,  23.6875,  27.75  ,  32.1875,\n        37.    ,  42.1875,  47.75  ,  53.6875])\n```\n:::\n:::\n\n\n::: {#f2524210 .cell execution_count=3}\n``` {.python .cell-code}\nplt.plot(xs, ys)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=575 height=411}\n:::\n:::\n\n\nWhat is the derivative of f at different points of x? Let's calculate f'(3) numerically using the fundamental law of calculus:\n\n::: {#e5fb5166 .cell execution_count=4}\n``` {.python .cell-code}\nh = 0.0000000001\nx = 3.0\n\n(f(x+h) - f(x))/h\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n14.000001158365194\n```\n:::\n:::\n\n\nIf our h is too small, we'll get a floating point error. With some trial and error, we can see f'(3) = 14\n\nLet's make a function that is a little more complicated\n\n::: {#a796b84a .cell execution_count=5}\n``` {.python .cell-code}\na = 2.0\nb = -3.0\nc = 10.0\nd1 = a*b + c\n```\n:::\n\n\n::: {#d28ec3cc .cell execution_count=6}\n``` {.python .cell-code}\nh = 0.0000001\n\n#derivative wrt a\na += h\n\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2-d1)/h)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nd1 4.0\nd2 3.9999997\nslope -2.9999999995311555\n```\n:::\n:::\n\n\n::: {#6f810db2 .cell execution_count=7}\n``` {.python .cell-code}\n#derivative wrt b\nb += h\na = 2.0\n\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2-d1)/h)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nd1 4.0\nd2 4.0000002\nslope 1.9999999967268423\n```\n:::\n:::\n\n\n# The 'Value' Class\n\nLet's define a class \"Value\" to store the individual values in a function\n\n::: {#13bc66a9 .cell execution_count=8}\n``` {.python .cell-code}\nclass Value:\n    def __init__(self, data, _children=(), _op='', label=''):\n        self.data = data\n        self.grad = 0.0\n        self._backward = lambda: None #default: nothing\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n\n    # Nicer looking way to see what the value actually is instead of an object\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n\n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data + other.data, (self, other), '+')\n        def _backward():\n            self.grad += out.grad\n            other.grad += out.grad\n        out._backward = _backward\n        return out\n\n    def __radd__(self, other): # other * self\n        return self + other\n        \n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data * other.data, (self, other), '*')\n        def _backward():\n            self.grad += other.data * out.grad\n            other.grad += self.data * out.grad\n        out._backward = _backward\n        return out\n\n    def __rmul__(self, other): # other * self\n        return self * other\n\n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x)-1)/(math.exp(2*x)+1)\n        out = Value(t, (self, ), 'tanh')\n        def _backward():\n            self.grad +=  (1 - t**2) * out.grad\n        out._backward = _backward\n        return out\n\n    def exp(self):\n        x = self.data\n        out = Value(math.exp(x), (self, ), 'exp')\n\n        def _backward():\n            self.grad += out.data * out.grad\n        out._backward = _backward\n\n        return out\n\n    def __pow__(self, other):\n        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n        out = Value(self.data**other, (self,), f'**{other}')\n\n        def _backward():\n            self.grad += other * (self.data**(other-1)) * out.grad\n        out._backward = _backward\n\n        return out\n    \n    def __truediv__(self, other): #self / other\n        return self * other**-1\n\n    def __neg__(self): # -self\n        return self * -1\n\n    def __sub__(self, other): # self - other\n        return self + (-other)\n\n    def backward(self):\n        topo = []\n        visited = set()\n        def build_topo(v):\n            if v not in visited:\n                visited.add(v)\n                for child in v._prev:\n                    build_topo(child)\n                topo.append(v)\n        \n        build_topo(self)\n        \n        # call _backward() in the right topological order\n        self.grad = 1.0\n        for node in reversed(topo):\n            node._backward()\n```\n:::\n\n\n::: {#0f83a043 .cell execution_count=9}\n``` {.python .cell-code}\na = Value(2.0)\nb = Value(4.0)\na-b\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nValue(data=-2.0)\n```\n:::\n:::\n\n\nNow let's define an example function L = (a*b + c)*f\n\n::: {#da7fc2d5 .cell execution_count=10}\n``` {.python .cell-code}\na = Value(2.0, label='a')\nb = Value(-3.0, label='b')\nc = Value(10.0, label='c')\ne = a*b; e.label = 'e'\nd = e + c; d.label = 'd'\nf = Value(-2.0, label = 'f')\nL = d * f; L.label = 'L'\nL\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\nValue(data=-8.0)\n```\n:::\n:::\n\n\n::: {#d499d453 .cell execution_count=11}\n``` {.python .cell-code}\nd._prev\nd._op\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n'+'\n```\n:::\n:::\n\n\nWe can also define a function 'draw_dot' to be able to visualize the components of our function. Here, we build out a graph using the GraphViz API. We then iterate over all nodes and create the corresponding nodes and edges (including values and operations as different node types).\n\n::: {#2cc55084 .cell execution_count=12}\n``` {.python .cell-code}\nfrom graphviz import Digraph\n\ndef trace(root):\n    # builds a set of all nodes and edges in a graph\n    nodes, edges = set(), set()\n    def build(v):\n        if v not in nodes:\n            nodes.add(v)\n            for child in v._prev:\n                edges.add((child, v))\n                build(child)\n    build(root)\n    return nodes, edges\n\ndef draw_dot(root):\n    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) #LR = left to right\n\n    nodes, edges = trace(root)\n    for n in nodes:\n        uid = str(id(n))\n        # for any value in the graph, create a rectangular ('record') node for it\n        dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape = 'record')\n        if n._op:\n            # if this value is a result of some operation, create an op node for it\n            dot.node(name = uid + n._op, label = n._op)\n            # and connect this node to it\n            dot.edge(uid + n._op, uid)\n\n    for n1, n2 in edges:\n        # connect n1 to the op node of n2\n        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n\n    return dot\n```\n:::\n\n\n::: {#e01a1b9f .cell execution_count=13}\n``` {.python .cell-code}\ndraw_dot(L)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n![](index_files/figure-html/cell-14-output-1.svg){}\n:::\n:::\n\n\n# Manual backpropagation example\n\nTime for backpropagation. We'll start from L and work backwards, taking the derivative wrt L at each value\n\nThis exercise is equivalent to determining the derivative of a loss function L wrt the weights of a neural network\n\n::: {#f398a580 .cell execution_count=14}\n``` {.python .cell-code}\n# Let's calculate gradient of L wrt A manually\n# (f(x+h) - f(x))/h\ndef lol():\n    h = 0.001\n    \n    a = Value(2.0, label='a')\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label = 'f')\n    L = d * f; L.label = 'L'\n    L1 = L.data\n\n    a = Value(2.0 + h, label='a')\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label = 'f')\n    L = d * f; L.label = 'L'\n    L2 = L.data\n\n    print((L2-L1)/h)\n```\n:::\n\n\n::: {#e60f113d .cell execution_count=15}\n``` {.python .cell-code}\n#dL/da\nlol()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n6.000000000000227\n```\n:::\n:::\n\n\n::: {#3d3666c5 .cell execution_count=16}\n``` {.python .cell-code}\n#We know dL/dL = 1\nL.grad = 1\n```\n:::\n\n\n::: {#074e454c .cell execution_count=17}\n``` {.python .cell-code}\n#L = d*f\n#So dL/df = d\n#and dL/dd = f\n\nf.grad = 4.0 # this is just the value of d\nd.grad = -2.0 # this is just the value of f\n```\n:::\n\n\n::: {#085cb935 .cell execution_count=18}\n``` {.python .cell-code}\n# what is dL/dc?\n# We can use dL/dd and dd/dc and apply the chain rule\n# dL / dc = (dL/dd) * (dd/dc) = -2*1 = -2\n# dL/de is the same, -2\nc.grad = -2.0 # this is just the value of d\ne.grad = -2.0 # this is just the value of f\n```\n:::\n\n\n::: {#6e4b58e4 .cell execution_count=19}\n``` {.python .cell-code}\n# dL/da = dL/de * de/da = -2*b = -2*-3 = 6\n# dL/db = dL/de * de/db = -2*a = -2*2 = -4\na.grad = 6.0 # this is just the value of d\nb.grad = -4.0 # this is just the value of f\n```\n:::\n\n\n::: {#31f8fc73 .cell execution_count=20}\n``` {.python .cell-code}\ndraw_dot(L)\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n![](index_files/figure-html/cell-21-output-1.svg){}\n:::\n:::\n\n\n**Backpropagation is just the recursive application of the chain rule backwards through the computational graph**.\n\n::: {#2e5ca7da .cell execution_count=21}\n``` {.python .cell-code}\n# Let's nudge our data in the positive direction of the gradient to increase L\na.data += 0.01*a.grad\nb.data += 0.01*b.grad\nc.data += 0.01*c.grad\nf.data += 0.01*f.grad\n\ne = a*b\nd = e+c\nL = d*f\n\nprint(L.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n-7.286496\n```\n:::\n:::\n\n\n# Now let's manually backpropagate through a neuron\n\n::: {#680b65c4 .cell execution_count=22}\n``` {.python .cell-code}\n# Example of a neuron\nfrom IPython.display import Image\nImage(filename='/Users/vsriram/Desktop/Unknown.jpeg') \n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n![](index_files/figure-html/cell-23-output-1.jpeg){}\n:::\n:::\n\n\nLet's make use of the tanh activation function to limit our output to a range of -1 to 1.\n\n::: {#38ce610a .cell execution_count=23}\n``` {.python .cell-code}\n#Squashing/activation function - tan(h)\nplt.plot(np.arange(-5,5,0.2), np.tanh(np.arange(-5,5,0.2)));\nplt.grid();\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-24-output-1.png){width=590 height=411}\n:::\n:::\n\n\nLet's define a new function o = tanh(x1w1 + x2w2 +b)\n\n::: {#269bddd7 .cell execution_count=24}\n``` {.python .cell-code}\n# inputs x1, x2\nx1 = Value(2.0, label = 'x1')\nx2 = Value(0.0, label = 'x2')\n\n# weights w1, w2\nw1 = Value(-3.0, label = 'w1')\nw2 = Value(1.0, label = 'w2')\n\n# bias of the neuron\nb = Value (6.881373587019542, label = 'b')\n\n#x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\n\nx1w1x2w2 = x1w1 + x2w2;\nx1w1x2w2.label = 'x1*w1 + x2*w2'\n\n# n is our cell body activation without the activation function\nn = x1w1x2w2 + b;\nn.label = 'n'\n```\n:::\n\n\n::: {#109d7c3e .cell execution_count=25}\n``` {.python .cell-code}\n# Apply activation function (defined in Value class earlier)\no = n.tanh(); o.label = 'o'\n```\n:::\n\n\n::: {#3d30170b .cell execution_count=26}\n``` {.python .cell-code}\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n![](index_files/figure-html/cell-27-output-1.svg){}\n:::\n:::\n\n\nWe care most about the derivative of o wrt to the weights w1 and w2. In a normal neural network, we would have a lot of neurons as well (not just the one here)\n\n::: {#53341e31 .cell execution_count=27}\n``` {.python .cell-code}\no.grad = 1.0\n\n# o = tanh(n)\n# do/dn = 1-tanh^2(n) = 1 - o^2\nn.grad = 1-o.data**2\n\n# do/db = do/dn * dn/db = (1-o^2)*1 = 1-o^2\n# d(x1w1x2w2)/db = do/dn * dn/d(x1w1x2w2) = (1-o^2)*1 = 1-o^2\nx1w1x2w2.grad = 1-o.data**2\nb.grad = 1-o.data**2\n\n# same logic of back-propagation wrt '+'\nx1w1.grad = 1-o.data**2\nx2w2.grad = 1-o.data**2\n\n#do/dx2 = w2 * do/d(x2w2)\nx2.grad = w2.data * x2w2.grad\n#do/dw2 = x2 * do/d/(x2w2)\nw2.grad = x2.data * x2w2.grad\n\n# same logic as for x2/w2\nx1.grad = w1.data * x1w1.grad\nw1.grad = x1.data * x1w1.grad\n```\n:::\n\n\n::: {#2f8da5c3 .cell execution_count=28}\n``` {.python .cell-code}\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n![](index_files/figure-html/cell-29-output-1.svg){}\n:::\n:::\n\n\nSo, if we want this neuron's output to increase, then we should increase w1. w2 doesn't matter because its gradient is 0.\n\n# Automating backpropagation\n\nLet's stop doing this back-propagation manually! Take a look at the logic for \\_backward in the Value class.\n\n::: {#68c92cd6 .cell execution_count=29}\n``` {.python .cell-code}\no.grad = 1.0\n\no._backward()\nn._backward()\nb._backward()\nx1w1x2w2._backward()\nx2w2._backward()\nx1w1._backward()\n```\n:::\n\n\n::: {#cb999ef1 .cell execution_count=30}\n``` {.python .cell-code}\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n![](index_files/figure-html/cell-31-output-1.svg){}\n:::\n:::\n\n\nLet's also stop calling \\_backward manually. We never want to call \\_backward on a node before we've called \\_backward on its children. Let's apply a topological sort to our data.\n\n::: {#2244d130 .cell execution_count=31}\n``` {.python .cell-code}\ntopo = []\nvisited = set()\ndef build_topo(v):\n    if v not in visited:\n        visited.add(v)\n        for child in v._prev:\n            build_topo(child)\n        topo.append(v)\n\nbuild_topo(o)\n\nfor node in reversed(topo):\n    node._backward()\n    \ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n![](index_files/figure-html/cell-32-output-1.svg){}\n:::\n:::\n\n\nGreat, this works! Now let's incorporate this backward function into our Value class.\n\n::: {#9bf718b2 .cell execution_count=32}\n``` {.python .cell-code}\no.backward()\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n![](index_files/figure-html/cell-33-output-1.svg){}\n:::\n:::\n\n\nWoohoo! it works!\n\nWe still have a bad bug... for example, b = a + a. The value of b will be correct, but the gradient db/da won't. db/da should be b = 2a = 2, but based on our current logic, it will come out to 1.\n\nThis will be an issue any time we use a variable more than once in our function. We can fix this by accumulating gradients (use += instead of =)\n\n::: {#2d4082bb .cell execution_count=33}\n``` {.python .cell-code}\na = Value(3.0, label = 'a')\nb = a+a; b.label = 'b'\nb.backward()\ndraw_dot(b)\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n![](index_files/figure-html/cell-34-output-1.svg){}\n:::\n:::\n\n\nEverything works now! Yay!\n\n# Breaking up tanh into its individual components\n\nSee the new exp and div functions defined in Value\n\n::: {#2ac44ad0 .cell execution_count=34}\n``` {.python .cell-code}\n# inputs x1, x2\nx1 = Value(2.0, label = 'x1')\nx2 = Value(0.0, label = 'x2')\n\n# weights w1, w2\nw1 = Value(-3.0, label = 'w1')\nw2 = Value(1.0, label = 'w2')\n\n# bias of the neuron\nb = Value (6.881373587019542, label = 'b')\n\n#x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\n\nx1w1x2w2 = x1w1 + x2w2;\nx1w1x2w2.label = 'x1*w1 + x2*w2'\n\n# n is our cell body activation without the activation function\nn = x1w1x2w2 + b;\nn.label = 'n'\n\n# Apply activation function (defined in Value class earlier)\ne = (2*n).exp()\no = (e-1)/(e+1)\no.label = 'o'\no.backward()\n```\n:::\n\n\n::: {#eb9a0f54 .cell execution_count=35}\n``` {.python .cell-code}\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n![](index_files/figure-html/cell-36-output-1.svg){}\n:::\n:::\n\n\nOur forward and backward passes are correct! Note that the level at which you perform your individual operations is entirely up to you (e.g. tanh vs. its individual components).\n\nAll that matters is that you have input and output and that you can do forward/backward passing of your operations.\n\n# Backpropagation with PyTorch\n\nIn PyTorch, everything is based around tensors rather than scalars\n\n::: {#403b9749 .cell execution_count=36}\n``` {.python .cell-code}\nimport torch\n\n# Cast to double to get 64bit precision\nx1 = torch.Tensor([2.0]).double()\n# by default, pytorch will say leaf nodes don't have gradients to improve efficiency\nx1.requires_grad = True\n\nx2 = torch.Tensor([0.0]).double()\nx2.requires_grad = True\n\nw1 = torch.Tensor([-3.0]).double()\nw1.requires_grad = True\n\nw2 = torch.Tensor([1.0]).double()\nw2.requires_grad = True\n\nb = torch.Tensor([6.8813735870195432]).double()\nb.requires_grad = True\n\nn = x1*w1 + x2*w2 + b\no = torch.tanh(n)\n\n# PyTorch tensors have data and grad elements\nprint(o.data.item())\n# PyTorch has a backward function too\no.backward()\n\nprint('---')\nprint('x2', x2.grad.item())\nprint('w2', w2.grad.item())\nprint('x1', x1.grad.item())\nprint('w1', w1.grad.item())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.7071066904050358\n---\nx2 0.5000001283844369\nw2 0.0\nx1 -1.5000003851533106\nw1 1.0000002567688737\n```\n:::\n:::\n\n\nEverything in PyTorch is much more efficient. We can do all these operations in parallel with much larger tensors (not just scalar values)\n\nLet's implement a simple neural network\n\n::: {#c020f340 .cell execution_count=37}\n``` {.python .cell-code}\nclass Neuron:\n    def __init__(self, nin):\n        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n        self.b = Value(random.uniform(-1,1))\n        \n    # Python goes to __call__ when you use the class as a function\n    def __call__(self, x):\n        # w.x + b\n        # start with self.b, add the dot product of w and x\n        act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b)\n        out = act.tanh()\n        return out\n\n    def parameters(self):\n        return self.w + [self.b]\n```\n:::\n\n\nHere's an example of a neural network\n\n::: {#83e3640f .cell execution_count=38}\n``` {.python .cell-code}\nImage(filename='/Users/vsriram/Desktop/Unknown-1.jpeg') \n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n![](index_files/figure-html/cell-39-output-1.jpeg){}\n:::\n:::\n\n\nWe've defined a neuron class. Let's define a Layer class as well\n\n::: {#2069c42d .cell execution_count=39}\n``` {.python .cell-code}\nclass Layer:\n    # nout is the size of hte output of the layer\n    def __init__(self, nin, nout):\n        self.neurons = [Neuron(nin) for _ in range(nout)]\n\n    def __call__(self, x):\n        outs = [n(x) for n in self.neurons]\n        return outs[0] if len(outs) == 1 else outs\n\n    def parameters(self):\n        params = []\n        for neuron in self.neurons:\n            ps = neuron.parameters()\n            params.extend(ps)\n        return params\n        \n        # Same as:\n        # return [p for neuron in self.neurons for p in neuron.parameters()]\n```\n:::\n\n\nNow let's make a multilayer perceptron (MLP)\n\n::: {#4125a92b .cell execution_count=40}\n``` {.python .cell-code}\nclass MLP:\n    # nouts is the list of layer sizes we want\n    def __init__(self, nin, nouts):\n        sz = [nin] + nouts\n        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n\n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n\n    def parameters(self):\n        return [p for layer in self.layers for p in layer.parameters()]\n```\n:::\n\n\n::: {#a09b6925 .cell execution_count=41}\n``` {.python .cell-code}\nx = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```\nValue(data=-0.25516954739652975)\n```\n:::\n:::\n\n\n::: {#de45efd4 .cell execution_count=42}\n``` {.python .cell-code}\ndraw_dot(n(x))\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n![](index_files/figure-html/cell-43-output-1.svg){}\n:::\n:::\n\n\nWow, PyTorch let's us get crazy with the functions we define. Obviously we're never going to manually backpropagate such an example... let's have PyTorch do it for us\n\n::: {#11dab176 .cell execution_count=43}\n``` {.python .cell-code}\n# Example data\nxs = [\n    [2.0, 3.0, -1.0],\n    [3.0, -1.0, 0.5],\n    [0.5, 1.0, 1.0],\n    [1.0, 1.0, -1.0]\n]\n\nys = [1.0, -1.0, -1.0, 1.0] #desired targets\n\n# Apply our MLP to predict y from x\nypred = [n(x) for x in xs]\nypred\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\n[Value(data=-0.25516954739652975),\n Value(data=-0.81054039168371),\n Value(data=-0.7652314530173903),\n Value(data=-0.3124544476665725)]\n```\n:::\n:::\n\n\n::: {#7968e3f3 .cell execution_count=44}\n``` {.python .cell-code}\n# loss will measure how good our neural net is\n# let's do mean squared error\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```\nValue(data=3.3889984837470655)\n```\n:::\n:::\n\n\n::: {#1d2abcd7 .cell execution_count=45}\n``` {.python .cell-code}\nloss.backward()\n```\n:::\n\n\n::: {#06b634e5 .cell execution_count=46}\n``` {.python .cell-code}\n# If this gradient is positive, then decreasing this weight will decrease our loss\n# If this is negative, then increasing this weight will decrease our loss\nn.layers[0].neurons[0].w[0].grad\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```\n0.1437930514421516\n```\n:::\n:::\n\n\n::: {#31da93ba .cell execution_count=47}\n``` {.python .cell-code}\nn.layers[0].neurons[0].w[0].data\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\n-0.38946425793232886\n```\n:::\n:::\n\n\n::: {#adfa3cd7 .cell execution_count=48}\n``` {.python .cell-code}\n# for every parameter in our neural net, let's change the weights slightly to reduce the loss\n# increase for negative grad, decrease for positive grad\nfor p in n.parameters():\n    p.data += -0.01*p.grad\n```\n:::\n\n\nLoss should have gone down a bit now. Let's recalculate it.\n\n::: {#f344338f .cell execution_count=49}\n``` {.python .cell-code}\nypred = [n(x) for x in xs]\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\nValue(data=1.6796372850100796)\n```\n:::\n:::\n\n\n::: {#e8b5e1ea .cell execution_count=50}\n``` {.python .cell-code}\n# Propoagate\nloss.backward()\n```\n:::\n\n\nNow all we have to do is iterate this process.\n\n::: {#17e68102 .cell execution_count=51}\n``` {.python .cell-code}\nypred\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\n[Value(data=0.22218472314987042),\n Value(data=-0.750643101375195),\n Value(data=-0.6794995972642768),\n Value(data=0.04619639911400329)]\n```\n:::\n:::\n\n\nNice, we're able to train our data better. Let's formalize this in a loop\n\n::: {#e4d3389e .cell execution_count=52}\n``` {.python .cell-code}\n# Reset the neural net\nx = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\nValue(data=0.5792580324085981)\n```\n:::\n:::\n\n\n::: {#87155989 .cell execution_count=53}\n``` {.python .cell-code}\n# Initialize input data and desired targets\nxs = [\n    [2.0, 3.0, -1.0],\n    [3.0, -1.0, 0.5],\n    [0.5, 1.0, 1.0],\n    [1.0, 1.0, -1.0]\n]\n\nys = [1.0, -1.0, -1.0, 1.0]\n```\n:::\n\n\n::: {#597e4ba4 .cell execution_count=54}\n``` {.python .cell-code}\nfor k in range(20):\n    # forward pass\n    ypred = [n(x) for x in xs]\n    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n\n    # backward pass\n    for p in n.parameters():\n        p.grad = 0.0\n    loss.backward()\n\n    # update\n    # \"stochastic gradient descent\"\n    for p in n.parameters():\n        p.data += -0.05 * p.grad\n\n    print(k, loss.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0 2.0286072292313904\n1 0.8451651695643778\n2 0.46218211141747023\n3 0.31100377728971784\n4 0.2317839911854902\n5 0.1835010988150704\n6 0.1511933565491248\n7 0.1281563627032515\n8 0.11095418436629649\n9 0.09765076448303228\n10 0.08707514652868029\n11 0.07847907694324446\n12 0.07136289694986098\n13 0.06538069923552094\n14 0.06028569815351427\n15 0.05589727455063839\n16 0.052080306240688254\n17 0.048731765248791165\n18 0.045771773151437094\n19 0.04313747949518701\n```\n:::\n:::\n\n\n::: {#a9039149 .cell execution_count=55}\n``` {.python .cell-code}\nypred\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```\n[Value(data=0.9168735976751606),\n Value(data=-0.8965320247954542),\n Value(data=-0.8757826734991045),\n Value(data=0.8995414780331833)]\n```\n:::\n:::\n\n\n# Summary\n\nNeural nets are simple mathematical expressions that take input data and weights. Forward pass of data followed by loss function. Try to minimize loss to get the output of the function to hit desired targets. Use back propagation from loss to get the gradients of the weights. Tune the weights against the gradient (gradient descent)\n\nSimulating a blob of neural tissue that can handle all sorts of interesting problems. GPT uses massive amounts of text from the internet and then predicts the next words in a sentence 100s of billions of parameters\n\nloss function and gradient descents may be slightly different ReLU instead of tanh. all are roughly equivalent non-linearities\n\nNext up you can look at Andrej Karpathy's micrograd example\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}