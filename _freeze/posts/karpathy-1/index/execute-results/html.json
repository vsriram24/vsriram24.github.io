{
  "hash": "0c8a152f14db44e3fa659e87612da890",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: A Python introduction to neural networks and backpropagation\ndescription: 'Andrej Karpathy''s ''Neural Networks: Zero to Hero'' video #1'\nauthor: Vivek Sriram\ndate: 7/8/2024\ndate-modified: 7/8/2024\nimage: zolaFish.jpeg\ncategories:\n  - Tutorials\ndraft: false\n---\n\nThis is a walkthrough of Andrej Karpathy's video \"[The spelled-out intro to neural networks and backpropagation: building micrograd](https://www.youtube.com/watch?v=VMj-3S1tku0)\". This video is the first in his YouTube series, \"[Neural Networks: Zero to Hero](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ).\"\n\n![A screen-grab of Andrej's video](karpathyVideo.png)\n\n[Neural networks](https://aws.amazon.com/what-is/neural-network/#:~:text=A%20neural%20network%20is%20a,that%20resembles%20the%20human%20brain.) are mathematical models used to represent nodes and the signals they send to one another through their links. Neural networks replicate the structure of the brain, where interconnected neurons send messages to each other through electric signals across the synpases that bridge them together. While individual nodes can perform only simple operations, many nodes connected together in a network can perform complex computational tasks.\n\nThe general structure of a neural network for machine learning includes three types of nodes, grouped into different \"layers\" within the neural network. The first set of nodes are the input nodes, corresponding to input (or training data). The second set of nodes refer to intermediate (hidden) nodes. The final type of node is the output node, corresponding to the result of processing the input data through the hidden nodes. This output layer typically comes in the form of a loss function, characterizing the difference between the output of the model and the expected output. The goal of optimizing a neural network is to minimize this output loss to best match the behavior of the input data.\n\n![The basic format of a neural network](nn.jpeg)\n\nBackpropagation is an algorithm for supervised learning of neural networks using [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent). This method will calculate the gradient of each intermediate node in the network with respect to the loss function, allowing us to iteratively tune their weights to minimize the overall loss.\n\nIn his video tutorial, Andrej shows how to construct a neural network from scratch and perform backpropagation on it to optimize the weights of the network. The code presented in this example is a direct copy of the code walked through in the video, streamlined a bit for interpretation. Writing this blog post helped me solidify my understanding of the material (and also helped me practice writing Python code in Quarto :) ). I would highly recommend following along with this tutorial and further videos for a hands-on, ground-up exploration of neural networks and language models! I aim to work through his other tutorials in the future as well.\n\nWith background out of the way, let's get started\\~\n\n```{{r}}\nlibrary(reticulate)\nuse_python('/opt/anaconda3/bin/python')\n```\n\n::: {#876ff6ad .cell execution_count=1}\n``` {.python .cell-code}\n# Import required packages\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n```\n:::\n\n\n# Defining functions and manually calculating derivatives\n\nWe can start by thinking about a simple mathematical expression to give us some intuition behind the workings of individual neurons.\n\nLet's define a scalar value function *f(*x*)* that takes scalar input and returns scalar output. We can apply this function to a single value or a range of values.\n\n::: {#546a8d98 .cell execution_count=2}\n``` {.python .cell-code}\n# e.g. scalar value function that takes scalar input and returns scalar output\ndef f(x):\n    return 3*x**2 - 4*x + 5\n\n# e.g. single value\nf(3.0)\n\n# e.g. range of values\nxs = np.arange(-5, 5, 0.25)\nys = f(xs)\nys\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```\narray([100.    ,  91.6875,  83.75  ,  76.1875,  69.    ,  62.1875,\n        55.75  ,  49.6875,  44.    ,  38.6875,  33.75  ,  29.1875,\n        25.    ,  21.1875,  17.75  ,  14.6875,  12.    ,   9.6875,\n         7.75  ,   6.1875,   5.    ,   4.1875,   3.75  ,   3.6875,\n         4.    ,   4.6875,   5.75  ,   7.1875,   9.    ,  11.1875,\n        13.75  ,  16.6875,  20.    ,  23.6875,  27.75  ,  32.1875,\n        37.    ,  42.1875,  47.75  ,  53.6875])\n```\n:::\n:::\n\n\nWe can plot the output of our function to see the association between our input and output as well.\n\n::: {#08eb2ee0 .cell execution_count=3}\n``` {.python .cell-code}\nplt.plot(xs, ys)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=575 height=411}\n:::\n:::\n\n\nDetermining the derivative of *f* would let us identify inflection points in our data. Let's calculate the derivative of *f* at 3 (i.e. *f'(*3)) numerically using the fundamental law of calculus:\n\n$$\n\\lim_{h\\to\\infty} \\frac{f(x+h)-f(x)}{h}\n$$\n\n::: {#4e7b59a9 .cell execution_count=4}\n``` {.python .cell-code}\nh = 0.0000000001\nx = 3.0\n\n(f(x+h) - f(x))/h\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```\n14.000001158365194\n```\n:::\n:::\n\n\nNote that if our *h* is too small for Python, we will end up with a floating point error. With some trial and error for different values of *h*, we can see *f'*(3) = 14\n\nNow let's make a function that is a little more complicated: $$\nd(a, b, c) = a*b + c\n$$\n\n::: {#160ef1ba .cell execution_count=5}\n``` {.python .cell-code}\na = 2.0\nb = -3.0\nc = 10.0\nd1 = a*b + c\n```\n:::\n\n\nAgain, we can calculate the derivative of ***d***. This time, since we have three inputs, we have to pick a variable with respect to which we calculate the derivative. Let's numerically calculate the derivative of ***d*** with respect to *a*.\n\n::: {#3cbeff89 .cell execution_count=6}\n``` {.python .cell-code}\nh = 0.0000001\n\n#derivative wrt a\na += h\n\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2-d1)/h)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nd1 4.0\nd2 3.9999997\nslope -2.9999999995311555\n```\n:::\n:::\n\n\nWe can do the same with respect to *b* as well.\n\n::: {#6d673f91 .cell execution_count=7}\n``` {.python .cell-code}\n#derivative wrt b\nb += h\na = 2.0\n\nd2 = a*b + c\n\nprint('d1', d1)\nprint('d2', d2)\nprint('slope', (d2-d1)/h)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nd1 4.0\nd2 4.0000002\nslope 1.9999999967268423\n```\n:::\n:::\n\n\nWe now have some intuition for how functions and derivatives work.\n\n# The 'Value' Class\n\nLet's define a class \"Value\" to store the individual values that come together to make a function / mathematical expression. Each 'Value' can be thought of as a node in a neural network.\n\n::: {#98e2aaf3 .cell execution_count=8}\n``` {.python .cell-code}\nclass Value:\n    def __init__(self, data, _children=(), _op='', label=''):\n        self.data = data\n        self.grad = 0.0\n        self._backward = lambda: None #default: nothing\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n\n    # Nicer looking way to see what the value actually is instead of an object\n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n\n    def __add__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data + other.data, (self, other), '+')\n        def _backward():\n            self.grad += out.grad\n            other.grad += out.grad\n        out._backward = _backward\n        return out\n\n    def __radd__(self, other): # other * self\n        return self + other\n        \n    def __mul__(self, other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data * other.data, (self, other), '*')\n        def _backward():\n            self.grad += other.data * out.grad\n            other.grad += self.data * out.grad\n        out._backward = _backward\n        return out\n\n    def __rmul__(self, other): # other * self\n        return self * other\n\n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x)-1)/(math.exp(2*x)+1)\n        out = Value(t, (self, ), 'tanh')\n        def _backward():\n            self.grad +=  (1 - t**2) * out.grad\n        out._backward = _backward\n        return out\n\n    def exp(self):\n        x = self.data\n        out = Value(math.exp(x), (self, ), 'exp')\n\n        def _backward():\n            self.grad += out.data * out.grad\n        out._backward = _backward\n\n        return out\n\n    def __pow__(self, other):\n        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n        out = Value(self.data**other, (self,), f'**{other}')\n\n        def _backward():\n            self.grad += other * (self.data**(other-1)) * out.grad\n        out._backward = _backward\n\n        return out\n    \n    def __truediv__(self, other): #self / other\n        return self * other**-1\n\n    def __neg__(self): # -self\n        return self * -1\n\n    def __sub__(self, other): # self - other\n        return self + (-other)\n\n    def backward(self):\n        topo = []\n        visited = set()\n        def build_topo(v):\n            if v not in visited:\n                visited.add(v)\n                for child in v._prev:\n                    build_topo(child)\n                topo.append(v)\n        \n        build_topo(self)\n        \n        # call _backward() in the right topological order\n        self.grad = 1.0\n        for node in reversed(topo):\n            node._backward()\n```\n:::\n\n\nWe can see how to perform mathematical operations using our `Value` class:\n\n::: {#b71aa313 .cell execution_count=9}\n``` {.python .cell-code}\na = Value(2.0)\nb = Value(4.0)\na-b\n```\n\n::: {.cell-output .cell-output-display execution_count=59}\n```\nValue(data=-2.0)\n```\n:::\n:::\n\n\nNow let's define an example function ***L*** that makes use of our `Value` class:\n\n$$\nL(a, b, c, f) = (a*b + c)*f\n$$\n\n::: {#df1bfc2e .cell execution_count=10}\n``` {.python .cell-code}\na = Value(2.0, label='a')\nb = Value(-3.0, label='b')\nc = Value(10.0, label='c')\ne = a*b; e.label = 'e'\nd = e + c; d.label = 'd'\nf = Value(-2.0, label = 'f')\nL = d * f; L.label = 'L'\nL\n```\n\n::: {.cell-output .cell-output-display execution_count=60}\n```\nValue(data=-8.0)\n```\n:::\n:::\n\n\nBased on the code in our `Value` class, we are able to see for each node which nodes came before it and what the operation was to generate the current node.\n\n::: {#1d50d242 .cell execution_count=11}\n``` {.python .cell-code}\nd._prev\nd._op\n```\n\n::: {.cell-output .cell-output-display execution_count=61}\n```\n'+'\n```\n:::\n:::\n\n\nWe can also define a function 'draw_dot' to be able to visualize the components of our function. Here, we build out a graph using the GraphViz API. We then iterate over all nodes and create corresponding nodes and edges (including values and operations as different node types in our network).\n\n::: {#50d4d7c6 .cell execution_count=12}\n``` {.python .cell-code}\nfrom graphviz import Digraph\n\ndef trace(root):\n    # builds a set of all nodes and edges in a graph\n    nodes, edges = set(), set()\n    def build(v):\n        if v not in nodes:\n            nodes.add(v)\n            for child in v._prev:\n                edges.add((child, v))\n                build(child)\n    build(root)\n    return nodes, edges\n\ndef draw_dot(root):\n    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) #LR = left to right\n\n    nodes, edges = trace(root)\n    for n in nodes:\n        uid = str(id(n))\n        # for any value in the graph, create a rectangular ('record') node for it\n        dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape = 'record')\n        if n._op:\n            # if this value is a result of some operation, create an op node for it\n            dot.node(name = uid + n._op, label = n._op)\n            # and connect this node to it\n            dot.edge(uid + n._op, uid)\n\n    for n1, n2 in edges:\n        # connect n1 to the op node of n2\n        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n\n    return dot\n```\n:::\n\n\n::: {#cac24515 .cell execution_count=13}\n``` {.python .cell-code}\ndraw_dot(L)\n```\n\n::: {.cell-output .cell-output-display execution_count=63}\n![](index_files/figure-html/cell-14-output-1.svg){}\n:::\n:::\n\n\n# Manual backpropagation example\n\nWith our basic function ***L*** now represented as a network of values and operations, let's perform manual backpropagation.\n\nWe'll start from ***L*** and work backwards, taking the derivative with respect to ***L*** at each intermediate value. This exercise is equivalent to determining the derivative of an output ***L*** with respect to the internal weights of a neural network.\n\n::: {#735327fb .cell execution_count=14}\n``` {.python .cell-code}\n# Let's calculate gradient of L wrt a manually using the fundamental theorem of calculus\n# (f(x+h) - f(x))/h\ndef lol():\n    h = 0.001\n    \n    a = Value(2.0, label='a')\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label = 'f')\n    L = d * f; L.label = 'L'\n    L1 = L.data\n\n    a = Value(2.0 + h, label='a')\n    b = Value(-3.0, label='b')\n    c = Value(10.0, label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.0, label = 'f')\n    L = d * f; L.label = 'L'\n    L2 = L.data\n\n    print((L2-L1)/h)\n```\n:::\n\n\n::: {#76339a31 .cell execution_count=15}\n``` {.python .cell-code}\n#dL/da\nlol()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n6.000000000000227\n```\n:::\n:::\n\n\nWe can go through this entire network structure and set the gradients for each node with respect to ***L***.\n\n::: {#91405de2 .cell execution_count=16}\n``` {.python .cell-code}\n#We know dL/dL = 1\nL.grad = 1\n```\n:::\n\n\n::: {#76ba40af .cell execution_count=17}\n``` {.python .cell-code}\n#L = d*f\n#So dL/df = d\n#and dL/dd = f\n\nf.grad = 4.0 # this is just the value of d\nd.grad = -2.0 # this is just the value of f\n```\n:::\n\n\n::: {#6b9a5c55 .cell execution_count=18}\n``` {.python .cell-code}\n# what is dL/dc?\n# We can use dL/dd and dd/dc and apply the chain rule\n# dL / dc = (dL/dd) * (dd/dc) = -2*1 = -2\n# dL/de is the same, -2\nc.grad = -2.0 # this is just the value of d\ne.grad = -2.0 # this is just the value of f\n```\n:::\n\n\n::: {#d76ee1ae .cell execution_count=19}\n``` {.python .cell-code}\n# dL/da = dL/de * de/da = -2*b = -2*-3 = 6\n# dL/db = dL/de * de/db = -2*a = -2*2 = -4\na.grad = 6.0 # this is just the value of d\nb.grad = -4.0 # this is just the value of f\n```\n:::\n\n\n::: {#e332d802 .cell execution_count=20}\n``` {.python .cell-code}\ndraw_dot(L)\n```\n\n::: {.cell-output .cell-output-display execution_count=70}\n![](index_files/figure-html/cell-21-output-1.svg){}\n:::\n:::\n\n\nHere is our key takeaway from this example:\n\n**Backpropagation is just the recursive application of the [chain rule](https://en.wikipedia.org/wiki/Chain_rule) backwards through the computational graph** **of your neural network.**\n\n# Introducing an activation function.\n\nIn our previous example, we had an output ***L*** that could take on any value. Now let's make use of the hyperbolic tangent ($tanh$) activation function to limit our output to a range of -1 to 1.\n\n$Tanh$ looks as follows:\n\n::: {#534e5218 .cell execution_count=21}\n``` {.python .cell-code}\n#Squashing/activation function - tan(h)\nplt.plot(np.arange(-5,5,0.2), np.tanh(np.arange(-5,5,0.2)));\nplt.grid();\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-22-output-1.png){width=590 height=411}\n:::\n:::\n\n\nLet's define a new function $o = tanh(x1*w1 + x2*w2 + b)$\n\n::: {#5bf3d1e3 .cell execution_count=22}\n``` {.python .cell-code}\n# inputs x1, x2\nx1 = Value(2.0, label = 'x1')\nx2 = Value(0.0, label = 'x2')\n\n# weights w1, w2\nw1 = Value(-3.0, label = 'w1')\nw2 = Value(1.0, label = 'w2')\n\n# bias of the neuron (crazy bias makes clean output in this example)\nb = Value (6.881373587019542, label = 'b')\n\n#x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\n\nx1w1x2w2 = x1w1 + x2w2;\nx1w1x2w2.label = 'x1*w1 + x2*w2'\n\n# n is our cell body activation without the activation function\nn = x1w1x2w2 + b;\nn.label = 'n'\n\n# Apply activation function (defined in Value class earlier)\no = n.tanh(); o.label = 'o'\n```\n:::\n\n\nHere is the network that represents the function we just defined:\n\n::: {#3abff129 .cell execution_count=23}\n``` {.python .cell-code}\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=73}\n![](index_files/figure-html/cell-24-output-1.svg){}\n:::\n:::\n\n\nWe care most about the derivative of ***o*** with respect to the weights *w1* and *w2*. In a normal neural network, we would have many more input and intermediate nodes (not just the two as in this example). We will calculate the gradients for this network by hand.\n\n::: {#48bc68cc .cell execution_count=24}\n``` {.python .cell-code}\no.grad = 1.0\n\n# o = tanh(n)\n# do/dn = 1-tanh^2(n) = 1 - o^2\nn.grad = 1-o.data**2\n\n# do/db = do/dn * dn/db = (1-o^2)*1 = 1-o^2\n# d(x1w1x2w2)/db = do/dn * dn/d(x1w1x2w2) = (1-o^2)*1 = 1-o^2\nx1w1x2w2.grad = 1-o.data**2\nb.grad = 1-o.data**2\n\n# same logic of back-propagation wrt '+'\nx1w1.grad = 1-o.data**2\nx2w2.grad = 1-o.data**2\n\n#do/dx2 = w2 * do/d(x2w2)\nx2.grad = w2.data * x2w2.grad\n#do/dw2 = x2 * do/d/(x2w2)\nw2.grad = x2.data * x2w2.grad\n\n# same logic as for x2/w2\nx1.grad = w1.data * x1w1.grad\nw1.grad = x1.data * x1w1.grad\n```\n:::\n\n\n::: {#1592598a .cell execution_count=25}\n``` {.python .cell-code}\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=75}\n![](index_files/figure-html/cell-26-output-1.svg){}\n:::\n:::\n\n\nSo, because *w1*'s gradient is positive, if we want this neuron's output to increase, then we should increase *w1*. *w2* doesn't affect the output of this function because its gradient is 0.\n\n# Automating backpropagation\n\nLet's stop doing this back-propagation manually! Take a look at the logic for `_backward` and `backward`in the `Value` class to see how we handle this (we apply a topological sort to our data in the `backward` function). We also ensure that we never call `_backward` on a node before we've called it on its children. Lastly, we make sure that we accumulate gradients in the `backward` function.\n\n::: {#294c1be4 .cell execution_count=26}\n``` {.python .cell-code}\no.grad = 1.0\n\no._backward()\nn._backward()\nb._backward()\nx1w1x2w2._backward()\nx2w2._backward()\nx1w1._backward()\n```\n:::\n\n\n::: {#467bd0af .cell execution_count=27}\n``` {.python .cell-code}\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=77}\n![](index_files/figure-html/cell-28-output-1.svg){}\n:::\n:::\n\n\n::: {#81c6991a .cell execution_count=28}\n``` {.python .cell-code}\no.backward()\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=78}\n![](index_files/figure-html/cell-29-output-1.svg){}\n:::\n:::\n\n\n::: {#e499838f .cell execution_count=29}\n``` {.python .cell-code}\na = Value(3.0, label = 'a')\nb = a+a; b.label = 'b'\nb.backward()\ndraw_dot(b)\n```\n\n::: {.cell-output .cell-output-display execution_count=79}\n![](index_files/figure-html/cell-30-output-1.svg){}\n:::\n:::\n\n\nEverything works! Yay!\n\n# Breaking up *`tanh`* into its individual components\n\nInstead of using a $tanh$ function in our `Value` class, we can break it up into exponent and division functions to see an example of a more complicated network.\n\n::: {#dc4811c0 .cell execution_count=30}\n``` {.python .cell-code}\n# inputs x1, x2\nx1 = Value(2.0, label = 'x1')\nx2 = Value(0.0, label = 'x2')\n\n# weights w1, w2\nw1 = Value(-3.0, label = 'w1')\nw2 = Value(1.0, label = 'w2')\n\n# bias of the neuron\nb = Value (6.881373587019542, label = 'b')\n\n#x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\n\nx1w1x2w2 = x1w1 + x2w2;\nx1w1x2w2.label = 'x1*w1 + x2*w2'\n\n# n is our cell body activation without the activation function\nn = x1w1x2w2 + b;\nn.label = 'n'\n\n# Apply activation function (defined in Value class earlier)\ne = (2*n).exp()\no = (e-1)/(e+1)\no.label = 'o'\no.backward()\n```\n:::\n\n\n::: {#ba764d8f .cell execution_count=31}\n``` {.python .cell-code}\ndraw_dot(o)\n```\n\n::: {.cell-output .cell-output-display execution_count=81}\n![](index_files/figure-html/cell-32-output-1.svg){}\n:::\n:::\n\n\nAs we can see, even after breaking our `tanh` function into its individual components, our forward and backward passes are still correct! Note that the level at which you perform your individual operations is entirely up to you (e.g. `tanh` vs. its individual components). All that matters is that you have input and output and that you can do forward/backward passing of your operations.\n\n# Backpropagation with PyTorch\n\nNow that we've developed backpropagation manually, let's see how it can be performed in [PyTorch](https://pytorch.org/docs/stable/index.html). With PyTorch, everything is based around [tensors](https://en.wikipedia.org/wiki/Tensor#:~:text=In%20mathematics%2C%20a%20tensor%20is,scalars%2C%20and%20even%20other%20tensors.) rather than scalars.\n\n::: {#e7e2de18 .cell execution_count=32}\n``` {.python .cell-code}\nimport torch\n\n# Cast to double to get 64bit precision\nx1 = torch.Tensor([2.0]).double()\n# by default, pytorch will say leaf nodes don't have gradients to improve efficiency\nx1.requires_grad = True\n\nx2 = torch.Tensor([0.0]).double()\nx2.requires_grad = True\n\nw1 = torch.Tensor([-3.0]).double()\nw1.requires_grad = True\n\nw2 = torch.Tensor([1.0]).double()\nw2.requires_grad = True\n\nb = torch.Tensor([6.8813735870195432]).double()\nb.requires_grad = True\n\nn = x1*w1 + x2*w2 + b\no = torch.tanh(n)\n\n# PyTorch tensors have data and grad elements\nprint(o.data.item())\n# PyTorch has a backward function too\no.backward()\n\nprint('---')\nprint('x2', x2.grad.item())\nprint('w2', w2.grad.item())\nprint('x1', x1.grad.item())\nprint('w1', w1.grad.item())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.7071066904050358\n---\nx2 0.5000001283844369\nw2 0.0\nx1 -1.5000003851533106\nw1 1.0000002567688737\n```\n:::\n:::\n\n\nPyTorch makes all of our calculations much more efficient. We can do all of these operations in parallel with very large tensors and not just scalar values.\n\n# A simple neural network\n\nWe've had enough fun with \"neural network adjacent\" mathematical expressions and their corresponding computational topologies.\n\nLet's implement a simple neural network. We will base this off of a [multilayer perceptron](https://www.datacamp.com/tutorial/multilayer-perceptrons-in-machine-learning#) (MLP). We can define a `Neuron` class, `Layer` class, and `MLP` class for our network.\n\nA typical neural network neuron looks like the following:\n\n![A typical neuron in a neural network](neuron.jpeg)\n\n::: {#ad06d062 .cell execution_count=33}\n``` {.python .cell-code}\nclass Neuron:\n    def __init__(self, nin):\n        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n        self.b = Value(random.uniform(-1,1))\n        \n    # Python goes to __call__ when you use the class as a function\n    def __call__(self, x):\n        # w.x + b\n        # start with self.b, add the dot product of w and x\n        act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b)\n        out = act.tanh()\n        return out\n\n    def parameters(self):\n        return self.w + [self.b]\n```\n:::\n\n\n::: {#737765b7 .cell execution_count=34}\n``` {.python .cell-code}\nclass Layer:\n    # nout is the size of the output of the layer\n    def __init__(self, nin, nout):\n        self.neurons = [Neuron(nin) for _ in range(nout)]\n\n    def __call__(self, x):\n        outs = [n(x) for n in self.neurons]\n        return outs[0] if len(outs) == 1 else outs\n\n    def parameters(self):\n        params = []\n        for neuron in self.neurons:\n            ps = neuron.parameters()\n            params.extend(ps)\n        return params\n        \n        # Same as:\n        # return [p for neuron in self.neurons for p in neuron.parameters()]\n```\n:::\n\n\n::: {#cdfc4e65 .cell execution_count=35}\n``` {.python .cell-code}\nclass MLP:\n    # nouts is the list of layer sizes we want\n    def __init__(self, nin, nouts):\n        sz = [nin] + nouts\n        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n\n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n\n    def parameters(self):\n        return [p for layer in self.layers for p in layer.parameters()]\n```\n:::\n\n\nBased upon our defined classes, let's initialize our MLP.\n\n::: {#82dcb60d .cell execution_count=36}\n``` {.python .cell-code}\nx = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=86}\n```\nValue(data=0.4944649312890593)\n```\n:::\n:::\n\n\n::: {#2b3565cf .cell execution_count=37}\n``` {.python .cell-code}\ndraw_dot(n(x))\n```\n\n::: {.cell-output .cell-output-display execution_count=87}\n![](index_files/figure-html/cell-38-output-1.svg){}\n:::\n:::\n\n\nWow, our function is much crazier than our initial examples! Obviously we're never going to manually backpropagate such an example... let's have PyTorch do it for us.\n\nWe start by defining some sample input data and our desired targets. We then use our baseline MLP to calculate model outputs from the input data.\n\n::: {#6338fd84 .cell execution_count=38}\n``` {.python .cell-code}\n# Example data\nxs = [\n    [2.0, 3.0, -1.0],\n    [3.0, -1.0, 0.5],\n    [0.5, 1.0, 1.0],\n    [1.0, 1.0, -1.0]\n]\n\nys = [1.0, -1.0, -1.0, 1.0] #desired targets\n\n# Apply our MLP to predict y from x\nypred = [n(x) for x in xs]\nypred\n```\n\n::: {.cell-output .cell-output-display execution_count=88}\n```\n[Value(data=0.4944649312890593),\n Value(data=0.40977958134154474),\n Value(data=-0.4050151100259451),\n Value(data=0.3923524132012742)]\n```\n:::\n:::\n\n\nWe can compare our model outputs to the expected outputs using a loss function such as [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error) (MSE).\n\n::: {#2e72e23d .cell execution_count=39}\n``` {.python .cell-code}\n# loss will measure how good our neural net is\n# let's do mean squared error\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n```\n\n::: {.cell-output .cell-output-display execution_count=89}\n```\nValue(data=2.96628678270387)\n```\n:::\n:::\n\n\nNow let's backpropagate (automatically this time)!\n\n::: {#b7597e28 .cell execution_count=40}\n``` {.python .cell-code}\nloss.backward()\n```\n:::\n\n\nIf the gradient of a weight is positive, then decreasing the weight will decrease the overall loss. Similarly, if the gradient is negative, then increasing the weight will decrease the loss.\n\n::: {#b2893698 .cell execution_count=41}\n``` {.python .cell-code}\n# If this gradient is positive, then decreasing this weight will decrease our loss\n# If this is negative, then increasing this weight will decrease our loss\nn.layers[0].neurons[0].w[0].grad\n```\n\n::: {.cell-output .cell-output-display execution_count=91}\n```\n-1.2640701291368466\n```\n:::\n:::\n\n\n::: {#d2aa9743 .cell execution_count=42}\n``` {.python .cell-code}\nn.layers[0].neurons[0].w[0].data\n```\n\n::: {.cell-output .cell-output-display execution_count=92}\n```\n-0.9567063145203327\n```\n:::\n:::\n\n\nFor every parameter in our neural network, let's change the weights slightly to reduce the overall loss. We increase the weight for negative gradients and decrease the weight for positive gradients.\n\n::: {#824f7e5b .cell execution_count=43}\n``` {.python .cell-code}\n# for every parameter in our neural net, let's change the weights slightly to reduce the loss\n# increase for negative grad, decrease for positive grad\nfor p in n.parameters():\n    p.data += -0.01*p.grad\n```\n:::\n\n\nOur overall loss should have gone down a bit now. Let's recalculate it.\n\n::: {#3d7062af .cell execution_count=44}\n``` {.python .cell-code}\nypred = [n(x) for x in xs]\nloss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\nloss\n```\n\n::: {.cell-output .cell-output-display execution_count=94}\n```\nValue(data=2.6726876872891854)\n```\n:::\n:::\n\n\n::: {#930f41d5 .cell execution_count=45}\n``` {.python .cell-code}\n# Propagate\nloss.backward()\n```\n:::\n\n\n::: {#f8f35ae1 .cell execution_count=46}\n``` {.python .cell-code}\nypred\n```\n\n::: {.cell-output .cell-output-display execution_count=96}\n```\n[Value(data=0.4993403271200778),\n Value(data=0.3198034181833698),\n Value(data=-0.45493607758790167),\n Value(data=0.38108818311718595)]\n```\n:::\n:::\n\n\nNice, we're able to train our data better now. Let's formalize this process of updating gradients in a loop. This is the same thing as \"[stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\".\n\n::: {#c63eae39 .cell execution_count=47}\n``` {.python .cell-code}\n# Reset the neural net\nx = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n```\n\n::: {.cell-output .cell-output-display execution_count=97}\n```\nValue(data=0.34934876482956906)\n```\n:::\n:::\n\n\n::: {#b0fea047 .cell execution_count=48}\n``` {.python .cell-code}\n# Initialize input data and desired targets\nxs = [\n    [2.0, 3.0, -1.0],\n    [3.0, -1.0, 0.5],\n    [0.5, 1.0, 1.0],\n    [1.0, 1.0, -1.0]\n]\n\nys = [1.0, -1.0, -1.0, 1.0]\n```\n:::\n\n\n::: {#5110a8e8 .cell execution_count=49}\n``` {.python .cell-code}\n# 20 iterations\nfor k in range(20):\n    # forward pass\n    ypred = [n(x) for x in xs]\n    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n\n    # backward pass\n    for p in n.parameters():\n        p.grad = 0.0\n    loss.backward()\n\n    # update\n    # \"stochastic gradient descent\"\n    for p in n.parameters():\n        p.data += -0.05 * p.grad\n\n    print(k, loss.data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0 8.493929671336291\n1 6.992068662805386\n2 5.769077247651545\n3 4.4735019295768295\n4 3.989548688723282\n5 3.7147609186944743\n6 3.405667943207894\n7 2.8620742530053116\n8 1.7745806845463523\n9 0.7698861574003086\n10 0.4457449169022083\n11 0.30780024751796564\n12 0.23273878356815986\n13 0.18590290331973824\n14 0.15408948967655905\n15 0.13116783996889828\n16 0.11392081179247492\n17 0.10050481438071963\n18 0.08979065153648244\n19 0.08104964070586138\n```\n:::\n:::\n\n\n::: {#f66f6a1b .cell execution_count=50}\n``` {.python .cell-code}\nypred\n```\n\n::: {.cell-output .cell-output-display execution_count=100}\n```\n[Value(data=0.9034116586940597),\n Value(data=-0.9567970932148172),\n Value(data=-0.8069423147548922),\n Value(data=0.8194935678632469)]\n```\n:::\n:::\n\n\nTa-da! We now understand the intuition behind developing simple neural networks and performing backpropagation to improve their predictive performance!\n\n# Takeaways and summary\n\nNeural nets are simple mathematical expressions that take input data and weights. Working with neural networks involves a forward pass of input data followed by the application of a loss function.\n\nThe goal of a neural network for machine learning is to minimize the output loss to get the model to better predict desired targets. Backpropagation can be applied from the loss function to determine the gradients of the intermediate weights of the network. We can then tune the weights of these nodes against the gradient (i.e. gradient descent) to improve the predictive performance of the model.\n\nSimulating a blob of neural tissue in this manner can handle all sorts of interesting problems. Generative Pre-trained Transformers (GPTs) uses massive amounts of text from the internet and then predict the next words in a sentence based on context. These are really just fancy neural networks with hundreds of billions of parameters. Different models may use different loss functions and different methods for gradient descent, but the underlying concepts are all consistent.\n\nThis concludes my walkthrough of Andrej's first neural networks video tutorial. Until next time, \\[VS\\]Coders!\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}